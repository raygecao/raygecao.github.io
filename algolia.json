[{"categories":["总结与整理"],"content":"grep, sed, awk被称为linux文本处理三剑客，分别侧重于文本搜索，流式编辑和格式化文本。 ","date":"2022-03-05","objectID":"/posts/text-process-tool/:0:0","tags":["linux"],"title":"Linux文本处理工具","uri":"/posts/text-process-tool/"},{"categories":["总结与整理"],"content":"grep 文本搜索工具 Schema：grep [option...] [patterns] [file...] ","date":"2022-03-05","objectID":"/posts/text-process-tool/:1:0","tags":["linux"],"title":"Linux文本处理工具","uri":"/posts/text-process-tool/"},{"categories":["总结与整理"],"content":"Options 短选项 长选项 作用 -e pattern --regexp=pattern 指定搜索pattern，可以不显式指定 -f file --file=file 从file中获取pattern进行搜索 -i/-y ignore-case 匹配忽略大小写 -v --invert-match 匹配反选 -w --word-regexp 指定单词完整匹配，其边界为行首或者除字母、数字、下划线以外的字符 -x --line-regexp 行完整匹配 -c --count 不打印匹配行，只打印匹配行数 -L -l --files-without-match --files-with-matches 不打印匹配行，只打印完全不匹配/存在匹配的文件名 -m num --max-count=num 指定最大匹配次数 -o --only-matching 只打印完整的匹配内容，不打印匹配行 -q --quiet/silent 不打印任何内容，只以返回码来描述是否存在匹配 -h -H --no-filename --with-filename 不打印/打印匹配的文件名前缀，默认为打印(-H) -n --line-number 打印匹配的行号前缀 -A num --after-context=num 打印匹配行，及其以后的num行 -B num --before-context=num 打印匹配行，及其以前的num行 -C num -context=num/-num 打印匹配行，及其前后的各num行 -R --dereference-recursive 递归的匹配目录下所有文件，遇到符号链接正常递归 ","date":"2022-03-05","objectID":"/posts/text-process-tool/:1:1","tags":["linux"],"title":"Linux文本处理工具","uri":"/posts/text-process-tool/"},{"categories":["总结与整理"],"content":"Tips grep不支持换行符的匹配 ","date":"2022-03-05","objectID":"/posts/text-process-tool/:1:2","tags":["linux"],"title":"Linux文本处理工具","uri":"/posts/text-process-tool/"},{"categories":["总结与整理"],"content":"sed 流编辑器，用于逐行地对输入流进行基本的文本转换 schema：sed SCRIPT INPUTFILE INPUTFILE未指定或者指定为-时，表示从stdin读取内容 默认输出为stdout，可以通过w cmd/重定向符保存到文件，可以指定-i在文件内原地修改 多个cmd可以通过;或换行来指定，或者-e指定。（a,c,i命令中不应使用;，会将其当做plain text） data buffer 模式空间（Pattern space）：数据处理空间，sed读取每行到模式空间，进行地址匹配并执行命令 保持空间（Hold space）：辅助暂存空间，在复杂处理过程中，作为数据的暂存区域 ","date":"2022-03-05","objectID":"/posts/text-process-tool/:2:0","tags":["linux"],"title":"Linux文本处理工具","uri":"/posts/text-process-tool/"},{"categories":["总结与整理"],"content":"Options 短选项 长选项 作用 -n --quiet/--silent 禁掉打印模式空间的内容，一般结合p命令打印处理过的行 -f --file 指定sed脚本文件路径，命令形式指定则对应选项-e，一般无需显式指定-e -i --in-place=[suffix] 原地修改文件，如指定suffix会拼接到原文件名作为原文件内容的backup -E/-r --regexp-entended 使用扩展正则表达式 -s --seperate 指定操作多个独立的文件 --posix 严格限定posix，禁用GNU扩展，便于简化可移植脚本的编写 ","date":"2022-03-05","objectID":"/posts/text-process-tool/:2:1","tags":["linux"],"title":"Linux文本处理工具","uri":"/posts/text-process-tool/"},{"categories":["总结与整理"],"content":"Commands 基本形式：[addr]X[options]，其中addr为地址匹配模式，X为单字符命令，options指一些命令需要的额外选项。 s命令：替换字符串 s/regexp/replacement/flags 根据regexp去模式空间找匹配，匹配成功后用replacement去替换掉regexp 特殊符号需插入\\转义 常用flag： g：所有匹配均替换 number：只替换第number个匹配 p：如果发生匹配，打印替换后的模式空间 i/I：匹配忽略字母大小写 m/M：支持多行匹配 其他常见命令 cmd 作用 d 删除模式空间内容，并开始下一轮匹配 p 匹配成功时，打印模式空间，一般配合-n选项使用 n 读取下一行替换当前模式空间的行，执行下一条处理命令而非第一条命令。一般用于周期性替换，如偶数行替换 seq 6 | sed 'n;s/./x/'。N命令在此基础上支持换行处理 {} 封装一组命令用以执行 a text 在一行后添加text i text 在一行前插入text c text 使用text替换行 y/source-chars/dest-chars 执行字符的替换，如使用0-9替换a-j：echo hello | sed 'y/abcdefghij/0123456789/' r filename 读取文件 w filename 将模式空间内容写入到文件 b label 类似于if-else的分支命令，goto label，如跳过第一行的替换：printf '%s\\n' a1 a2 a3 | sed -E '/1/bx ; s/a/z/ ; :x' 与保持空间相关的命令 cmd 作用 g 使用保持空间的内容替换模式空间的内容 G 添加一个新行，并将保持空间的内容追加到模式空间 h 使用模式空间的内容替换保持空间的内容 H 添加一个新行，并将模式空间的内容追加到保持空间 x 交换保持空间和模式空间的内容 ","date":"2022-03-05","objectID":"/posts/text-process-tool/:2:2","tags":["linux"],"title":"Linux文本处理工具","uri":"/posts/text-process-tool/"},{"categories":["总结与整理"],"content":"地址匹配 行号匹配 number：第几行 $: 最后一行 first~step：从first开始，每隔step匹配 正则匹配 范围匹配 addr1,+N：匹配[addr1, addr1+N]行 addr1,~N：匹配[addr1, addr1+addr1%N]行 # examples sed '4,17s/hello/world/' input.txt # 第4-17行将所有hello替换成world sed '/apple/s/hello/world/' input.txt # 所有包含apple的行将hello替换为world sed '2!s/hello/world/' input.txt \u003e output.txt # 除第二行以外将所有hello替换为world ","date":"2022-03-05","objectID":"/posts/text-process-tool/:2:3","tags":["linux"],"title":"Linux文本处理工具","uri":"/posts/text-process-tool/"},{"categories":["总结与整理"],"content":"Tips -i可以指定可选参数，所以其后不应有其他的短选项 sed -Ei ... =\u003e sed -E -i ... sed -iE ... =\u003e sed --in-place=E ... label用作循环处理文本，一般会配合n/N使用，如多行合并的示例：seq 6 | sed ':x; N;s/\\n//; bx;' D,G,H,N,P支持多行处理，每个命令的作用与其小写命令相同 ","date":"2022-03-05","objectID":"/posts/text-process-tool/:2:4","tags":["linux"],"title":"Linux文本处理工具","uri":"/posts/text-process-tool/"},{"categories":["总结与整理"],"content":"awk 文本格式化工具，多用于格式化文本，生成报表。 ","date":"2022-03-05","objectID":"/posts/text-process-tool/:3:0","tags":["linux"],"title":"Linux文本处理工具","uri":"/posts/text-process-tool/"},{"categories":["总结与整理"],"content":"基本用法 schema awk [options] 'Pattern{Action}' file 普通格式化 # $0表示完整行，$1表示第一列，$NF表示最后一列，$(NF-1)表示倒数第二列 df | awk '{print $1, $2}' 设置分隔符 # 输入字段分隔符，可以使用-F: 或者-v FS=:的形式设置 cat /etc/passwd | awk -F: '{print $1} # 输出字段分隔符，可以使用-v OFS=@的形式设置 cat /etc/passwd | awk -v FS=: -v OFS=@ '{print $1, $3}' 内置变量 变量名 作用 默认值 FS 输入字段分隔符 空格 OFS 输出字段分隔符 空格 RS 输入换行符（记录分隔符） \\n ORS 输出换行符 \\n NF 字段数目 NR 行号 FNR 文件序号 FILENAME 当前文件名 ARGC 命令行参数的个数 ARGV 命令行参数组成的数组 # 打印行号，变量在action里不应加$，加$表示获取对应列的内容 df | awk '{print NR, $2}' 自定义变量 # 使用-v设置 awk -v a=\"b\" 'BEGIN {print a}' # 在action中设置，并用分号分隔 awk 'BEGIN {a=\"b\"; print a}' ","date":"2022-03-05","objectID":"/posts/text-process-tool/:3:1","tags":["linux"],"title":"Linux文本处理工具","uri":"/posts/text-process-tool/"},{"categories":["总结与整理"],"content":"特殊模式 BEGIN表示在处理文本前执行action，可用于打印表头 END表示在处理文本后执行action，可用于打印表尾 df | awk 'BEGIN{print \"开始时执行\"} {print $1} END{print \"结束时执行\"}' 条件匹配 # 打印第2行，第一列的内容 df | awk 'NR == 2 {print $1}' # 如果第3行的值大于0，打印完整行 df | awk '$3\u003e0 {print}' 正则相关 # 打印/dev开头的行 # 正则模式采用awk '/regexp1/{action}'的形式 df | awk '/^\\/dev/{print}' # 打印最后一列以/dev开头的行 # 正则匹配采用awk 'var~/regexp1/{action}'的形式 df | awk '$NF~/^\\/dev/{print}' # 打印最后一列从/d开头到/p开头之间的行 # 范围模式采用 awk '/regexp1/, /regexp2/ {action}'形式 df | awk '$NF~/^\\/d/,$NF~/^\\/p/{print}' 分支动作 # 判断分支 df | awk '{ if($2\u003e0){print \"大于0\"}else{print \"小于0\"} }' # 循环分支 df | awk '{ for(i=1; i\u003c3; i++){print $i}}' df | awk '{ i=0; while(i\u003c4){print $0; i++}}' # 将每行打印4遍 ","date":"2022-03-05","objectID":"/posts/text-process-tool/:3:2","tags":["linux"],"title":"Linux文本处理工具","uri":"/posts/text-process-tool/"},{"categories":["总结与整理"],"content":"Tips {}意味着代码块，可以通过;将语句划归到同一代码块中 print动作如果使用,分隔两列，则输出会以输出字段分隔符将两列连接起来，如果以空格分隔，则输出会将两列直接拼接打印 awk支持三元运算符 ","date":"2022-03-05","objectID":"/posts/text-process-tool/:3:3","tags":["linux"],"title":"Linux文本处理工具","uri":"/posts/text-process-tool/"},{"categories":["总结与整理"],"content":"参考文档 https://www.gnu.org/software/grep/manual/grep.html https://www.gnu.org/software/sed/manual/sed.html https://www.gnu.org/software/gawk/manual/gawk.html ","date":"2022-03-05","objectID":"/posts/text-process-tool/:4:0","tags":["linux"],"title":"Linux文本处理工具","uri":"/posts/text-process-tool/"},{"categories":["整理与总结"],"content":"Iptables is the userspace command line program used to configure the Linux 2.4.x and later packet filtering ruleset. It is targeted towards system administrators. ","date":"2021-12-08","objectID":"/posts/iptables/:0:0","tags":["网络"],"title":"Iptables概要整理","uri":"/posts/iptables/"},{"categories":["整理与总结"],"content":"简介 Netfilter/Iptables是unix/linux自带的防火墙工具，netfilter是内核中数据包处理模块，定义了一组hook点，埋在网络协议栈中以对不同阶段的包进行处理，而Iptables是操纵netfilter的命令行工具。netfilter工作在二、三、四层，其匹配规则涵盖网卡，IP，端口等。 netfilter的作用 NAT（网络地址转换） 数据包内容修改 数据包过滤 ","date":"2021-12-08","objectID":"/posts/iptables/:1:0","tags":["网络"],"title":"Iptables概要整理","uri":"/posts/iptables/"},{"categories":["整理与总结"],"content":"Iptables 四表五链 Iptables四张表 filter表：负责过滤数据包； nat表：网络地址转换，如SNAT、DNAT； mangle表：修改报文，解包-\u003e修改-\u003e封包； raw表：关闭nat及数据包链接追踪机制； Iptables五个默认链 PREROUTING：刚进入网络层的数据包会先经由PREROUTING链，并根据路由判断目标地址是否为本机。由于此链为接收包的第一站，因此DNAT通常在此链上配置； INPUT：经由PREROUTING链的数据包发现目标地址为本机，会经由INPUT链进入本机，入站过滤规则通常在此链配置； FORWARD：经由PREROUTING链的数据报发现目标地址不是本机，会经由FORWARD链进行转发，通常网络防火墙会在此链配置； OUTPUT：从本机产生的数据包向外发送时会先经过OUTPUT链，通常出站过滤规则在此链配置。 POSTROUTING：经由OUTPUT/FORWORD链中流出的数据包最终经路由后会到达POSTROUTING链，以从对应的接口流出，POSTROUTING为数据包流出的最后一站，SNAT通常在此链上配置； 每条链上会有多个规则，按顺序匹配，符合规则的触发action，并停止后续的规则匹配。 iptables的默认链及拥有的功能表，引自从零开始认识 iptables\" iptables的默认链及拥有的功能表，引自从零开始认识 iptables 数据包由外部发往本主机进程流向为：PREROUTING -\u003e INPUT 数据包由本主机发往外部进程流向为：OUTPUT -\u003e POSTROUTING 数据包由本主机进行转发的流向为：PREROUTING -\u003e FORWARD -\u003e POSTROUTING 表与链的区别：表主要是按功能进行分类；而链是协议栈中某处提供的钩子函数。 默认策略：每条默认链都会有一个默认策略，在没有规则被匹配时会执行默认策略中的动作，而与之相关的是防火墙的两种通行策略： 黑名单机制：只有匹配到规则的数据包才可能被拒绝，没有匹配到的数据包都会被接受。将默认策略设置为ACCEPT即可实现黑名单机制； 白名单机制：只有匹配到规则的数据包才可能被接收，没有匹配到的数据包都会被拒绝。将默认策略设置为DROP即可实现白名单机制； 注意 黑白名单机制并非只能靠调整默认策略实现，设置默认策略只是实现此机制的一种方案，也可以通过其他方案来实现黑白名单机制，比如将默认策略设置ACCEPT，在链的尾部加一个DROP ALL的规则可以实现白名单机制。通常不建议将默认策略更改为DROP/REJECT，因为在此默认策略下，误flush了链会导致所有请求被拒绝。 同一链上各表执行优先级：raw \u003e mangle \u003e nat \u003e filter ","date":"2021-12-08","objectID":"/posts/iptables/:1:1","tags":["网络"],"title":"Iptables概要整理","uri":"/posts/iptables/"},{"categories":["整理与总结"],"content":"匹配条件 常见匹配条件 类型 iptables输出 备注 源IP source IP报头中记录，可以使单个IP地址或网段，-s指定 目的IP destination IP报头中记录，可以使单个IP地址或网段， -d指定 流入网卡 in -i指定 流出网卡 out -o指定 协议类型 prot -p指定，支持tcp/udp/icmp等 扩展匹配条件 类型 表示 备注 源端口 tcp spt:22 导入协议模块，同时指定--sport指定目的端口 目的端口 tcp dpt:22 导入协议模块，同时指定--dport 指定目的端口 字符串 STRING 导入string模块，同时指定--string指定匹配文本内容 连接数 connlimit 需导入connlimit模块，并设置连接数规则 报文速率 limit 需导入limit模块，并设置速率限制规则 状态 state 需导入state模块，通过--state对状态进行设置，通常用来判断报文是对方主动发送的还是对方回复的响应报文 使用!可以对匹配条件进行取反，扩展匹配条件通常需要通过-m导入特定的模块才可以使用。 ","date":"2021-12-08","objectID":"/posts/iptables/:1:2","tags":["网络"],"title":"Iptables概要整理","uri":"/posts/iptables/"},{"categories":["整理与总结"],"content":"常用的处理动作 动作 含义 ACCEPT 接受此数据包 DROP 直接丢弃此数据包 REJECT 拒绝数据包，并返回相应的通知 SNAT 源端网络地址转换，即将数据包的源IP改写为指定IP MASQUERADE 动态的SNAT，无需手动指定源IP，iptables会将数据包的源IP改写成out网卡的IP，适用于动态生成IP的场景 DNAT 目的端网络地址转换，即将数据包的目的地址改写为指定IP REDIRECT 本机端口映射，即将数据包导向另一个端口 LOG 将数据包记录在内核日志中，然后继续后续规则匹配 RETURN 结束在当前链中的规则匹配，返回到父链继续匹配 ","date":"2021-12-08","objectID":"/posts/iptables/:1:3","tags":["网络"],"title":"Iptables概要整理","uri":"/posts/iptables/"},{"categories":["整理与总结"],"content":"CheatSheet 选项 作用 备注 -L 获取规则列表 可接链名，不接默认为所有链，一般使用-nvL --line列举 -I/-A 在特定行/尾行插入 -I可以指定行号，默认为首行 -t 指定表名 默认为filter表 -D 删除某条规则 可以指定行号，也可以指定匹配条件+动作 -R 更新规则 须指定匹配条件和动作，建议使用删除+添加的形式 -F 清空某条链全部规则 慎用 -P 修改某条链上的默认规则 初始为ACCEPT，不建议设置为DROP/REJECT -N 创建一条自定义链 规则模块化，便于管理 ","date":"2021-12-08","objectID":"/posts/iptables/:1:4","tags":["网络"],"title":"Iptables概要整理","uri":"/posts/iptables/"},{"categories":["整理与总结"],"content":"增删改查基本指令示例 $ iptables -t filter -nvL INPUT --line # 查询filter表，INPUT链的所有规则并展示行号 $ iptables -t filter -I INPUT 2 -s 10.1.0.1 -j DROP # 在filter表，INPUT链第二行添加拒绝源IP为10.1.0.1的DROP规则 $ iptables -t filter -D INPUT 2 # 在filter表，INPUT链删除第二条规则 $ iptables -D INPUT 2 \u0026\u0026 iptable -I INPUT 2 -s 10.1.0.2 -j REJECT # 将filter表，INPUT链第二条规则修改为拒绝10.122.0.2 $ iptables -t filter -P FORWARD DROP # 将filter表的FORWARD链默认动作设置为DROP(默认禁止转发) ","date":"2021-12-08","objectID":"/posts/iptables/:1:5","tags":["网络"],"title":"Iptables概要整理","uri":"/posts/iptables/"},{"categories":["整理与总结"],"content":"自定义链 上述描述的五条链是Iptables的默认链，除此之外，iptables还支持自定义链，自定义链与默认链的操作方式相同，但不是netfilter标准hook点，因此自定义链需要附加在某个默认链上。默认链在匹配到自定义链时会将其展开进行规则匹配，类似于内联函数，我们可以类比自定义函数来看一下自定义链的优势。 函数一般需要满足单一性原则，自定义链也是将满足同一功能/归属统一业务的规则集中在一条链上管理，这样可以有效避免默认链上规则无限制的增长，便于管理与维护。 函数是可复用的，自定义链也是可以复用的，一些通用的规则可以放在一条自定义链上被多个默认链/其他自定义链引用，对复用链的更新会传播到引用链中，对同一条规则的修改无需手动操作多条链。 ","date":"2021-12-08","objectID":"/posts/iptables/:1:6","tags":["网络"],"title":"Iptables概要整理","uri":"/posts/iptables/"},{"categories":["整理与总结"],"content":"Docker iptables分析 为了将docker中iptables的作用展示的更透彻，示例环境启动了两个容器，详情如下： # docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES f36770eceff5 ibmcom/guestbook:v2 \"./guestbook\" 3 weeks ago Up 3 weeks 0.0.0.0:19002-\u003e3000/tcp jolly_noether d8e30286aa69 ibmcom/guestbook:v1 \"./guestbook\" 3 weeks ago Up 3 weeks 0.0.0.0:19001-\u003e3000/tcp eager_dubinsky 均在默认的bridge网络下，两个容器的3000端口分别publish到19002与19001端口。 ","date":"2021-12-08","objectID":"/posts/iptables/:2:0","tags":["网络"],"title":"Iptables概要整理","uri":"/posts/iptables/"},{"categories":["整理与总结"],"content":"filter表 Iptables的INPUT链，OUTPUT链均为空，FORWARD设置了默认策略是DROP的白名单模式，这里着重看一下FORWARD链： filter表中forward链\" filter表中forward链 Rule1引用了一个自定义链DOCKER-USER，此链只有一个RETURN动作，如果需要在此docker环境下手动添加iptables rules可以选择在此处添加。 Rule2引用了DOCKER-ISOLATION-STAGE-1链，相继引用了DOCKER-ISOLATION-STAGE-2链，这两条链也都没有实质性规则，所有的转发数据包会继续向下匹配。 Rule3表示接受从docker0流出的所有响应报文。 Rule4表示从docker0流出的数据包需要走DOCKER链，DOCKER链我们稍后分析。 Rule5表示接受从docker0流入，但不是从docker0流出的数据包，容器访问宿主机/外网等非容器网络时匹配此规则。 Rule6表示接受从docker0流入，同时从docker0流出的数据报，在默认bridge网络上的容器间通信匹配此规则。 再来看一下DOCKER链，容器相关的规则都放在DOCKER链上，便于管理及查询。 filter表中自定义DOCKER链\" filter表中自定义DOCKER链 Rule1表示接受不是从docker0流入，但从docker0流出，并且访问的目的IP为172.17.0.2， 访问目的port为3000的tcp报文。 Rule2表示接受不是从docker0流入，但从docker0流出，并且访问的目的IP为172.17.0.3， 访问目的port为3000的tcp报文。 上述规则都没有匹配的报文，那是因为无论我们从容器内还是宿主机访问容器，都是从docker0流入、从docker0流出。如果将某个一条路由的节点添加一条路由规则，将172.17.0.0/24的destination gateway设置为本机，这样对172.17.0.3:3000的访问会经物理网卡流入，经docker0流出到容器内，会匹配上此链上的规则。说白了，其意图是只要你能将请求路由到本机，我就允许你访问默认bridge网络中容器提供的服务。 ","date":"2021-12-08","objectID":"/posts/iptables/:2:1","tags":["网络"],"title":"Iptables概要整理","uri":"/posts/iptables/"},{"categories":["整理与总结"],"content":"nat表 下面来分析一下nat表，OUTPUT链和PREROUTING链会引用DOCKER自定义链，其他链上规则基本为空或者都不会匹配到。我们主要关注一下POSTROUTING链和DOKCER链，先看一下POSTROUTING链： nat表中PREROUTING链\" nat表中PREROUTING链 Rule1表示不是从docker0流出的，且源网段为172.17.0.0/16的数据包会被进行动态SNAT，将数据包的源IP改为流出网卡的地址，若从容器内访问外网，源IP会被更新为宿主机物理网卡的IP地址。 Rule2，Rule3乍一看像是自己访问自己的3000端口时会采用MASQ。但从容器内路由规则可以看到，容器内访问容器网络是无需路由到docker0，而直接在二层网络上转发。而容器内通过容器IP访问自身服务是无需经由docker0的，因此第2、3条的作用不明确。 再看一下DOCKER链： nat表中自定义DOCKER链\" nat表中自定义DOCKER链 Rule1表示从docker0流入的数据包直接跳过此链，因为容器网络间的访问是不需要NAT的。 Rule2, Rule3分别表示两个容器publish了3000端口到19001端口，3000端口到19002端口。那些不是从docker0流入的数据包想要访问容器内的服务时，访问对应网卡上的19001端口的tcp请求就转发到172.17.0.2:3000；而访问19002端口的tcp请求就转发到172.17.0.3:3000。 ","date":"2021-12-08","objectID":"/posts/iptables/:2:2","tags":["网络"],"title":"Iptables概要整理","uri":"/posts/iptables/"},{"categories":["整理与总结"],"content":"Tips 由于iptables是按顺序匹配的，因此应该将更容易匹配的规则放在前面，以提升防火墙的匹配性能。 当存在多个匹配条件时，各条件之间为与的关系，即所有匹配条件均满足时才会执行对应的action。 配置白名单时，一般不会将默认链策略设置为DROP，这是因为如果误刷了该默认链（-F）将导致所有数据包都会被拒绝，会导致我们无法连接到服务器。一般白名单机制会将默认链策略设置为ACCEPT，并在链的最后设置DROP ALL的规则。 为提升iptables线性匹配算法，一些ACL优化算法被提出，eBPF 技术实践：高性能 ACL 采用根据匹配规则倒排，并利用bitmap来快速匹配的算法，以达到近O(1)的匹配性能。 ","date":"2021-12-08","objectID":"/posts/iptables/:3:0","tags":["网络"],"title":"Iptables概要整理","uri":"/posts/iptables/"},{"categories":["整理与总结"],"content":"参考文献 朱双印的博客iptables部分 从零开始认识 iptables eBPF 技术实践：高性能 ACL ","date":"2021-12-08","objectID":"/posts/iptables/:4:0","tags":["网络"],"title":"Iptables概要整理","uri":"/posts/iptables/"},{"categories":["探索与实战"],"content":"Docker 通过storage driver来存储镜像层，并且将数据存储到容器层。本文主要介绍storage driver与volume的区别，以及对经典的driver：aufs, overlay, overlay2进行简单的探索。 ","date":"2021-10-16","objectID":"/posts/storage-driver/:0:0","tags":["container"],"title":"浅谈Docker Storage Driver","uri":"/posts/storage-driver/"},{"categories":["探索与实战"],"content":"Storage Driver vs Docker Volume Storage Driver 用于存储image layer。 用于在容器层（writeable layer）存数据。 容器层在容器销毁后丢失，无法做到持久化，无法在多个容器中共享用户数据。 一般使用CoW（copy on write）机制写容器层，初次写数据时需要从镜像层将数据copy-up到容器层进行写操作。 容器可以复用镜像层，由于CoW机制，每创建一个容器仅多创建一个很薄的容器层，可以充分提升空间效率。 Docker Volume 持久化容器产生的数据，与容器生命周期无关。 数据可以在容器间共享。 写volume性能远比写容器层的性能好，volume适合于写密集的场景。 ","date":"2021-10-16","objectID":"/posts/storage-driver/:1:0","tags":["container"],"title":"浅谈Docker Storage Driver","uri":"/posts/storage-driver/"},{"categories":["探索与实战"],"content":"Aufs ","date":"2021-10-16","objectID":"/posts/storage-driver/:2:0","tags":["container"],"title":"浅谈Docker Storage Driver","uri":"/posts/storage-driver/"},{"categories":["探索与实战"],"content":"理论 判断内核是否支持aufs driver，结果输出如下表示支持： $ grep aufs /proc/filesystems nodev aufs Aufs是一个联合文件系统，其采用union mount将linux系统上的多个目录堆叠成一个目录，一个目录代表一个branch（在docker术语中对应为layer）。 aufs layer组织形式\" aufs layer组织形式 存储结构 diff/：每一层的内容，每层以一个独立的子目录存储。 layers/：存放layers的元信息以标识镜像层如何堆叠，每层以一个文件表示。 mnt/：挂载点，每层一个，用于向容器组装/挂载联合文件系统。 容器读文件 仅在容器层存在：直接从容器层读出。 仅在镜像层存在：沿着layer stack寻找文件，找到后读出。 在容器层和镜像层均存在：从容器层读出，镜像层相应的文件被容器层所遮盖。 容器写文件 从容器层查找文件，如果存在则直接修改。 如果不存在，沿着镜像layer stack查找文件，如果文件存在则copy-up到容器层进行修改。 如果镜像层也不存在，则直接在容器层创建文件。 容器删除文件/目录 删除文件：在容器层创建一个whiteout file，避免向下层继续寻找。 删除目录：在容器层创建一个opaque file（实测依然是whiteout file）。 Aufs性能 对容器密集型场景友好，因其能有效利用运行中的容器image，使得容器启动更迅速，减少磁盘空间使用。 能有效使用page cache。 定位文件开销大，需要沿着layer stack逐层定位。 首次写操作开销大，尤其是文件在镜像层存在时，需要copy-up至容器层。由于aufs底层存储是文件级别而非块级别，对于文件的修改需要将整个文件复制到容器层。因此文件越大，写性能越差。 最佳实践 使用ssd盘，速度远高于旋转式磁盘。 对于write-heavy负载使用volume，减少IO开销的同时可以将容器数据持久化，并且可以在多个容器中共享。 ","date":"2021-10-16","objectID":"/posts/storage-driver/:2:1","tags":["container"],"title":"浅谈Docker Storage Driver","uri":"/posts/storage-driver/"},{"categories":["探索与实战"],"content":"实践 使用ubuntu:16.04 image对aufs driver进行探究，首先启动一个container： $ docker run -it --rm ubuntu:16.04 bash Docker存储目录结构如下： $ tree -L 2 /var/lib/docker/aufs /var/lib/docker/aufs ├── diff │ ├── 1492027998d17f2f422a0d46ed6e41a9ef59911bb13357765aeb0dc9f150ea76 │ ├── 72c62493358ebb6ae7d47717a491b7f3ff402fb338a34d9df8529c166223737a │ ├── 8065b4da5339d297dfb53f4bd7edfeba97b5c0089eda635c412943c4d7e55e81 │ ├── a5cad43027e71dcd8efaa9287a4c502a59631c108d22b5e861d9ca1878525227 │ ├── a5cad43027e71dcd8efaa9287a4c502a59631c108d22b5e861d9ca1878525227-init │ └── aff7006186a6867de9cc7a75f1d31c90eb52753b9d96d6c85a3f66e78ccd465b ├── layers │ ├── 1492027998d17f2f422a0d46ed6e41a9ef59911bb13357765aeb0dc9f150ea76 │ ├── 72c62493358ebb6ae7d47717a491b7f3ff402fb338a34d9df8529c166223737a │ ├── 8065b4da5339d297dfb53f4bd7edfeba97b5c0089eda635c412943c4d7e55e81 │ ├── a5cad43027e71dcd8efaa9287a4c502a59631c108d22b5e861d9ca1878525227 │ ├── a5cad43027e71dcd8efaa9287a4c502a59631c108d22b5e861d9ca1878525227-init │ └── aff7006186a6867de9cc7a75f1d31c90eb52753b9d96d6c85a3f66e78ccd465b └── mnt ├── 1492027998d17f2f422a0d46ed6e41a9ef59911bb13357765aeb0dc9f150ea76 ├── 72c62493358ebb6ae7d47717a491b7f3ff402fb338a34d9df8529c166223737a ├── 8065b4da5339d297dfb53f4bd7edfeba97b5c0089eda635c412943c4d7e55e81 ├── a5cad43027e71dcd8efaa9287a4c502a59631c108d22b5e861d9ca1878525227 ├── a5cad43027e71dcd8efaa9287a4c502a59631c108d22b5e861d9ca1878525227-init └── aff7006186a6867de9cc7a75f1d31c90eb52753b9d96d6c85a3f66e78ccd465b 15 directories, 6 files 可以看到存在一个-init后缀目录项，因此可以断定a5cad43是容器层，其他均为镜像层。 从挂载信息中可以验证这一点，aufs仅需挂载upperdir： $ mount | grep aufs none on /var/lib/docker/aufs/mnt/a5cad43027e71dcd8efaa9287a4c502a59631c108d22b5e861d9ca1878525227 type aufs (rw,relatime,si=b3be613c19d0e57c,dio,dirperm1) 可以看到此挂载source内容即为ubuntu rootfs的内容： $ ls /var/lib/docker/aufs/mnt/a5cad43027e71dcd8efaa9287a4c502a59631c108d22b5e861d9ca1878525227 bin boot dev etc home lib lib64 media mnt opt proc root run sbin srv sys tmp usr var 此镜像中layer stack又是如何组织的呢？ $ cat /var/lib/docker/aufs/layers/a5cad43027e71dcd8efaa9287a4c502a59631c108d22b5e861d9ca1878525227 a5cad43027e71dcd8efaa9287a4c502a59631c108d22b5e861d9ca1878525227-init aff7006186a6867de9cc7a75f1d31c90eb52753b9d96d6c85a3f66e78ccd465b 8065b4da5339d297dfb53f4bd7edfeba97b5c0089eda635c412943c4d7e55e81 1492027998d17f2f422a0d46ed6e41a9ef59911bb13357765aeb0dc9f150ea76 72c62493358ebb6ae7d47717a491b7f3ff402fb338a34d9df8529c166223737a 可以从容器层的layers内容中看到layer stack自顶向下的组织形式为 a5 -\u003e a5-init -\u003e af -\u003e 80 -\u003e 14 -\u003e 72。 接下来验证一下容器内更改文件系统对aufs存储有什么影响。 创建文件 # 容器内 $ touch kkk # 宿主机 $ find /var/lib/docker/aufs -name kkk /var/lib/docker/aufs/mnt/a5cad43027e71dcd8efaa9287a4c502a59631c108d22b5e861d9ca1878525227/kkk /var/lib/docker/aufs/diff/a5cad43027e71dcd8efaa9287a4c502a59631c108d22b5e861d9ca1878525227/kkk 可以看见文件的创建仅发生在容器层。同理，更改文件内容也是如此，只是涉及到从镜像层到容器层的copy-up。 删除文件 # 容器内 $ rm /bin/zegrep # 宿主机 $ find /var/lib/docker/aufs -name *zegrep* /var/lib/docker/aufs/mnt/a5cad43027e71dcd8efaa9287a4c502a59631c108d22b5e861d9ca1878525227/usr/share/man/man1/zegrep.1.gz /var/lib/docker/aufs/diff/a5cad43027e71dcd8efaa9287a4c502a59631c108d22b5e861d9ca1878525227/bin/.wh.zegrep /var/lib/docker/aufs/diff/72c62493358ebb6ae7d47717a491b7f3ff402fb338a34d9df8529c166223737a/bin/zegrep /var/lib/docker/aufs/diff/72c62493358ebb6ae7d47717a491b7f3ff402fb338a34d9df8529c166223737a/usr/share/man/man1/zegrep.1.gz 可以看到容器中/bin/zegrep位于最底层的72c6249镜像层，容器内删除此文件并不会在镜像层删除，而是在容器层a5cad43产生一个whiteout文件——/bin/.wh.zegrep，通过whiteout文件避免沿着layer stack向下查找。如果容器内误删了某个文件，可以在对应容器层diff目录中将whiteout文件删除以将其恢复。 ","date":"2021-10-16","objectID":"/posts/storage-driver/:2:2","tags":["container"],"title":"浅谈Docker Storage Driver","uri":"/posts/storage-driver/"},{"categories":["探索与实战"],"content":"OverlayFS OverlayFS是一种类似aufs的联合文件系统，但是速度更快，更简单。Docker基于overlayFS提供了两种存储驱动：overlay和overlay2 将两个目录以union mount的形式组织成单个目录，镜像层目录为lowerdir，容器层目录为upperdir，对外呈现一致的目录视图（容器内看到的文件系统）叫做merged。 overlayFS layer组织形式\" overlayFS layer组织形式 ","date":"2021-10-16","objectID":"/posts/storage-driver/:3:0","tags":["container"],"title":"浅谈Docker Storage Driver","uri":"/posts/storage-driver/"},{"categories":["探索与实战"],"content":"Overlay2 Overlay2 driver每一层均以一个patch的形式表示，基于内核overlayFS的multiple lower layers特性实现，不再需要硬链接，lowerdir是将镜像层所有的layer overlay起来组成。 容器层挂载信息： # mount | grep overlay overlay on /var/lib/docker/overlay2/23ae9a63ab9f4f4c36af29f78fb64d4e943c7af9f241b696e7870d37dca0130b/merged type overlay (rw,relatime,lowerdir=/var/lib/docker/overlay2/l/XRV25KXVQWJ42GBK5UJD7ICFVV:/var/lib/docker/overlay2/l/ZVAQQEPIP4VXNQK2LZM24JXP7H:/var/lib/docker/overlay2/l/7YTDWL6UA7JEAI5KPCZEUDIUUF:/var/lib/docker/overlay2/l/OER42RBQQTIFRQ7LZRR4IPRQWU:/var/lib/docker/overlay2/l/2MR2ULDESC4VPFHAYTSOAVXLFF,upperdir=/var/lib/docker/overlay2/23ae9a63ab9f4f4c36af29f78fb64d4e943c7af9f241b696e7870d37dca0130b/diff,workdir=/var/lib/docker/overlay2/23ae9a63ab9f4f4c36af29f78fb64d4e943c7af9f241b696e7870d37dca0130b/work,xino=off) 层间组织关系简单示意： overlay2 driver层堆叠示意\" overlay2 driver层堆叠示意 存储结构 diff/：本层的内容。 link：当前层的短标识。 lower：当前层的父layers，按层序排列，除最底层外有此文件。 work/：overlayFS内部使用的文件，除最底层外有此目录。 merged/：其自身及其父layer的联合目录结构，只有容器层有此目录。 l/：此目录存放短id的符号链接。 # tree -L 2 /var/lib/docker/overlay2 /var/lib/docker/overlay2 ├── 013299735d8abd2c0cc5cbad32f011be44fad600a624bc6c2f1f94b9bffa64c2 │ ├── diff │ ├── link │ ├── lower │ └── work ├── 23ae9a63ab9f4f4c36af29f78fb64d4e943c7af9f241b696e7870d37dca0130b │ ├── diff │ ├── link │ ├── lower │ ├── merged │ └── work ├── 23ae9a63ab9f4f4c36af29f78fb64d4e943c7af9f241b696e7870d37dca0130b-init │ ├── committed │ ├── diff │ ├── link │ ├── lower │ └── work ├── 36bf33266ffa01007cdc8db601c77fb6bd5aa5d2dc8dd35fe873e1580073db82 │ ├── committed │ ├── diff │ └── link ├── 3862629a36e3286f03a2d9234633fdb0e9301a33a7195087afd3b3f92c1464fb │ ├── committed │ ├── diff │ ├── link │ ├── lower │ └── work ├── 6d1ca51490fa03a0ebf3767e0ddc93508593fa380b542af3e5187f0ec5e2629c │ ├── committed │ ├── diff │ ├── link │ ├── lower │ └── work ├── 74e31d6f05b337350eb841d01d9728852f6fb0c69a007957dcf04cdb570d8b06 │ ├── committed │ ├── diff │ ├── link │ ├── lower │ └── work └── l ├── 2MR2ULDESC4VPFHAYTSOAVXLFF -\u003e ../36bf33266ffa01007cdc8db601c77fb6bd5aa5d2dc8dd35fe873e1580073db82/diff ├── 7YTDWL6UA7JEAI5KPCZEUDIUUF -\u003e ../74e31d6f05b337350eb841d01d9728852f6fb0c69a007957dcf04cdb570d8b06/diff ├── EYKZCXLZJEZJW55DB7S5ID2HKW -\u003e ../23ae9a63ab9f4f4c36af29f78fb64d4e943c7af9f241b696e7870d37dca0130b/diff ├── OER42RBQQTIFRQ7LZRR4IPRQWU -\u003e ../3862629a36e3286f03a2d9234633fdb0e9301a33a7195087afd3b3f92c1464fb/diff ├── TQQ75355OL5U7VFEC6XG7YBWE5 -\u003e ../013299735d8abd2c0cc5cbad32f011be44fad600a624bc6c2f1f94b9bffa64c2/diff ├── XRV25KXVQWJ42GBK5UJD7ICFVV -\u003e ../23ae9a63ab9f4f4c36af29f78fb64d4e943c7af9f241b696e7870d37dca0130b-init/diff └── ZVAQQEPIP4VXNQK2LZM24JXP7H -\u003e ../6d1ca51490fa03a0ebf3767e0ddc93508593fa380b542af3e5187f0ec5e2629c/diff 注意 OverlayFS中删除文件仍然使用whiteout文件来阻止向容器层以下查找文件，只是在aufs中，whiteout文件以.wh.{FILENAME}命名的普通文件呈现；而在overlayFS中，whiteout文件以原文件命名的字符设备文件呈现。 例如，从附录ubuntu:16.04的镜像分析中可以看到第三层删除了/var/lib/apt/lists下的所有文件，对应layer的diff中可以看到，这些文件都变成了字符设备文件： $ ll -a /var/lib/docker/overlay2/74e31d6f05b337350eb841d01d9728852f6fb0c69a007957dcf04cdb570d8b06/diff/var/lib/apt/lists/ total 8 drwxr-xr-x 2 root root 4096 Aug 31 09:21 ./ drwxr-xr-x 3 root root 4096 Aug 5 03:01 ../ c--------- 1 root root 0, 0 Oct 7 13:55 archive.ubuntu.com_ubuntu_dists_xenial_InRelease c--------- 1 root root 0, 0 Oct 7 13:55 archive.ubuntu.com_ubuntu_dists_xenial_main_binary-amd64_Packages c--------- 1 root root 0, 0 Oct 7 13:55 archive.ubuntu.com_ubuntu_dists_xenial_main_i18n_Translation-en c--------- 1 root root 0, 0 Oct 7 13:55 archive.ubuntu.com_ubuntu_dists_xenial_restricted_binary-amd64_Packages c--------- 1 root root 0, 0 Oct 7 13:55 archive.ubuntu.com_ubuntu_dists_xenial_restricted_i18n_Translation-en c--------- 1 root root 0, 0 Oct 7 13:55 archive.ubuntu.com_ubuntu_dists_xenial-updates_InReleasec--------- 1 root root 0, 0 Oct 7 13:55 archive.ubuntu.com_ubuntu_dists_xenial-updates_main_binary-amd64_Packages c--------- 1 root root 0, 0 Oct 7 13:55 archive.ubuntu.com_ubuntu_dists_xenial-updates_main_i18n_Translation-en c--------- 1 root root ","date":"2021-10-16","objectID":"/posts/storage-driver/:3:1","tags":["container"],"title":"浅谈Docker Storage Driver","uri":"/posts/storage-driver/"},{"categories":["探索与实战"],"content":"Overlay Overlay driver每一层都构筑成完整的镜像，即每一层都是从最底层到当前层overlay出的完整结构，下一层的文件以硬链接的方式出现在它的上一层，lowerdir只由镜像层的top layer组成。 容器层挂载信息： # 镜像层每层以硬链接形式共享文件 $ cd /var/lib/docker/overlay; ls -i 07236efba039eb5cb4e0b6ec010218aefd17293f8297d43c04be4a5b0fd59ab7/root/bin/ls 09195a984aeac5c05ac3c487b1bb2ffb4d57465a3dc575c13e8d4610484ae0b2/root/bin/ls 655184 07236efba039eb5cb4e0b6ec010218aefd17293f8297d43c04be4a5b0fd59ab7/root/bin/ls 655184 09195a984aeac5c05ac3c487b1bb2ffb4d57465a3dc575c13e8d4610484ae0b2/root/bin/ls # 容器层仅overlay mount了镜像层最顶层的root目录 $ mount | grep overlay overlay on /var/lib/docker/overlay/4d0852eca897d746e415bffb325ad3661f8371987082f6b6c8e9d5b9fda9abc5/merged type overlay (rw,relatime,lowerdir=/var/lib/docker/overlay/07236efba039eb5cb4e0b6ec010218aefd17293f8297d43c04be4a5b0fd59ab7/root,upperdir=/var/lib/docker/overlay/4d0852eca897d746e415bffb325ad3661f8371987082f6b6c8e9d5b9fda9abc5/upper,workdir=/var/lib/docker/overlay/4d0852eca897d746e415bffb325ad3661f8371987082f6b6c8e9d5b9fda9abc5/work,xino=off) 层间组织关系简单示意： overlay driver层堆叠示意\" overlay driver层堆叠示意 存储结构 root/：本层完整的目录结构，下层文件以硬链的形式出现在本层，所有镜像层有且仅有此目录。 merged/： 其自身及其父layer的联合目录结构，只有容器层有此目录。 upper/：本层的内容，类似于overlay2中的diff目录，但只有容器层有此目录。 work/：overlayFS内部使用的文件，只有容器层有此目录。 lower-id：lowerdir（镜像层顶层）的id。 $ tree -L 2 /var/lib/docker/overlay /var/lib/docker/overlay ├── 07236efba039eb5cb4e0b6ec010218aefd17293f8297d43c04be4a5b0fd59ab7 │ └── root ├── 09195a984aeac5c05ac3c487b1bb2ffb4d57465a3dc575c13e8d4610484ae0b2 │ └── root ├── 15afdc0d3161ffd9002a5d7714bb3566a658bfa286de82ff95a49368769e5072 │ └── root ├── 4d0852eca897d746e415bffb325ad3661f8371987082f6b6c8e9d5b9fda9abc5 │ ├── lower-id │ ├── merged │ ├── upper │ └── work ├── 4d0852eca897d746e415bffb325ad3661f8371987082f6b6c8e9d5b9fda9abc5-init │ ├── lower-id │ ├── upper │ └── work └── f6bdc701b8624ef39632441ad84efde79de50ae2bc3c637eabf0827084d547ec └── root init layer 在上述driver中，存储目录中都有一个-init后缀的目录，此为init layer，位于容器层与镜像层之间，只读。其主要包含了docker为容器准备的一些文件： $ tree /var/lib/docker/overlay/2178b65434aae442f3e71937bc6f775063a9993a3684625e982c7195052e9289-init/ /var/lib/docker/overlay/2178b65434aae442f3e71937bc6f775063a9993a3684625e982c7195052e9289-init/ ├── lower-id ├── upper │ ├── dev │ │ └── console │ └── etc │ ├── hostname │ ├── hosts │ ├── mtab -\u003e /proc/mounts │ └── resolv.conf └── work └── work upper dir中除了mtab是指向/proc/mounts的软链接之外，其他都是空的普通文件。这些文件都是Linux runtime必须的文件，如果缺少会导致某些程序或库出现异常。init layer主要是用于占坑，避免系统因缺少特殊文件而崩溃，具体内容后续进行bind mount。 由于init layer很薄并且只读，上述讨论将其予以忽略，其本身可以帮助我们快速定位到容器层的id。 ","date":"2021-10-16","objectID":"/posts/storage-driver/:3:2","tags":["container"],"title":"浅谈Docker Storage Driver","uri":"/posts/storage-driver/"},{"categories":["探索与实战"],"content":"Aufs, overlay与overlay2比较 相同点 划分容器层与镜像层，镜像层只读可以复用；容器层可写，采用CoW机制。 底层基于file-level，而非block-level，可有效利用内存，但写操作开销大，CoW效率低。当文件很大时，对其修改需要全部copy-up到容器层，即便是仅仅进行了很小的修改。 不同点 Aufs driver是按照layer stack组织镜像层的，即在定位文件时需要沿着layer stack一层一层地去定位。因此其性能相较于overlayFS差，尤其是镜像层数比较深时。 Overlay driver每层都构筑完整的镜像目录结构，通过硬链接的形式复用底层镜像层的文件。在镜像层数较深时，定位文件及写容器层的性能要略好于overlay2。但是由于每层都是完整的镜像目录结构，各级子目录会占用大量的inode，尤其当层数很深时，inode易被耗尽。 Overlay2 driver每层仅包含当前层的增量内容，通过overlay multiple lower layers形式构筑lowerdir，解决了overlay driver中消耗大量inode的问题，也是docker官方推荐的storage driver。 ","date":"2021-10-16","objectID":"/posts/storage-driver/:4:0","tags":["container"],"title":"浅谈Docker Storage Driver","uri":"/posts/storage-driver/"},{"categories":["探索与实战"],"content":"附录 使用dive对ubuntu:16.04进行镜像分析： $ dive ubuntu:16.04 ubuntu:16.04的镜像分析\" ubuntu:16.04的镜像分析 ","date":"2021-10-16","objectID":"/posts/storage-driver/:5:0","tags":["container"],"title":"浅谈Docker Storage Driver","uri":"/posts/storage-driver/"},{"categories":["探索与实战"],"content":"参考文献 About storage drivers Use the AUFS storage driver Use the OverlayFS storage driver DOCKER基础技术：AUFS ","date":"2021-10-16","objectID":"/posts/storage-driver/:6:0","tags":["container"],"title":"浅谈Docker Storage Driver","uri":"/posts/storage-driver/"},{"categories":["探索与实战"],"content":"Telepresence用于在本地轻松开发和调试服务，同时将服务代理到远程 Kubernetes 集群。 使用 telepresence 可以为本地服务使用自定义工具（如调试器和 IDE）， 并提供对 Configmap、Secret 和远程集群上运行的服务的完全访问。 ","date":"2021-10-02","objectID":"/posts/telepresence/:0:0","tags":["k8s"],"title":"Telepresence——本地调试k8s服务利器","uri":"/posts/telepresence/"},{"categories":["探索与实战"],"content":"背景 应用容器化带来了高效率、强扩展性等优势的的同时也带来一些复杂性。尤其对于开发人员，需要将修改部署到容器中（构建容器-\u003e发布到registry-\u003e部署到集群中）。如果使用k8s这种容器平台，还需要维护容器编排及配置从而延长开发迭代周期。总之，在容器化应用中，研发要对软件的整个生命周期负责。 为了提升开发效率，需要引入将远程k8s集群与本地开发桥接起来的方法，以此减少反馈时间，提升debug效率。加速反馈的最佳实现方式是单个本地服务，其他依赖服务都是远程的，telepresence便是基于此思想的一个加速反馈， 便于调试及协作的开发者工具。 Telepresence被设计为让k8s开发者的笔记本如同加入到了k8s集群中一样，能够将服务在本地运行，并且被proxy到远端集群中。 ","date":"2021-10-02","objectID":"/posts/telepresence/:1:0","tags":["k8s"],"title":"Telepresence——本地调试k8s服务利器","uri":"/posts/telepresence/"},{"categories":["探索与实战"],"content":"架构 Telepresence架构图\" Telepresence架构图 Telepresence CLI：用于编排出所有其他的组件，如telepresence daemon，traffic manager，授权Ambassador Cloud等。既起到bootstrap作用，又起到发送控制命令作用。 # 首次执行telepresence list cli $ telepresence list Launching Telepresence Daemon v2.3.2 (api v3) Connecting to traffic manager... Connected to context minikube (https://10.122.101.148:38443) frontend : ready to intercept (traffic-agent not yet installed) redis-follower: ready to intercept (traffic-agent not yet installed) redis-leader : ready to intercept (traffic-agent not yet installed) 上例可以看到，在初次执行telepresence cli时，其先启动了telepresence daemon，紧接着安装并连接traffic manager，最后才返回对应cmd的结果。 Telepresence Daemon：是开发者本地的代理点。 Traffic Manager：集群流量入口点，也是流量控制的中枢代理。同时它会与Ambassador Cloud交互以支持Preview URL的特性。 Traffic Agent：用于流量代理的sidecar，主要根据拦截规则判断到达的请求，要么将请求直接交付给pod对应的端口，要么路由到traffic manager以转发到本地服务中。 拦截方式 目前主要的拦截方式有两种：全量拦截和preview URL，前者traffic agent会全量地路由给traffic manager；后者会对请求进行判断，只有preview URL请求会路由到traffic manager，其他请求交付给pod内的服务。 Ambassador Cloud：产生临时域名，将preview URL从授权的用户路由到traffic manager。 ","date":"2021-10-02","objectID":"/posts/telepresence/:2:0","tags":["k8s"],"title":"Telepresence——本地调试k8s服务利器","uri":"/posts/telepresence/"},{"categories":["探索与实战"],"content":"使用 ","date":"2021-10-02","objectID":"/posts/telepresence/:3:0","tags":["k8s"],"title":"Telepresence——本地调试k8s服务利器","uri":"/posts/telepresence/"},{"categories":["探索与实战"],"content":"准备工作 安装telepresence k8s集群中安装guestbook demo $ kubectl get pod NAME READY STATUS RESTARTS AGE frontend-7bcb4574cb-j2wwz 1/1 Running 0 39s frontend-7bcb4574cb-rbxkj 1/1 Running 0 41s frontend-7bcb4574cb-xxm56 1/1 Running 0 44s redis-follower-dd4df4648-pvd2c 1/1 Running 5 50d redis-follower-dd4df4648-wzf54 1/1 Running 5 50d redis-leader-6d7765b8f6-mbzm8 1/1 Running 5 50d $ kubectl get svc NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE frontend ClusterIP 10.111.60.121 \u003cnone\u003e 80/TCP 50d kubernetes ClusterIP 10.96.0.1 \u003cnone\u003e 443/TCP 50d redis-follower ClusterIP 10.96.4.108 \u003cnone\u003e 6379/TCP 50d redis-leader ClusterIP 10.101.93.34 \u003cnone\u003e 6379/TCP 50d 由于k8s环境是通过minikube虚拟机搭建的，为了方便在宿主机访问集群内部服务，我们使用port-forward进行端口转发。 # 集群服务器148开端口转发，将148宿主机上12180端口的流量转发到集群内frontend service中 $ kubectl port-forward svc/frontend 12180:80 --address=0.0.0.0 验证一下frontend service提供的是guestbook服务。 $ curl 10.122.101.148:12180 \u003chtml ng-app=\"redis\"\u003e \u003chead\u003e \u003ctitle\u003eGuestbook\u003c/title\u003e \u003clink rel=\"stylesheet\" href=\"//netdna.bootstrapcdn.com/bootstrap/3.1.1/css/bootstrap.min.css\"\u003e \u003cscript src=\"https://ajax.googleapis.com/ajax/libs/angularjs/1.2.12/angular.min.js\"\u003e\u003c/script\u003e \u003cscript src=\"controllers.js\"\u003e\u003c/script\u003e \u003cscript src=\"https://cdnjs.cloudflare.com/ajax/libs/angular-ui-bootstrap/0.13.0/ui-bootstrap-tpls.js\"\u003e\u003c/script\u003e \u003c/head\u003e \u003cbody ng-controller=\"RedisCtrl\"\u003e \u003cdiv style=\"width: 50%; margin-left: 20px\"\u003e \u003ch2\u003eGuestbook\u003c/h2\u003e \u003cform\u003e \u003cfieldset\u003e \u003cinput ng-model=\"msg\" placeholder=\"Messages\" class=\"form-control\" type=\"text\" name=\"input\"\u003e\u003cbr\u003e \u003cbutton type=\"button\" class=\"btn btn-primary\" ng-click=\"controller.onRedis()\"\u003eSubmit\u003c/button\u003e \u003c/fieldset\u003e \u003c/form\u003e \u003cdiv\u003e \u003cdiv ng-repeat=\"msg in messages track by $index\"\u003e {{msg}} \u003c/div\u003e \u003c/div\u003e \u003c/div\u003e \u003c/body\u003e \u003c/html\u003e ","date":"2021-10-02","objectID":"/posts/telepresence/:3:1","tags":["k8s"],"title":"Telepresence——本地调试k8s服务利器","uri":"/posts/telepresence/"},{"categories":["探索与实战"],"content":"连接到集群 $ telepresence connect Launching Telepresence Daemon v2.3.2 (api v3) Connecting to traffic manager... Connected to context minikube (https://10.122.101.148:38443) 需要确保kubeconfig的配置，示例中的context连接到的apiserver为10.122.101.148:38443 ","date":"2021-10-02","objectID":"/posts/telepresence/:3:2","tags":["k8s"],"title":"Telepresence——本地调试k8s服务利器","uri":"/posts/telepresence/"},{"categories":["探索与实战"],"content":"服务全量拦截 查看可拦截的服务列表： $ telepresence list frontend : ready to intercept (traffic-agent not yet installed) redis-follower: ready to intercept (traffic-agent not yet installed) redis-leader : ready to intercept (traffic-agent not yet installed) 结果中可以看出有三个service可以拦截，并且都没有安装traffic agent。不过不用担心，我们在进行服务拦截时会自动向pod内注入traffic agent。 拦截frontend留言板服务，拦截前我们先本地18888端口起一个nginx服务。 $ docker run --rm --name nginx-test -p 18888:80 -d nginx:1.21.1 9d514b006d2c386b7d3676bb40d1dafcbf9211ba9737e213e0dac180496c8d3a 验证一下nginx可以正常访问。 $ curl localhost:18888 \u003c!DOCTYPE html\u003e \u003chtml\u003e \u003chead\u003e \u003ctitle\u003eWelcome to nginx!\u003c/title\u003e \u003cstyle\u003e body { width: 35em; margin: 0 auto; font-family: Tahoma, Verdana, Arial, sans-serif; } \u003c/style\u003e \u003c/head\u003e \u003cbody\u003e \u003ch1\u003eWelcome to nginx!\u003c/h1\u003e \u003cp\u003eIf you see this page, the nginx web server is successfully installed and working. Further configuration is required.\u003c/p\u003e \u003cp\u003eFor online documentation and support please refer to \u003ca href=\"http://nginx.org/\"\u003enginx.org\u003c/a\u003e.\u003cbr/\u003e Commercial support is available at \u003ca href=\"http://nginx.com/\"\u003enginx.com\u003c/a\u003e.\u003c/p\u003e \u003cp\u003e\u003cem\u003eThank you for using nginx.\u003c/em\u003e\u003c/p\u003e \u003c/body\u003e \u003c/html\u003e 下面我们来看看如何使用本地的nginx service来拦截集群中的frontend service。其实不过在本地执行一句简单的命令：\u0003 # telepresence intercept \u003cservice-name\u003e --port \u003clocal-port\u003e[:\u003cremote-port\u003e] --env-file \u003cpath-to-env-file\u003e $ telepresence intercept frontend --port 18888:80 --env-file frontend-svc.env Using Deployment frontend intercepted Intercept name : frontend State : ACTIVE Workload kind : Deployment Destination : 127.0.0.1:18888 Service Port Identifier: 80 Volume Mount Error : sshfs is not installed on your local machine Intercepting : all TCP connections 这样，我们便将对frontend:80的访问就会被转发到localhost:18888，即访问到的是nginx服务。验证一下： curl 10.122.101.148:12180 | head -5 \u003c!DOCTYPE html\u003e \u003chtml\u003e \u003chead\u003e \u003ctitle\u003eWelcome to nginx!\u003c/title\u003e \u003cstyle\u003e 使用telepresence cli可以查看到服务的拦截状态： $ telepresence list frontend : intercepted Intercept name : frontend State : ACTIVE Workload kind : Deployment Destination : 127.0.0.1:18888 Service Port Identifier: 80 Intercepting : all TCP connections redis-follower: ready to intercept (traffic-agent not yet installed) redis-leader : ready to intercept (traffic-agent not yet installed) 此外，frontend service的endpoints也从80端口（frontend container）切换到了9900端口（traffic agent）。这意味着pod内访问9900端口（traffic agent）会经由traffic manager转发到本地nginx服务中。 $ kubectl describe svc frontend Name: frontend Namespace: default Labels: app=guestbook tier=frontend Annotations: telepresence.getambassador.io/actions: {\"version\":\"2.3.2\",\"make_port_symbolic\":{\"PortName\":\"\",\"TargetPort\":80,\"SymbolicName\":\"tx-80\"}} Selector: app=guestbook,tier=frontend Type: ClusterIP IP Family Policy: SingleStack IP Families: IPv4 IP: 10.111.60.121 IPs: 10.111.60.121 Port: \u003cunset\u003e 80/TCP TargetPort: tx-80/TCP Endpoints: 172.18.0.2:9900,172.18.0.7:9900,172.18.0.8:9900 # 端口从80切换到了9900 Session Affinity: None Events: \u003cnone\u003e 信息 上面提及到在执行telepresence intercept时会自动注入traffic agent这个sidecar，可以观察一下frontend svc对应的endpoint pod的信息。 $ kubectl get pod NAME READY STATUS RESTARTS AGE frontend-698684655-bfd2l 2/2 Running 0 7m50s frontend-698684655-ddh4c 2/2 Running 0 7m54s frontend-698684655-zvnmg 2/2 Running 0 7m47s redis-follower-dd4df4648-pvd2c 1/1 Running 5 50d redis-follower-dd4df4648-wzf54 1/1 Running 5 50d redis-leader-6d7765b8f6-mbzm8 1/1 Running 5 50d $ kubectl describe pod frontend-698684655-bfd2l Name: frontend-698684655-bfd2l Namespace: default ...... Containers: php-redis: Image: gcr.io/google_samples/gb-frontend:v5 Port: 80/TCP .... traffic-agent: Image: docker.io/datawire/tel2:2.3.2 Port: 9900/TCP ... ...... ","date":"2021-10-02","objectID":"/posts/telepresence/:3:3","tags":["k8s"],"title":"Telepresence——本地调试k8s服务利器","uri":"/posts/telepresence/"},{"categories":["探索与实战"],"content":"拦截Preview URL 一般在开发环境中，会有多个开发人员协同工作。上述的拦截方案的最大问题是traffic agent无脑将请求全部转发给traffic manger，从而将流量全部转发到本地。这势必会造成对其他开发人员的影响，因此我们需要能够在不影响其他人的情况下进行拦截调试。实现上利用了context 传递来实现可控的拦截，借助Ambassador Cloud的preview URL给我们提供了可控拦截的能力。 Preview URL需要与ingress配合使用，所以第一步我们先创建一个ingress： $ cat ingress.yaml apiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: demo-ingress annotations: nginx.ingress.kubernetes.io/rewrite-target: /$1 spec: rules: - host: frontend.raygecao.com http: paths: - path: / pathType: Prefix backend: service: name: frontend port: number: 80 $ kubectl apply -f ingress.yaml $ kubectl describe ing demo-ingress Name: demo-ingress Namespace: default Address: 172.17.0.40 Default backend: default-http-backend:80 (\u003cerror: endpoints \"default-http-backend\" not found\u003e) Rules: Host Path Backends ---- ---- -------- frontend.raygecao.com / frontend:80 (172.18.0.2:9900,172.18.0.7:9900,172.18.0.8:9900) Annotations: nginx.ingress.kubernetes.io/rewrite-target: /$1 Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal UPDATE 3m54s (x2 over 20d) nginx-ingress-controller Ingress default/demo-ingress 然后我们清理掉之前的拦截。 $ telepresence leave frontend $ telepresence list frontend : ready to intercept (traffic-agent already installed) redis-follower: ready to intercept (traffic-agent not yet installed) redis-leader : ready to intercept (traffic-agent not yet installed) 注册并登陆Ambassador Cloud，然后重新进行拦截： $ telepresence intercept frontend --port 18888:80 --env-file frontend-svc.env To create a preview URL, telepresence needs to know how cluster ingress works for this service. Please Confirm the ingress to use. 1/4: What's your ingress' layer 3 (IP) address? You may use an IP address or a DNS name (this is usually a \"service.namespace\" DNS name). [default: 10.122.101.148]: 2/4: What's your ingress' layer 4 address (TCP port number)? [default: 9999]: 3/4: Does that TCP port on your ingress use TLS (as opposed to cleartext)? [default: n]: 4/4: If required by your ingress, specify a different layer 5 hostname (TLS-SNI, HTTP \"Host\" header) to access this service. [default: frontend.raygecao.com]: Using Deployment frontend intercepted Intercept name : frontend State : ACTIVE Workload kind : Deployment Destination : 127.0.0.1:18888 Service Port Identifier: 80 Volume Mount Error : sshfs is not installed on your local machine Intercepting : HTTP requests that match all headers: 'x-telepresence-intercept-id: 2da7518d-ce3f-4732-9c02-f144de3443a8:frontend' Preview URL : https://musing-kirch-7616.preview.edgestack.me Layer 5 Hostname : frontend.raygecao.com 注意 由于之前拦截时配置过一次，因此这一次一路默认就好，第一次配置需要结合自身的ingress来配置。 为了使hostname可以访问到集群内的服务，需要手动添加一条DNS记录将hostname resolve到ingress节点上（即在hosts文件中添加一条172.17.0.40 frontend.raygecao.com）。或者利用ingress路由请求的原理，直接将hostname指定到Hostheader进行路由。 可以看到，Ambassador Cloud为我们生成了一个preview URL https://musing-kirch-7616.preview.edgestack.me，并且添加了转发规则：所有包含'x-telepresence-intercept-id: 2da7518d-ce3f-4732-9c02-f144de3443a8:frontend'header并且host是frontend.raygecao.com的request会被本地nginx服务拦截。 Ambassador Cloud进行服务拦截管理\" Ambassador Cloud进行服务拦截管理 从效果上看，添加了这种特殊的header，就会将流量导到preview URL上，这正是ambassador cloud给予我们的便利。我们验证一下具体的拦截情况。 # 正常的请求不会被本地的nginx服务拦截 $ curl 10.122.101.148:9999 -H 'Host: frontend.raygecao.com' | head -5 \u003chtml ng-app=\"redis\"\u003e \u003chead\u003e \u003ctitle\u003eGuestbook\u003c/title\u003e \u003clink rel=\"stylesheet\" href=\"//netdna.bootstrapcdn.com/bootstrap/3.1.1/css/bootstrap.min.css\"\u003e \u003cscript src=\"https://ajax.googleapis.com/ajax/libs/angularjs/1.2.12/angular.min.js\"\u003e\u003c/script\u003e # 添加header会被转发到preview URL中 $ curl 10.122.101.148:9999 -H 'Host: frontend.raygecao.com' -H 'x-telepresence-intercept-id: 2da7518d-ce3f-4732-9c02-f144de3443a8:frontend' | head -5 \u003c!DOCTYPE html\u003e \u003chtml\u003e \u003chead\u003e \u003ctitle\u003eWelcome to nginx!\u003c/title\u003e \u003cstyle\u003e ","date":"2021-10-02","objectID":"/posts/telepresence/:3:4","tags":["k8s"],"title":"Telepresence——本地调试k8s服务利器","uri":"/posts/telepresence/"},{"categories":["探索与实战"],"content":"参考文献 Telepresence官方文档 ","date":"2021-10-02","objectID":"/posts/telepresence/:4:0","tags":["k8s"],"title":"Telepresence——本地调试k8s服务利器","uri":"/posts/telepresence/"},{"categories":["探索与实战"],"content":"通过隔离namespace与cgroup构建出一个小型容器，项目来源：containers-from-scratch ","date":"2021-09-27","objectID":"/posts/container-from-scratch/:0:0","tags":["container"],"title":"Containers from scratch探究","uri":"/posts/container-from-scratch/"},{"categories":["探索与实战"],"content":"概述 本项目以几十行代码搭建起了一个最简单的container，包含如下特点： Mount namespace隔离，通过chroot将container的文件系统隔离到宿主机的单个目录层次结构中。 Pid namespace隔离，保证container与host的pid相互独立。 使用独立的cgroup限制容器内的资源使用。 ","date":"2021-09-27","objectID":"/posts/container-from-scratch/:1:0","tags":["container"],"title":"Containers from scratch探究","uri":"/posts/container-from-scratch/"},{"categories":["探索与实战"],"content":"代码分析 package main import ( \"fmt\" \"io/ioutil\" \"os\" \"os/exec\" \"path/filepath\" \"strconv\" \"syscall\" ) // go run main.go run \u003ccmd\u003e \u003cargs\u003e func main() { switch os.Args[1] { case \"run\": run() case \"child\": child() default: panic(\"help\") } } func run() { fmt.Printf(\"Running %v \\n\", os.Args[2:]) cmd := exec.Command(\"/proc/self/exe\", append([]string{\"child\"}, os.Args[2:]...)...) cmd.Stdin = os.Stdin cmd.Stdout = os.Stdout cmd.Stderr = os.Stderr cmd.SysProcAttr = \u0026syscall.SysProcAttr{ Cloneflags: syscall.CLONE_NEWUTS | syscall.CLONE_NEWPID | syscall.CLONE_NEWNS, Unshareflags: syscall.CLONE_NEWNS, } must(cmd.Run()) } func child() { fmt.Printf(\"Running %v \\n\", os.Args[2:]) cg() cmd := exec.Command(os.Args[2], os.Args[3:]...) cmd.Stdin = os.Stdin cmd.Stdout = os.Stdout cmd.Stderr = os.Stderr must(syscall.Sethostname([]byte(\"container\"))) must(syscall.Chroot(\"/home/liz/ubuntufs\")) must(os.Chdir(\"/\")) must(syscall.Mount(\"proc\", \"proc\", \"proc\", 0, \"\")) must(syscall.Mount(\"thing\", \"mytemp\", \"tmpfs\", 0, \"\")) must(cmd.Run()) must(syscall.Unmount(\"proc\", 0)) must(syscall.Unmount(\"thing\", 0)) } func cg() { cgroups := \"/sys/fs/cgroup/\" pids := filepath.Join(cgroups, \"pids\") os.Mkdir(filepath.Join(pids, \"liz\"), 0755) must(ioutil.WriteFile(filepath.Join(pids, \"liz/pids.max\"), []byte(\"20\"), 0700)) // Removes the new cgroup in place after the container exits must(ioutil.WriteFile(filepath.Join(pids, \"liz/notify_on_release\"), []byte(\"1\"), 0700)) must(ioutil.WriteFile(filepath.Join(pids, \"liz/cgroup.procs\"), []byte(strconv.Itoa(os.Getpid())), 0700)) } func must(err error) { if err != nil { panic(err) } } run函数中主要有两个工作： Fork出子进程并调用child函数：/proc/self/exe 表明当前的程序，即fork出一份子进程执行当前程序的child命令。 设置Clone隔离属性：Cloneflags通过设置syscall.CLONE_NEWUTS,syscall.CLONE_NEWPID,syscall.CLONE_NEWNS分别隔离了uts, pid及mount namespace。Unshareflags设置了syscall.CLONE_NEWNS用以禁用挂载传播。 child函数中主要做了四件事： 为子进程设置cgroup，设置当前cgroup总的进程数上限为20。 更新子进程的hostname，用以验证uts namespace隔离。 更新子进程的root目录，将container文件系统隔离到宿主机中的单个目录中。 挂载proc及tmpfs，用以验证pid隔离以及mount隔离。 ","date":"2021-09-27","objectID":"/posts/container-from-scratch/:2:0","tags":["container"],"title":"Containers from scratch探究","uri":"/posts/container-from-scratch/"},{"categories":["探索与实战"],"content":"视频讲解 视频基本上将代码的核心模块全部手敲了一遍，核心内容解释的较为清晰，但存在如下问题： 视频中run方法中并未设置cmd.SysProcAttr.Unshareflags=syscall.CLONE_NEWNS，在实践中发现，未指定此flag会导致容器内的挂载会泄露到宿主机上，这与挂载传播相关，笔者系统上默认使用shared传播类型，猜测Liz的系统默认使用private传播类型。 视频中在Liz退出容器时会触发panic，报错内容为No such file or directory，探索后发现是在第59行卸载thing时出错，看一下syscall关系Mount和Unmount的api： func Mount(source string, target string, fstype string, flags uintptr, data string) (err error) func Unmount(target string, flags int) (err error) 尽管umount命令支持使用设备文件或者挂载点，但从报错信息及syscall api上看到，比较稳妥的方式是通过挂载点卸载，因此Line:59建议改成must(syscall.Unmount(\"mytemp\", 0))。 ","date":"2021-09-27","objectID":"/posts/container-from-scratch/:3:0","tags":["container"],"title":"Containers from scratch探究","uri":"/posts/container-from-scratch/"},{"categories":["探索与实战"],"content":"实践探究 ","date":"2021-09-27","objectID":"/posts/container-from-scratch/:4:0","tags":["container"],"title":"Containers from scratch探究","uri":"/posts/container-from-scratch/"},{"categories":["探索与实战"],"content":"准备ubuntufs 实现所需的ubuntufs是container的rootfs，为其提供必要的指令。笔者采用从ubuntu container中将整个文件系统拷贝出来。 docker run -it --rm ubuntu:21.04 docker cp ${UBUNTU_IMAGE_ID}:/ ~/ubuntufs 准备完需要更新Line:51chroot的path为ubuntufs所在的路径。 ","date":"2021-09-27","objectID":"/posts/container-from-scratch/:4:1","tags":["container"],"title":"Containers from scratch探究","uri":"/posts/container-from-scratch/"},{"categories":["探索与实战"],"content":"运行容器并验证namespace隔离情况 # 容器内 root@container:/# ls -l /proc/self/ns/ total 0 lrwxrwxrwx 1 root root 0 Sep 24 05:57 cgroup -\u003e 'cgroup:[4026531835]' lrwxrwxrwx 1 root root 0 Sep 24 05:57 ipc -\u003e 'ipc:[4026531839]' lrwxrwxrwx 1 root root 0 Sep 24 05:57 mnt -\u003e 'mnt:[4026536295]' lrwxrwxrwx 1 root root 0 Sep 24 05:57 net -\u003e 'net:[4026531969]' lrwxrwxrwx 1 root root 0 Sep 24 05:57 pid -\u003e 'pid:[4026536294]' lrwxrwxrwx 1 root root 0 Sep 24 05:57 user -\u003e 'user:[4026531837]' lrwxrwxrwx 1 root root 0 Sep 24 05:57 uts -\u003e 'uts:[4026536293]' # host $ ll /proc/self/ns total 0 lrwxrwxrwx 1 ubuntu ubuntu 0 Sep 24 13:57 cgroup -\u003e cgroup:[4026531835] lrwxrwxrwx 1 ubuntu ubuntu 0 Sep 24 13:57 ipc -\u003e ipc:[4026531839] lrwxrwxrwx 1 ubuntu ubuntu 0 Sep 24 13:57 mnt -\u003e mnt:[4026531840] lrwxrwxrwx 1 ubuntu ubuntu 0 Sep 24 13:57 net -\u003e net:[4026531969] lrwxrwxrwx 1 ubuntu ubuntu 0 Sep 24 13:57 pid -\u003e pid:[4026531836] lrwxrwxrwx 1 ubuntu ubuntu 0 Sep 24 13:57 user -\u003e user:[4026531837] lrwxrwxrwx 1 ubuntu ubuntu 0 Sep 24 13:57 uts -\u003e uts:[4026531838] 由此可知，container内的mnt, pid, uts namespace与host的均不同。 ","date":"2021-09-27","objectID":"/posts/container-from-scratch/:4:2","tags":["container"],"title":"Containers from scratch探究","uri":"/posts/container-from-scratch/"},{"categories":["探索与实战"],"content":"验证Cgourp设置 Cgroups的设置也生效，在后台起若干个sleep进程后，新起的进程被cgroup限制了。 Cgroup限制最大进程数\" Cgroup限制最大进程数 Liz在测试时使用了fork bomb :(){ :|:\u0026 };:，这种形式本质上是shell实现的一个自身指数递归调用，其简化形式为： bomb() { bomb | bomb \u0026 }; bomb :()定义了一个名字叫:的函数。 {}声明了函数体。 :|:表示函数递归调用并pipe到自身，从而实现进程数指数增长。 \u0026表示进程在后台运行。 ;表示函数调用结束。 :运行此函数，触发fork bomb。 ","date":"2021-09-27","objectID":"/posts/container-from-scratch/:4:3","tags":["container"],"title":"Containers from scratch探究","uri":"/posts/container-from-scratch/"},{"categories":["探索与实战"],"content":"功能扩展 ","date":"2021-09-27","objectID":"/posts/container-from-scratch/:5:0","tags":["container"],"title":"Containers from scratch探究","uri":"/posts/container-from-scratch/"},{"categories":["探索与实战"],"content":"支持bind mount Bind mount将宿主目录映射到容器内，实现上比较简单，即在chroot jail前进行bind即可。示例代码如下： // bind mount testBindPath := filepath.Join(rootPath, \"test\") os.Mkdir(testBindPath, 0755) must(syscall.Mount(fmt.Sprintf(\"%s/test\", homePath), testBindPath, \"\", syscall.MS_BIND, \"\")) 上例将家目录下的test目录bind mount到rootfs的test目录，从而在容器内部可见。 ","date":"2021-09-27","objectID":"/posts/container-from-scratch/:5:1","tags":["container"],"title":"Containers from scratch探究","uri":"/posts/container-from-scratch/"},{"categories":["探索与实战"],"content":"Cgroup资源扩展（Memory/CPU） 在memory和cpu下创建两个cgroup，设置好限制内容，并将container pid加入到这两个cgroup中： // Add cpu limitation for 0.3 core cpu := filepath.Join(cgroups, \"cpu\") os.Mkdir(filepath.Join(cpu, \"liz\"), 0755) must(ioutil.WriteFile(filepath.Join(cpu, \"liz/cpu.cfs_period_us\"), []byte(\"100000\"), 0700)) must(ioutil.WriteFile(filepath.Join(cpu, \"liz/cpu.cfs_quota_us\"), []byte(\"30000\"), 0700)) must(ioutil.WriteFile(filepath.Join(cpu, \"liz/notify_on_release\"), []byte(\"1\"), 0700)) must(ioutil.WriteFile(filepath.Join(cpu, \"liz/cgroup.procs\"), []byte(strconv.Itoa(os.Getpid())), 0700)) // Add memory limitation for 100M mem := filepath.Join(cgroups, \"memory\") os.Mkdir(filepath.Join(mem, \"liz\"), 0755) must(ioutil.WriteFile(filepath.Join(mem, \"liz/memory.limit_in_bytes\"), []byte(\"100M\"), 0700)) must(ioutil.WriteFile(filepath.Join(mem, \"liz/memory.swappiness\"), []byte(\"0\"), 0700)) must(ioutil.WriteFile(filepath.Join(mem, \"liz/notify_on_release\"), []byte(\"1\"), 0700)) must(ioutil.WriteFile(filepath.Join(mem, \"liz/cgroup.procs\"), []byte(strconv.Itoa(os.Getpid())), 0700)) 上例分别对cpu与memory进行了限制： CPU: 限制container最大使用核数为0.3 Memory: 限制物理内存上限为100M，且禁用swap，即内容使用超过了100M的话立刻触发OOM。 验证cgroup隔离效果： root@container:/# cat /proc/self/cgroup 12:perf_event:/ 11:cpuset:/ 10:devices:/user.slice 9:net_cls,net_prio:/ 8:pids:/liz 7:blkio:/user.slice 6:memory:/liz 5:rdma:/ 4:hugetlb:/ 3:freezer:/ 2:cpu,cpuacct:/liz 1:name=systemd:/user.slice/user-1000.slice/session-12.scope 0::/user.slice/user-1000.slice/session-12.scope 使用while : ; do : ; done 压测cpu limitation： CPU使用被限制在0.3Core\" CPU使用被限制在0.3Core 验证memory limitation： 分配400M内存导致OOM\" 分配400M内存导致OOM ","date":"2021-09-27","objectID":"/posts/container-from-scratch/:5:2","tags":["container"],"title":"Containers from scratch探究","uri":"/posts/container-from-scratch/"},{"categories":["探索与实战"],"content":"使用pivot_root系统调用替换chroot pivot_root与chroot作用类似，都是将rootfs jail到一个目录上。区别在于前者更改此mount namespace下的所有进程的rootfs，后者仅更改当前进程的rootfs。 pivot_root核心思想是将root mount更改为new_root，并且原root mount会移到put_old中。其定义了一系列限制，列举如下： - new_root and put_old must be directories. - new_root and put_old must not be on the same mount as the current root. - put_old must be at or underneath new_root; that is, adding some nonnegative number of \"/..\" prefixes to the pathname pointed to by put_old must yield the same directory as new_root. - new_root must be a path to a mount point, but can't be \"/\". A path that is not already a mount point can be con‐ verted into one by bind mounting the path onto itself. - The propagation type of the parent mount of new_root and the parent mount of the current root directory must not be MS_SHARED; similarly, if put_old is an existing mount point, its propagation type must not be MS_SHARED. These re‐ strictions ensure that pivot_root() never propagates any changes to another mount namespace. - The current root directory must be a mount point. 参考 runc pivotRoot func 对代码进行修改： must(syscall.Mount(rootPath, rootPath, \"bind\", syscall.MS_BIND, \"\")) // jail rootfs with pivot_root syscall // ref: https://github.com/opencontainers/runc/blob/v1.0.2/libcontainer/rootfs_linux.go#L817 putOldPath := filepath.Join(rootPath, \"put_old\") os.Mkdir(putOldPath, 0755) must(syscall.PivotRoot(rootPath, putOldPath)) // lazy unmount must(syscall.Unmount(\"/put_old\", syscall.MNT_DETACH)) if err := os.Remove(\"/put_old\"); err != nil{ panic(err) } //must(syscall.Chroot(\"fmt.Sprintf(\"%s/ubuntufs\", homePath)) must(os.Chdir(\"/\")) 为满足第二条限制，new_root以bind mount形式脱离current root filesystem。 由于存在process使用原root mount下的文件，因此无法直接unmount掉put_old。这里使用lazy unmount（通过syscall.MNT_DETACH flag）的方式卸载掉。Lazy unmount使新的进程看不到此挂载点（隐藏掉），并且当接入此mount的进程全部退出后将其真正卸载掉。 注意 上述扩展的完整代码参考这里。 ","date":"2021-09-27","objectID":"/posts/container-from-scratch/:5:3","tags":["container"],"title":"Containers from scratch探究","uri":"/posts/container-from-scratch/"},{"categories":["探索与实战"],"content":"知识延伸 为探究Line:34 Unshareflags对挂载的影响，我们了解一下挂载传播。 ","date":"2021-09-27","objectID":"/posts/container-from-scratch/:6:0","tags":["container"],"title":"Containers from scratch探究","uri":"/posts/container-from-scratch/"},{"categories":["探索与实战"],"content":"挂载传播 Mount namespace有时会因提供太强的隔离性导致便捷性降低的问题，比如将一个新磁盘加载到一个光驱驱动器中，当有多个mount namespace时，需要将该磁盘挂载到每个namespace中。为了只使用一次挂载命令就可以将磁盘挂载到所有的mount namespace，Linux 从2.6.15起引入了共享子树特性（Shared Subtrees），即允许在namespace之间自动、可控地传播挂载和卸载事件。 此特性下，每个挂载点都有一个传播类型，此类型决定在此挂载点下创建/删除的挂载点能否传播到其他挂载点下，传播类型有如下四种： 传播类型 作用 MS_SHARED 该挂载点下同一对等组中的挂载点双向共享挂载和卸载事件 MS_SLAVE 该挂载点下同一对等组中的主挂载点可以将挂载或卸载事件单向传播到从属挂载点 MS_PRIVATE 挂载点不会将事件传播给任何对等方，同时也不会接收事件 MS_UNBINDABLE 在MS_PRIVATE基础上不能作为绑定挂载操作的源 判断挂载点的默认类型基本方法如下： 如果挂载点非根挂载点，且其父节点传播类型是MS_SHARED，则新挂载点的传播类型也是MS_SHARED。 否则挂载点的传播类型是MS_PRIVATE。 有了这个概念，我们验证一下这个Unshareflag加与不加的区别： 添加Unshareflags： # 容器中 root@container:/# cat /proc/self/mountinfo 4153 4751 0:610 / /proc rw,relatime - proc proc rw 4223 4751 0:642 / /mytemp rw,relatime - tmpfs thing rw 未添加Unshareflags： # 容器中 root@container:/# cat /proc/self/mountinfo 4750 4223 0:610 / /proc rw,relatime shared:304 - proc proc rw 4753 4223 0:642 / /mytemp rw,relatime shared:312 - tmpfs thing rw # 容器外 $ cat /proc/self/mountinfo | grep ubuntufs 4751 25 0:610 / ~/ubuntufs/proc rw,relatime shared:304 - proc proc rw 4754 25 0:642 / ~/ubuntufs/mytemp rw,relatime shared:312 - tmpfs thing rw 由于实验系统根挂载点是MS_SHARED类型，新建子挂载点的默认类型为MS_SHARED，因此container内的挂载会共享到host。 解决办法有两种: 如代码展示那样，加入Unshareflags=syscall.CLONE_NEWNS 参考 issue-38471。 指定根挂载为MS_PRIVATE类型，如must(syscall.Mount(\"\", \"/\", \"\", syscall.MS_PRIVATE|syscall.MS_REC, \"\"))。 ","date":"2021-09-27","objectID":"/posts/container-from-scratch/:6:1","tags":["container"],"title":"Containers from scratch探究","uri":"/posts/container-from-scratch/"},{"categories":["探索与实战"],"content":"Unshare Linux unshare 指令可以新建namespace，并在namespace中运行程序，支持的命名空间类型有： Mount namespace，默认使用private传播类型。 UTS namespace IPC namespace Network namespace Pid namespace User namespace 欲达到上述的隔离效果，可以通过如下命令来进行： $ sudo unshare --fork --pid --mount-proc --uts /bin/bash --pid声明了pid namespace隔离。 --mount-proc挂载了proc，并声明了mount namespace隔离。 --uts声明了uts namespace隔离。 ","date":"2021-09-27","objectID":"/posts/container-from-scratch/:6:2","tags":["container"],"title":"Containers from scratch探究","uri":"/posts/container-from-scratch/"},{"categories":["探索与实战"],"content":"参考文献 containers-from-scratch 挂载命名空间和共享子树 unshare(1) ","date":"2021-09-27","objectID":"/posts/container-from-scratch/:7:0","tags":["container"],"title":"Containers from scratch探究","uri":"/posts/container-from-scratch/"},{"categories":["探索与实战"],"content":"私有化交付的三要求：可复现性，易操作性和易维护性。 ","date":"2021-08-26","objectID":"/posts/oras/:0:0","tags":["container"],"title":"私有化交付下的应用打包方案","uri":"/posts/oras/"},{"categories":["探索与实战"],"content":"私有化交付 公有云交付和私有化交付是ToB服务交付两种重要手段。公有云交付成本较低，数据安全性及性能的要求不需要太高，通常允许连接外网；而私有化交付一定程度上避免的资源的复用与共享，成本较高，但数据安全性高，适合数据敏感度高的企业，这些企业中大部分不允许连接外网。综上，私有化交付在数据安全很高的事业单位、银行及政府部门中占据主导地位。 私有化交付的一个重要的应用场景是如何将一组服务部署到与外部隔绝的内网环境，这也是我们今天研究的主题。本文不深入探究平台等基建是如何bootstrap出来，毕竟这个topic要溯源的话甚至要问一问服务器是哪来的。我们更专注于应用的打包方案。 显然，在网络受限的环境下，应用相关的所有资源都只能通过人肉搬运。下面的模式是私有化交付场景下常见的模式。 传统私有化交付方案\" 传统私有化交付方案 ","date":"2021-08-26","objectID":"/posts/oras/:1:0","tags":["container"],"title":"私有化交付下的应用打包方案","uri":"/posts/oras/"},{"categories":["探索与实战"],"content":"一个应用部署需要啥？ 镜像：容器化是私有化交付的关键，而容器化中最重要的组成就是image，image在服务部署中是不可或缺的。 编排文件与配置信息（应用包）：私有化交付的特点是允许较高程度上的定制：不同私有化集群受节点数目、资源条件、特殊需求等因素，对服务的配置有着不同的需求。为了尽可能地自动化，将编排及默认配置打包在应用中是不错的选择，其中比较经典的例子是helm chart。编排及配置相当于应用管理工具包，有了它可以便于部署的自动化，但并不像image那么刚需。 数据包：应用中的部分服务可能会依赖于某些数据包，如算法模型、调试工具包等。服务相关的附属物件的都可以认为是一种数据包。是否需要数据包是具体服务确定的。 打包应用，无外乎将应用所需的上述的所有组件pack起来带到现场进行部署。 ","date":"2021-08-26","objectID":"/posts/oras/:2:0","tags":["container"],"title":"私有化交付下的应用打包方案","uri":"/posts/oras/"},{"categories":["探索与实战"],"content":"当前交付方案 镜像/编排/数据包各自有着不同的发布流程，并且各自的发布中心独立，比如： 镜像的发布中心可以是docker registry。 编排包的发布中心可以是chart museum。 数据包的发布中心可以是某个s3。 为保证系统的可复现性，意味着现场环境也需要mirror这些infra，结构大致如下： 当前mirror方案\" 当前mirror方案 这个架构存在两个痛点： 发布中心分散，无法进行统一管理，增加维护成本。 公网中将各个组件打成一个tar包，隔离性太强，很多版本的image/数据包没有变化，存在同一组件打包多份的情况。这增加了打包时长，浪费公网存储资源。 ","date":"2021-08-26","objectID":"/posts/oras/:3:0","tags":["container"],"title":"私有化交付下的应用打包方案","uri":"/posts/oras/"},{"categories":["探索与实战"],"content":"优化方向 ","date":"2021-08-26","objectID":"/posts/oras/:4:0","tags":["container"],"title":"私有化交付下的应用打包方案","uri":"/posts/oras/"},{"categories":["探索与实战"],"content":"统一制品仓库 为解决第一个问题，我们考虑是否可以将这些发布中心归拢在一起。我们把上面提及的镜像，应用包及数据包统一描述为制品（artifact），我们需要一个统一制品仓库来实现这些制品的发布。而OCI registry是个不错的选择，理由是： OCI registry即满足OCI Distribution Spec的registry，很多开源产品实现了此规范，如docker registry, harbor, nexus等。灵活性较强，可以根据发布规模、运维需求等因素灵活选型。 OCI registry天然支持docker image的发布。上述制品中，只有image的发布最为复杂，OCI Image Format Spec里定义的镜像格式是基于content-addressed的，而一般的存储系统都是location-addressed，使用registry统一制品会相对简单一些。 普通制品使用OCI registry存储已存在开源的解决方案oras (OCI registry as storage)，可以方便地实现content-addressable 特性。 ","date":"2021-08-26","objectID":"/posts/oras/:4:1","tags":["container"],"title":"私有化交付下的应用打包方案","uri":"/posts/oras/"},{"categories":["探索与实战"],"content":"公网发布中心改造 公网发布中心面临的最大问题就是存储空间的浪费。由于不同应用间以及同一应用各版本均为彼此隔离地打包上传，这导致了公网发布中心无法对内容做任何复用，经常一份镜像要重复打包成百上千次（比如ubuntu 这种base image），极大的浪费了存储空间。 一个显而易见的优化方向是将公网发布中心向着OCI registry方向改造，这样很多content可以被复用，这会带来一系列的好处： 节省了大量存储空间。 利用layer cache可以节省打包上传的时间。 可以增加layer粒度的diff机制，用户在公网下在新版本的应用时，只需要下载对应的patch即可，提升交付效率。 技巧 如果公网也是OCI registry，那么包的上传就有点类似于docker push，当上传的layer在registry已存在时，对应的blob将不会重复上传。只有新增的layer blob会被上传，形式上类似于增加了一层layer cache。 ","date":"2021-08-26","objectID":"/posts/oras/:4:2","tags":["container"],"title":"私有化交付下的应用打包方案","uri":"/posts/oras/"},{"categories":["探索与实战"],"content":"增量发布 如果app bundle尺寸很大的话，会对交付效率带来较大的影响。 下载应用包耗时较长。 应用包占用的存储空间较大，并且应用包的跨网离线拷贝耗时较长。 现场环境加载应用包耗时较长。 交付效率 交付效率并没有一个官方的定义，我们这里姑且用将一个应用从公司内网环境mirror到现场环境并成功部署所耗费的时间来表述。增量发布只会影响mirror的效率，对部署效率不会有影响。 初次交付时，这一问题无法避免，因为这时现场是个空的registry，需要mirror应用所需的所有artifacts。但是如果现场因新需求或bugfix等原因需要升级时，就不需要mirror另一个版本的全部content了。我们可以对这两个版本的bundle进行diff，生成一个补丁包来承载新版本存在，但老版本不存在的blob集合。如下图所示，app从v1.0.0升级到v1.0.1仅需要将M2与L4打到补丁包里即可，即其复用了就版本的L1与L2两个blob。 app v1.0.1基于v1.0.0版本的patch\" app v1.0.1基于v1.0.0版本的patch 增量发布对于小版本bugfix效率很高，改动越小，可以复用的layer越多，补丁包就越小，交付效率也就越高。 ","date":"2021-08-26","objectID":"/posts/oras/:4:3","tags":["container"],"title":"私有化交付下的应用打包方案","uri":"/posts/oras/"},{"categories":["探索与实战"],"content":"优化方案 ","date":"2021-08-26","objectID":"/posts/oras/:5:0","tags":["container"],"title":"私有化交付下的应用打包方案","uri":"/posts/oras/"},{"categories":["探索与实战"],"content":"现有开源项目参考 ORAS：使用OCI registry存储artifacts。 可以将若干文件以layer的方式存到某个repository下。 push操作只能实现一层关联，即manifest =\u003e layers+config。 依赖特定annotation，无法与docker image兼容，即无法pull出docker image。 crane: 与registry交互的go lib。 基本封装了OCI Distribution Spec。 与image format绑定较深，对OCI Artifacts支持不完善，尤其是对index的支持。 cnab-to-oci：使用OCI registry来发布应用包（application bundle），其引入了打包的概念，将若干Image打包成一个bundle，并在registry中流转。 突出了app bundle的概念，便于应用整体的管理。 与Docker Image Format Spec强绑定，底层调用moby sdk，无法支持通用的artifacts。 helm registry：chart 支持基于OCI registry的发布。 local cache以OCI image-layout结构组织，content addressable \u0026 location addressable。 与registry的交互必须依赖于local cache。 同样仅支持两层镜像结构 containered 一个容器运行时的标准，其中imagespkg包含对OCI image format的处理，remotespkg包含与registry交互的底层sdk。 兼容全部的OCI Spec。 封装度低，对image的处理十分通用，不局限于docker image。 ","date":"2021-08-26","objectID":"/posts/oras/:5:1","tags":["container"],"title":"私有化交付下的应用打包方案","uri":"/posts/oras/"},{"categories":["探索与实战"],"content":"组织结构 打包操作无非是将若干的artifacts包在一起，并给其一个用于定位的reference（包名），而其对偶的拆包操作就是根据包名能获取到所有artifacts。 cnab给我们提供一个很好的组织方式的参考，bundle reference作为检索的入口，可以关联到所有的artifacts，形式上就类似于一个image index与image manifest之间的关系。 cnab’s bundle format in OCI registry\" cnab’s bundle format in OCI registry 简化一下组织结构，本质上就是一棵多叉树。 bundle组织结构\" bundle组织结构 ","date":"2021-08-26","objectID":"/posts/oras/:5:2","tags":["container"],"title":"私有化交付下的应用打包方案","uri":"/posts/oras/"},{"categories":["探索与实战"],"content":"实践探索 我们以一个具体的例子来简化一下我们要解决的问题：我们如何使用helm在私有化k8s集群中部署起来一个nginx服务。我们要做的是将helm chart与image发布并打包，在现场环境中导入这些artifacts。 结合oras, crane与containerd sdk开发一个小工具cb，提供如下核心功能 cmd 作用 实现要点 push 上传普通制品（非docker image） 对oras.Push做简单封装 pull 下载普通制品，是push的对偶操作 对oras.Pull做简单封装 bundle 打包生成bundle，将一组制品关联起来 生成index索引artifact list，并将index及artifacts push到registry中特定的repository里 pack 将registry中的bundle保存到本地 以OCI image-layout的形式存储上述结构，相关的reference通过特殊的annotation记录在index.json中 load 从OCI image-layout中恢复bundle 加载OCI image-layout中的index.json并将关联的content及reference push到registry diff 比较并产生target reference相对source reference的patch包 形式仍以OCI image-layout存在，只是blobs与index.json中存在的是两个ref之间的diff，而非全量的引用关系。一般来讲，diff产生的patch包，脱离了source reference是无法加载的 patch 加载patch包 Provider需要结合source reference与patch包构建完整target reference。另外patch包里记录source与target是一个不错的选择 此外cb还wrap了crane的manifest，catalog及list 功能，另外结合了go-graphviz实现了OCI layer可视化功能。 ","date":"2021-08-26","objectID":"/posts/oras/:6:0","tags":["container"],"title":"私有化交付下的应用打包方案","uri":"/posts/oras/"},{"categories":["探索与实战"],"content":"准备阶段 在本地起一个docker registry（确保registry是干净的），并添加dns myregistry。 在docker hub上下载ubuntu:21.04和nginx:1.21.1，以及使用helm create创建默认的nginx chart。 ","date":"2021-08-26","objectID":"/posts/oras/:6:1","tags":["container"],"title":"私有化交付下的应用打包方案","uri":"/posts/oras/"},{"categories":["探索与实战"],"content":"上传制品 # push chart $ cb push myregistry:5000/nginx-chart:1.0.0 --files mychart # push nginx image $ docker tag nginx:1.21.1 myregistry:5000/nginx:1.21.1 $ docker push myregistry:5000/nginx:1.21.1 $ cb catalog myregistry:5000 # 列出registry中的repositories NO. NAME 0 nginx 1 nginx-chart Push仅仅包装了oras cli，nginx chart的manifest如下 { \"schemaVersion\": 2, \"config\": { \"mediaType\": \"application/vnd.unknown.config.v1+json\", \"digest\": \"sha256:44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a\", \"size\": 2 }, \"layers\": [ { \"mediaType\": \"application/vnd.oci.image.layer.v1.tar+gzip\", \"digest\": \"sha256:64f02409c5583265a67390256055c95902696345bdfb46a566b14ea9eac7c306\", \"size\": 3943, \"annotations\": { \"io.deis.oras.content.digest\": \"sha256:f2c5bf294ce3a1fcd249c00df5f916135059d107cc3f35c92c86189b7113d74e\", \"io.deis.oras.content.unpack\": \"true\", \"org.opencontainers.image.title\": \"mychart\" } } ] } ","date":"2021-08-26","objectID":"/posts/oras/:6:2","tags":["container"],"title":"私有化交付下的应用打包方案","uri":"/posts/oras/"},{"categories":["探索与实战"],"content":"打包bundle 定义nginx-app bundle，tag为v1.0.0，包含nginx镜像与nginx chart。bundle.yaml简化如下 name:myregistry:5000/nginx-apptag:v1.0.0artifacts:- name:\"myregistry:5000/nginx:1.21.1\"- name:\"myregistry:5000/nginx-chart:1.0.0\" $ cb bundle nginx-bundle.yaml # 打包nginx-app nginx-app:v1.0.0的index如下，reference记录在org.opencontainers.image.ref.name annotation里，这个reference（tag）需要被记录并在现场加载时恢复。 { \"schemaVersion\": 2, \"manifests\": [ { \"mediaType\": \"application/vnd.oci.image.manifest.v1+json\", \"digest\": \"sha256:053598290cc6fad47d9af8f98baa939d6ebb92f672f7a1871e29cb55a85f2964\", \"size\": 257 }, { \"mediaType\": \"application/vnd.docker.distribution.manifest.v2+json\", \"digest\": \"sha256:5e95e5eb8be4322e3b3652d737371705e56809ed8b307ad68ec59ddebaaf60e4\", \"size\": 1570, \"annotations\": { \"org.opencontainers.image.ref.name\": \"myregistry:5000/nginx:1.21.1\" } }, { \"mediaType\": \"application/vnd.oci.image.manifest.v1+json\", \"digest\": \"sha256:7ca59b0f5387479b242896fa0c507d8c29dfa5292100a5576f8663a546e41611\", \"size\": 602, \"annotations\": { \"org.opencontainers.image.ref.name\": \"myregistry:5000/nginx-chart:1.0.0\" } } ] } ","date":"2021-08-26","objectID":"/posts/oras/:6:3","tags":["container"],"title":"私有化交付下的应用打包方案","uri":"/posts/oras/"},{"categories":["探索与实战"],"content":"下载bundle # 将nginx-app bundle下载到nginx-app目录下 $ cb pack myregistry:5000/nginx-app:v1.0.0 -o nginx-app # 验证nginx-app中的结构符合OCI Image Layer Spec $ tree nginx-app nginx-app ├── blobs │ └── sha256 │ ├── 053598290cc6fad47d9af8f98baa939d6ebb92f672f7a1871e29cb55a85f2964 │ ├── 12455f71a9b5e0c207a601fb32bcf7f10a933d7193574d968409bbc5c2d89fe0 │ ├── 2a53fa598ee20ad436f2f9da7c0a21cce583bd236f47828895d771fb2e8795e1 │ ├── 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a │ ├── 572061c855037851b6384e6bba08cb7d48f71e74631865641518644ba1469e32 │ ├── 5e95e5eb8be4322e3b3652d737371705e56809ed8b307ad68ec59ddebaaf60e4 │ ├── 64f02409c5583265a67390256055c95902696345bdfb46a566b14ea9eac7c306 │ ├── 7ca59b0f5387479b242896fa0c507d8c29dfa5292100a5576f8663a546e41611 │ ├── 9e324aa228dbd3c1b80ea7c20b6d63b897605fa92f168ccce976a2df42375e77 │ ├── b86f2ba62d17b165964516228297d3ba669d60b6a283b5fd7779b27d7ec33871 │ ├── dd34e67e3371dc2d1328790c3157ee42dfcae74afffd86b297459ed87a98c0fb │ ├── e1acddbe380c63f0de4b77d3f287b7c81cd9d89563a230692378126b46ea6546 │ ├── e21006f71c6fb784a76159590b6ba8ab3fb22e5026f67abcf5feb8e4231837d6 │ └── f3341cc17e586daa9660abf087f13b2eba247bcf6646ee972e85d4cbaf18dbae ├── index.json ├── ingest └── oci-layout # 查看index内容，相当于把nginx-app在全局index中拍平 $ cat nginx-app/index.json| jq . { \"schemaVersion\": 2, \"manifests\": [ { \"mediaType\": \"application/vnd.oci.image.index.v1+json\", \"digest\": \"sha256:572061c855037851b6384e6bba08cb7d48f71e74631865641518644ba1469e32\", \"size\": 674, \"annotations\": { \"org.opencontainers.image.ref.name\": \"myregistry:5000/nginx-app:v1.0.0\" } }, { \"mediaType\": \"application/vnd.docker.distribution.manifest.v2+json\", \"digest\": \"sha256:5e95e5eb8be4322e3b3652d737371705e56809ed8b307ad68ec59ddebaaf60e4\", \"size\": 1570, \"annotations\": { \"org.opencontainers.image.ref.name\": \"myregistry:5000/nginx:1.21.1\" } }, { \"mediaType\": \"application/vnd.oci.image.manifest.v1+json\", \"digest\": \"sha256:7ca59b0f5387479b242896fa0c507d8c29dfa5292100a5576f8663a546e41611\", \"size\": 602, \"annotations\": { \"org.opencontainers.image.ref.name\": \"myregistry:5000/nginx-chart:1.0.0\" } } ] } ","date":"2021-08-26","objectID":"/posts/oras/:6:4","tags":["container"],"title":"私有化交付下的应用打包方案","uri":"/posts/oras/"},{"categories":["探索与实战"],"content":"加载bundle 删除掉registry中的内容并重启，将nginx-app加载到registry中，可以恢复完整的nginx-app bundle。 $ cb load nginx-app ","date":"2021-08-26","objectID":"/posts/oras/:6:5","tags":["container"],"title":"私有化交付下的应用打包方案","uri":"/posts/oras/"},{"categories":["探索与实战"],"content":"多层结构 当前打包策略实现了OCI Artifacts的高扩展性，结构树可以灵活地向上延展，比如bundle里嵌套bundle。 name:myregistry:5000/ubuntu-nginx-apptag:v1.0.0artifacts:- name:\"myregistry:5000/nginx-app:v1.0.0\"# 这是一个bundle- name:\"myregistry:5000/ubuntu:21.04\"# 这是一个image 打包后，ubuntu-nginx-app:v1.0.0的index如下： { \"schemaVersion\": 2, \"manifests\": [ { \"mediaType\": \"application/vnd.oci.image.manifest.v1+json\", \"digest\": \"sha256:52e0a43cc3025f0814510022bc2bc7f64135a9f4c93944ea0b82df344cc798c0\", \"size\": 257 }, { \"mediaType\": \"application/vnd.oci.image.index.v1+json\", \"digest\": \"sha256:572061c855037851b6384e6bba08cb7d48f71e74631865641518644ba1469e32\", \"size\": 674, \"annotations\": { \"org.opencontainers.image.ref.name\": \"myregistry:5000/nginx-app:v1.0.0\" } }, { \"mediaType\": \"application/vnd.docker.distribution.manifest.v2+json\", \"digest\": \"sha256:ef8ee90cfa9cfc7c218586dea9daa6a8d1d191b3c73be143f4120fe140dae3d0\", \"size\": 529, \"annotations\": { \"org.opencontainers.image.ref.name\": \"myregistry:5000/ubuntu:21.04\" } } ] } 对应的层序结构为： ubuntu-nginx-app:v1.0.0镜像的层序结构\" ubuntu-nginx-app:v1.0.0镜像的层序结构 下载与加载均可以正常工作。 ","date":"2021-08-26","objectID":"/posts/oras/:6:6","tags":["container"],"title":"私有化交付下的应用打包方案","uri":"/posts/oras/"},{"categories":["探索与实战"],"content":"补丁机制 通过ubuntu-nginx-app:v1.0.0与nginx-app:v1.0.0两个bundle验证一下补丁机制的可用性。从上述层序结构图中可以看到后者是前者的一个子集，所以预想中patch包应包含根节点及其左右两个子分支全部节点对应的blob，及ubuntu-nginx-app:v1.0.0和ubuntu:21.04两个reference。 $ cb diff myregistry:5000/ubuntu-nginx-app:v1.0.0 myregistry:5000/nginx-app:v1.0.0 -o patch INFO[0000] get 6 diffs $ tree patch patch ├── blobs │ └── sha256 │ ├── 4451f5c7eb7af74432585f5ebfbeb01bbfc87ec4a74dc93703bdd89330559cd1 │ ├── 52e0a43cc3025f0814510022bc2bc7f64135a9f4c93944ea0b82df344cc798c0 │ ├── a2723fc64a92418869862e0a14d8e913641ba6e4bca78cf43d0db4be4c3c14fa │ ├── bf70ebd2c444440ae068c5ccea80e2087906a825ff1019a9f6d6cbb229e33481 │ ├── ee951c00fa8985cc5f5b49f0d7fe5e456697198f24fed85142b4869083b7085b │ └── ef8ee90cfa9cfc7c218586dea9daa6a8d1d191b3c73be143f4120fe140dae3d0 ├── index.json ├── ingest └── oci-layout 3 directories, 8 files $ cat patch/index.json | jq . { \"schemaVersion\": 2, \"manifests\": [ { \"mediaType\": \"application/vnd.oci.image.index.v1+json\", \"digest\": \"sha256:a2723fc64a92418869862e0a14d8e913641ba6e4bca78cf43d0db4be4c3c14fa\", \"size\": 669, \"annotations\": { \"org.opencontainers.image.ref.name\": \"myregistry:5000/ubuntu-nginx-app:v1.0.0\" } }, { \"mediaType\": \"application/vnd.docker.distribution.manifest.v2+json\", \"digest\": \"sha256:ef8ee90cfa9cfc7c218586dea9daa6a8d1d191b3c73be143f4120fe140dae3d0\", \"size\": 529, \"annotations\": { \"org.opencontainers.image.ref.name\": \"myregistry:5000/ubuntu:21.04\" } } ] } 上述结果表明patch包中blobs及index.json中的引用均符合我们预期。 清空registry并将nginx-app:v1.0.0load到registry中以验证应用patch的正确性。 $ cb load nginx-app INFO[0000] successfully push ref myregistry:5000/nginx-app:v1.0.0 INFO[0001] successfully push ref myregistry:5000/nginx-chart:1.0.0 $ cb patch patch INFO[0000] successfully push ref myregistry:5000/ubuntu:21.04 INFO[0001] successfully push ref myregistry:5000/ubuntu-nginx-app:v1.0.0 ","date":"2021-08-26","objectID":"/posts/oras/:6:7","tags":["container"],"title":"私有化交付下的应用打包方案","uri":"/posts/oras/"},{"categories":["探索与实战"],"content":"总结 本文主要介绍了私有化交付下的应用打包方案，简单介绍了私有化交付的模式，提出了现有的打包方案及基于layer cache的一些优化方向。 本文要解决的问题是如何将一组内容从一个registry离线搬运到另一个registry中。问题的核心是如何将一组artifacts关联起来，这些内容应以什么组织形式在公司与现场之间流转。 通过bundle的概念对应用进行打包，便于对应用及版本进行管理。而OCI image layout是将bundle本地化的一个不错的解决思路，此架构可以与helm OCI完全兼容。 ","date":"2021-08-26","objectID":"/posts/oras/:7:0","tags":["container"],"title":"私有化交付下的应用打包方案","uri":"/posts/oras/"},{"categories":["探索与实战"],"content":"OCI Image Format定义了content addressable与location addressable结合的分层树状结构。 ","date":"2021-08-26","objectID":"/posts/oci-image/:0:0","tags":["container"],"title":"OCI Image Format Spec探索与实践","uri":"/posts/oci-image/"},{"categories":["探索与实战"],"content":"基本组成 Image manifest：用于对镜像的内容寻址。 Image index：指向多个manifest的更高级别manifest，一般用于区分多平台。 Filesystem layers：用于描述容器文件系统内容变化。 Configuration：用于记录镜像配置及运行时信息等元信息。 引用go-containerregistry项目中结构图来宏观描述一下上述组成的关系： 镜像层级结构\" 镜像层级结构 OCI Image Spec中有更细化的描述： ","date":"2021-08-26","objectID":"/posts/oci-image/:1:0","tags":["container"],"title":"OCI Image Format Spec探索与实践","uri":"/posts/oci-image/"},{"categories":["探索与实战"],"content":"Content Descriptor Content descriptor用于描述对象内容的位置，组件内的descriptor可以描述当前组件对其他组件的引用关系，其应包含如下核心元素： 内容的类型 内容唯一标识 内容的大小 ","date":"2021-08-26","objectID":"/posts/oci-image/:2:0","tags":["container"],"title":"OCI Image Format Spec探索与实践","uri":"/posts/oci-image/"},{"categories":["探索与实战"],"content":"属性描述 属性 类型 作用 mediaType string 对象内容的类型 digest string 对象内容的唯一标识，常使用sha256算法加密 size int64 对象内容的字节数 urls []string 对象可以被下载的url列表（optional） annotations map[string]string 携带额外信息的键值对集合 mediaType的作用 mediaType用于唯一地标识当前blob的类型，通过此类型可以标准化对blob的处理。以containerd的image.ChildrenHandler获取当前descriptor所有直接子引用为例。可以看出对不同blob的处理依据就是mediaType。 // Children returns the immediate children of content described by the descriptor. func Children(ctx context.Context, provider content.Provider, desc ocispec.Descriptor) ([]ocispec.Descriptor, error) { var descs []ocispec.Descriptor switch desc.MediaType { case MediaTypeDockerSchema2Manifest, ocispec.MediaTypeImageManifest: p, err := content.ReadBlob(ctx, provider, desc) if err != nil { return nil, err } // TODO(stevvooe): We just assume oci manifest, for now. There may be // subtle differences from the docker version. var manifest ocispec.Manifest if err := json.Unmarshal(p, \u0026manifest); err != nil { return nil, err } descs = append(descs, manifest.Config) descs = append(descs, manifest.Layers...) case MediaTypeDockerSchema2ManifestList, ocispec.MediaTypeImageIndex: p, err := content.ReadBlob(ctx, provider, desc) if err != nil { return nil, err } var index ocispec.Index if err := json.Unmarshal(p, \u0026index); err != nil { return nil, err } descs = append(descs, index.Manifests...) default: if IsLayerType(desc.MediaType) || IsKnownConfig(desc.MediaType) { // childless data types. return nil, nil } log.G(ctx).Debugf(\"encountered unknown type %v; children may not be fetched\", desc.MediaType) } return descs, nil } ","date":"2021-08-26","objectID":"/posts/oci-image/:2:1","tags":["container"],"title":"OCI Image Format Spec探索与实践","uri":"/posts/oci-image/"},{"categories":["探索与实战"],"content":"Image Manifest Manifest用于定位镜像内容，可以认为是一个镜像的实际入口，包含一个特定platform下image所需的全部信息： 若干个layers 一个configuration ","date":"2021-08-26","objectID":"/posts/oci-image/:3:0","tags":["container"],"title":"OCI Image Format Spec探索与实践","uri":"/posts/oci-image/"},{"categories":["探索与实战"],"content":"MediaType application/vnd.oci.image.manifest.v1+json OCI Image Format Spec application/vnd.docker.distribution.manifest.v2+json 兼容Docker Image Format Spec ","date":"2021-08-26","objectID":"/posts/oci-image/:3:1","tags":["container"],"title":"OCI Image Format Spec探索与实践","uri":"/posts/oci-image/"},{"categories":["探索与实战"],"content":"属性描述 属性 类型 作用 schemaVersion int 指定manifest schema，为确保与旧版本docker兼容，此Spec下固定值为2 mediaType string 内容的类型 config descriptor 与容器运行时相关的配置信息 layers []descriptor 用于构建镜像内文件系统布局，其中layers[0]描述base layer annotations map[string]string 携带额外信息的键值对集合 ","date":"2021-08-26","objectID":"/posts/oci-image/:3:2","tags":["container"],"title":"OCI Image Format Spec探索与实践","uri":"/posts/oci-image/"},{"categories":["探索与实战"],"content":"实践探索 以linux/amd64下的ubuntu:21.04为例，我们看一下其manifest: { \"schemaVersion\": 2, \"mediaType\": \"application/vnd.docker.distribution.manifest.v2+json\", \"config\": { \"mediaType\": \"application/vnd.docker.container.image.v1+json\", \"size\": 1462, \"digest\": \"sha256:bf70ebd2c444440ae068c5ccea80e2087906a825ff1019a9f6d6cbb229e33481\" }, \"layers\": [ { \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\", \"size\": 31837572, \"digest\": \"sha256:4451f5c7eb7af74432585f5ebfbeb01bbfc87ec4a74dc93703bdd89330559cd1\" } ] } 可以看到，其mediaType为application/vnd.docker.distribution.manifest.v2+json，包含一个config blob与一个layer blob。 ","date":"2021-08-26","objectID":"/posts/oci-image/:3:3","tags":["container"],"title":"OCI Image Format Spec探索与实践","uri":"/posts/oci-image/"},{"categories":["探索与实战"],"content":"Image Index Index又被称为fat manifest，manifest可以视为layer的索引，而index是在manifest上又加了一层的索引。有了index，这种两层树状结构变成了多层，提供了多描述符入口点。 在docker image中，index的主要作用是区分多平台（OS/ORCH）。 ","date":"2021-08-26","objectID":"/posts/oci-image/:4:0","tags":["container"],"title":"OCI Image Format Spec探索与实践","uri":"/posts/oci-image/"},{"categories":["探索与实战"],"content":"MediaType application/vnd.oci.image.index.v1+json OCI Image Format Spec application/vnd.docker.distribution.manifest.list.v2+json 兼容Docker Image Format Spec ","date":"2021-08-26","objectID":"/posts/oci-image/:4:1","tags":["container"],"title":"OCI Image Format Spec探索与实践","uri":"/posts/oci-image/"},{"categories":["探索与实战"],"content":"属性描述 属性 类型 作用 schemaVersion int 指定manifest schema，为确保与旧版本docker兼容，此spec下固定值为2 mediaType string 内容的类型 manifests []object 描述运行时要求的最小集，主要是操作系统/架构等平台相关，列表中有多个manifest，提供平台相关的属性用以进行filter。 annotations map[string]string 携带额外信息的键值对集合 ","date":"2021-08-26","objectID":"/posts/oci-image/:4:2","tags":["container"],"title":"OCI Image Format Spec探索与实践","uri":"/posts/oci-image/"},{"categories":["探索与实战"],"content":"实践探索 我们看一下dockerhub上ubuntu:21.04的index。 { \"schemaVersion\": 2, \"mediaType\": \"application/vnd.docker.distribution.manifest.list.v2+json\", \"manifests\": [ { \"mediaType\": \"application/vnd.docker.distribution.manifest.v2+json\", \"size\": 529, \"digest\": \"sha256:ef8ee90cfa9cfc7c218586dea9daa6a8d1d191b3c73be143f4120fe140dae3d0\", \"platform\": { \"architecture\": \"amd64\", \"os\": \"linux\" } }, { \"mediaType\": \"application/vnd.docker.distribution.manifest.v2+json\", \"size\": 529, \"digest\": \"sha256:b7de3b708ddbdb5ca7d0a6a81f6d9df450276fc4794174a7b7a3441b00281a61\", \"platform\": { \"architecture\": \"arm\", \"os\": \"linux\", \"variant\": \"v7\" } }, { \"mediaType\": \"application/vnd.docker.distribution.manifest.v2+json\", \"size\": 529, \"digest\": \"sha256:ca763e1a382a5b23f91abaf1c36a84be33da2d657f45746112f28ae010571041\", \"platform\": { \"architecture\": \"arm64\", \"os\": \"linux\", \"variant\": \"v8\" } }, { \"mediaType\": \"application/vnd.docker.distribution.manifest.v2+json\", \"size\": 529, \"digest\": \"sha256:54b3fc49fc1949bcedbafbf1f18393920545ba934331cf72176cb14087962879\", \"platform\": { \"architecture\": \"ppc64le\", \"os\": \"linux\" } }, { \"mediaType\": \"application/vnd.docker.distribution.manifest.v2+json\", \"size\": 529, \"digest\": \"sha256:9c389f10c2b192dd01e87188c7cf1591dc830370046085190dd3ecfdaa1f2cfb\", \"platform\": { \"architecture\": \"riscv64\", \"os\": \"linux\" } }, { \"mediaType\": \"application/vnd.docker.distribution.manifest.v2+json\", \"size\": 529, \"digest\": \"sha256:13532df2f7a272c2c973268db5264059be5ba9882962d30db3d86ca38db3a737\", \"platform\": { \"architecture\": \"s390x\", \"os\": \"linux\" } } ] } 从中不难看出，该镜像提供了六种CPU架构下编译的ubuntu镜像，当某个client发出docker pull命令时，registry会index到对应的架构平台，找到合适的manifest。 ","date":"2021-08-26","objectID":"/posts/oci-image/:4:3","tags":["container"],"title":"OCI Image Format Spec探索与实践","uri":"/posts/oci-image/"},{"categories":["探索与实战"],"content":"Filesystem layer Layer是镜像内文件系统的组成成分，每一层都在描述一系列文件系统变化。 ","date":"2021-08-26","objectID":"/posts/oci-image/:5:0","tags":["container"],"title":"OCI Image Format Spec探索与实践","uri":"/posts/oci-image/"},{"categories":["探索与实战"],"content":"MediaType application/vnd.oci.image.layer.v1.tar+gzip OCI Image Format Spec application/vnd.docker.image.rootfs.diff.tar.gzip 兼容Docker Image Format Spec ","date":"2021-08-26","objectID":"/posts/oci-image/:5:1","tags":["container"],"title":"OCI Image Format Spec探索与实践","uri":"/posts/oci-image/"},{"categories":["探索与实战"],"content":"实践探索 我们copy出ubuntu:21.04的layer并解压，看一下base image的样式，tar内文件太多，仅列出前10行。 $ cp blobs/sha256/44/4451f5c7eb7af74432585f5ebfbeb01bbfc87ec4a74dc93703bdd89330559cd1/data ~/ubuntu.tar.gz \u0026\u0026 gzip -d ~/ubuntu.tar.gz -c | tar tv | head -10 # output lrwxrwxrwx 0/0 0 2021-07-24 01:47 bin -\u003e usr/bin drwxr-xr-x 0/0 0 2021-04-19 15:26 boot/ drwxr-xr-x 0/0 0 2021-07-24 01:50 dev/ drwxr-xr-x 0/0 0 2021-07-24 01:50 etc/ -rw------- 0/0 0 2021-07-24 01:47 etc/.pwd.lock -rw-r--r-- 0/0 3028 2021-07-24 01:47 etc/adduser.conf drwxr-xr-x 0/0 0 2021-07-24 01:50 etc/alternatives/ -rw-r--r-- 0/0 100 2021-04-14 18:32 etc/alternatives/README lrwxrwxrwx 0/0 0 2021-07-24 01:50 etc/alternatives/awk -\u003e /usr/bin/mawk lrwxrwxrwx 0/0 0 2021-07-24 01:50 etc/alternatives/nawk -\u003e /usr/bin/mawk 技巧 可以通过... | awk '{print $6}' | awk -F/ '{print $1}'| sort | uniq 对上述输出结果进行聚合获取第一层目录，结果可以看到就是标准的ubuntu root filesystem。 再探索一下filesystem changeset的内容，新创建一个镜像，修改镜像内的文件系统 FROMubuntu:21.04RUN echo \"hello world\" \u003e /tmp/hello.txtCOPY ccc . 分别将第二层与第三层的内容拷贝出来并解压 # 略去拷贝过程 ######Layer2###### $ tar zxvf layer2.tar.gz tmp/ tmp/hello.txt ######Layer3###### $ tar zxvf layer3.tar.gz ccc 上述结果验证了之前踩过的一个坑：写Dockerfile构建镜像时，使用COPY将宿主机上的文件复制到镜像里时，如果源文件变化了，docker缓存会失效。之前误以为一个dockerfile中的一条语句对应一个layer，只要语句不变，layer就不变，就可以使用cache。此例清晰地描述出layer会与文件系统的changeset密切相关。 ","date":"2021-08-26","objectID":"/posts/oci-image/:5:2","tags":["container"],"title":"OCI Image Format Spec探索与实践","uri":"/posts/oci-image/"},{"categories":["探索与实战"],"content":"Configuration 用于描述镜像的一些元信息及容器运行时所需的信息。 ","date":"2021-08-26","objectID":"/posts/oci-image/:6:0","tags":["container"],"title":"OCI Image Format Spec探索与实践","uri":"/posts/oci-image/"},{"categories":["探索与实战"],"content":"MediaType application/vnd.oci.image.config.v1+json OCI Image Format Spec application/vnd.docker.container.image.v1+json 兼容Docker Image Format Spec ","date":"2021-08-26","objectID":"/posts/oci-image/:6:1","tags":["container"],"title":"OCI Image Format Spec探索与实践","uri":"/posts/oci-image/"},{"categories":["探索与实战"],"content":"属性描述 属性 类型 作用 created string 描述镜像创建日期 author string 描述镜像创建的作者 architecture string 描述编译镜像中二进制包的节点CPU架构 os string 描述构建镜像的节点的操作系统 config object 容器运行时所需要的执行参数（docker run中所能指定的参数），如Volumes，Env，ExposedPort等 rootfs object 描述image各层DiffID history object 描述每一层的历史信息 上述大部分属性可以通过docker inspect [IMAGE]获取到。 DiffID DiffID是layer未压缩时的tar包hash后的digest，可用于解压后内容验证。 由于DiffID仅能描述某个layer的信息，无法描述整个layer布局的信息，因此又引入ChainID来校验image的布局，主要思想是引入与之前layer的相关性来生成对应layer的ID。从定义上看，第一层base layer的DiffID与ChainID一致。 ","date":"2021-08-26","objectID":"/posts/oci-image/:6:2","tags":["container"],"title":"OCI Image Format Spec探索与实践","uri":"/posts/oci-image/"},{"categories":["探索与实战"],"content":"实践探索 展示一下ubuntu:21.04的configuration，部分与container相关的字段超出此spec范围。 { \"architecture\": \"amd64\", \"config\": { \"Hostname\": \"\", \"Domainname\": \"\", \"User\": \"\", \"AttachStdin\": false, \"AttachStdout\": false, \"AttachStderr\": false, \"Tty\": false, \"OpenStdin\": false, \"StdinOnce\": false, \"Env\": [ \"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\" ], \"Cmd\": [ \"bash\" ], \"Image\": \"sha256:2a1126c0612fcbe61f0acaa6b1f2caf3a156b31684219de8bbb763ee3e99940c\", \"Volumes\": null, \"WorkingDir\": \"\", \"Entrypoint\": null, \"OnBuild\": null, \"Labels\": null }, \"container\": \"acac01451c096428e536623ecd3887aa7c79f8377ac8a94885b6ceae8971dfcf\", \"container_config\": { \"Hostname\": \"acac01451c09\", \"Domainname\": \"\", \"User\": \"\", \"AttachStdin\": false, \"AttachStdout\": false, \"AttachStderr\": false, \"Tty\": false, \"OpenStdin\": false, \"StdinOnce\": false, \"Env\": [ \"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\" ], \"Cmd\": [ \"/bin/sh\", \"-c\", \"#(nop) \", \"CMD [\\\"bash\\\"]\" ], \"Image\": \"sha256:2a1126c0612fcbe61f0acaa6b1f2caf3a156b31684219de8bbb763ee3e99940c\", \"Volumes\": null, \"WorkingDir\": \"\", \"Entrypoint\": null, \"OnBuild\": null, \"Labels\": {} }, \"created\": \"2021-07-26T21:21:54.791192114Z\", \"docker_version\": \"20.10.7\", \"history\": [ { \"created\": \"2021-07-26T21:21:54.424131139Z\", \"created_by\": \"/bin/sh -c #(nop) ADD file:6ae44786caae9af1c6b70dc9cc244e7d4e06fffc0696f68877527d69aa3fc735 in / \" }, { \"created\": \"2021-07-26T21:21:54.791192114Z\", \"created_by\": \"/bin/sh -c #(nop) CMD [\\\"bash\\\"]\", \"empty_layer\": true } ], \"os\": \"linux\", \"rootfs\": { \"type\": \"layers\", \"diff_ids\": [ \"sha256:ce91b7d7ac5b2c288515e8eee3a83720d6855e7f1cf8dfa6e9b524453956175f\" ] } } ","date":"2021-08-26","objectID":"/posts/oci-image/:6:3","tags":["container"],"title":"OCI Image Format Spec探索与实践","uri":"/posts/oci-image/"},{"categories":["探索与实战"],"content":"Image Layout 用于描述OCI内容寻址（content-addressable）blob与位置寻址（location-addressable）reference的目录结构。 content-addressable vs location-addressable 在location-addressed存储中，每个数据元素存储在特定的物理媒介中，并且它的（物理媒介）location会被记录下来以供后续访问。当想要访问到对应数据内容时，只需要在request中使用这个location即可。位置寻址不关心存储的具体内容是什么，只关心内容存储在什么位置，内容的大小多少（与盘空间占用相关），location所标识的内容可以被灵活地修改/覆盖/删除。 与之相比，content-addressed存储通过与内容相关的唯一ID来定位，通过存储系统找到对应的内容。内容一旦发生变化，这个标识ID也会发生变化，即寻址地址也会发生变化。由于这个特点，一般的content-addressed系统不允许修改原有的内容，并且删除操作也会通过严格的策略进行控制。 参考wikipedia: Content-addressed vs. location-addressed ","date":"2021-08-26","objectID":"/posts/oci-image/:7:0","tags":["container"],"title":"OCI Image Format Spec探索与实践","uri":"/posts/oci-image/"},{"categories":["探索与实战"],"content":"结构组成 blobs目录：包含内容寻址的blob。 子目录是hash算法名称 内容索引形式为blobs/\u003calg\u003e/\u003cencoded\u003e oci-layout 文件：声明OCI image-layout的版本。 Index.json文件：image-layout中reference的入口点。 一般使用org.opencontainers.image.ref.name annotation声明引用。 组织形式与image index形式十分相似。 ","date":"2021-08-26","objectID":"/posts/oci-image/:7:1","tags":["container"],"title":"OCI Image Format Spec探索与实践","uri":"/posts/oci-image/"},{"categories":["探索与实战"],"content":"示例 比较完善的示例是helm对OCI支持，chart的发布支持OCI规范，实现上依赖于本地的OCI Image Layout与OCI registry交互完成chart的发布。 helm支持OCI的交互方式\" helm支持OCI的交互方式 使用save cmd保存两个版本的chart。 $ helm chart save mychart-0.1.0 myregistry:5000/mychart:v0.1.0 ref: myregistry:5000/mychart:v0.1.0 digest: dfec110f2b7aecb1d8604d64f7f32026b0af51aa1286627c6520ff2cf1576337 size: 3.7 KiB name: mychart version: 0.1.0 v0.1.0: saved $ helm chart save mychart-0.2.0 myregistry:5000/mychart:v0.2.0 ref: myregistry:5000/mychart:v0.2.0 digest: fe45ba098c1f8bc61e19245c6123f47d7c51f78cec016834e2c0c26c28901e24 size: 3.7 KiB name: mychart version: 0.2.0 v0.2.0: saved local OCI image layout的结构为： $ tree ~/.cache/helm/registry/cache ├── blobs │ └── sha256 │ ├── 573f8b72a735d3f6e5919acb325d365aeddf69edee1e4840c59a5d741179da97 │ ├── 65a07b841ece031e6d0ec5eb948eacb17aa6d7294cdeb01d5348e86242951487 │ ├── 98ddb183b4658761a6e431fbbde4c6c15863b0c3597b74b519c67776830de282 │ ├── dfec110f2b7aecb1d8604d64f7f32026b0af51aa1286627c6520ff2cf1576337 │ ├── e76837ca35eb2e8f22ce8a78f14a1275511eafed58b76955b2ac7ddd0211c965 │ └── fe45ba098c1f8bc61e19245c6123f47d7c51f78cec016834e2c0c26c28901e24 ├── index.json ├── ingest └── oci-layout 查看一下index.json中的内容cat ~/.cache/helm/registry/cache/index.json | jq . { \"schemaVersion\": 2, \"manifests\": [ { \"mediaType\": \"application/vnd.oci.image.manifest.v1+json\", \"digest\": \"sha256:dfec110f2b7aecb1d8604d64f7f32026b0af51aa1286627c6520ff2cf1576337\", \"size\": 322, \"annotations\": { \"org.opencontainers.image.ref.name\": \"myregistry:5000/mychart:v0.1.0\" } }, { \"mediaType\": \"application/vnd.oci.image.manifest.v1+json\", \"digest\": \"sha256:fe45ba098c1f8bc61e19245c6123f47d7c51f78cec016834e2c0c26c28901e24\", \"size\": 322, \"annotations\": { \"org.opencontainers.image.ref.name\": \"myregistry:5000/mychart:v0.2.0\" } } ] } 从index.json中很容易看出来通过descriptor中的digest与org.opencontainers.image.ref.name annotion将location（chart reference）与content（OCI manifest）关联了起来。 ","date":"2021-08-26","objectID":"/posts/oci-image/:7:2","tags":["container"],"title":"OCI Image Format Spec探索与实践","uri":"/posts/oci-image/"},{"categories":["探索与实战"],"content":"总结与延伸 本文介绍了OCI Image Format Spec的组成，其对mediaType做了兼容，可以说是Docker Image Format Spec的一个超集。但OCI Image Format Spec要更通用些，体现在layer content可以更加多样，并且index不局限于一层。在此通用规范下可以做一些更cool的事情，比如OCI Artifacts。 此外，OCI Image Format Spec与OCI Runtime Spec及OCI Distribution Spec密切相关，比如image config如何转换成runtime bundle；image如何存储到registry。可见OCI Image Format Spec是OCI 规范中关键纽带。 后续会写一篇文章来描述一个私有化交付下的应用打包方案，从中可以看到OCI Artifacts，OCI Image Format Spec与OCI Distribution结合起来释放的强大力量。 ","date":"2021-08-26","objectID":"/posts/oci-image/:8:0","tags":["container"],"title":"OCI Image Format Spec探索与实践","uri":"/posts/oci-image/"},{"categories":["探索与实战"],"content":"OCI Distribution Spec 定义了内容分发的一组标准API。 ","date":"2021-08-26","objectID":"/posts/oci-distribution/:0:0","tags":["container"],"title":"OCI Distribution Spec探索与实践","uri":"/posts/oci-distribution/"},{"categories":["探索与实战"],"content":"术语介绍 Registry：存储/发布artifact的中心，提供OCI Distribution Spec规范的api。 Blob：存储在registry中二进制形式的内容，通过digest寻址到。 Manifest：定义一个artifact的json文档，用于定位artifact的具体内容。 Digest: 对blob内容加密后的唯一标识符。 Artifact：以blob形式存储的概念化的内容，一般是由一个manifest定址若干blobs构成。 Tag：用于便于人类阅读、定位manifest的引用。 ","date":"2021-08-26","objectID":"/posts/oci-distribution/:1:0","tags":["container"],"title":"OCI Distribution Spec探索与实践","uri":"/posts/oci-distribution/"},{"categories":["探索与实战"],"content":"Registry基本要求 Pull，从registry中拉取conent。 Push，向registry中发布content。 Content Discovery，从registry中获取content列表项。 Content Managerment，控制registry中content的完整生命周期。 ","date":"2021-08-26","objectID":"/posts/oci-distribution/:2:0","tags":["container"],"title":"OCI Distribution Spec探索与实践","uri":"/posts/oci-distribution/"},{"categories":["探索与实战"],"content":"标准API汇总 Method API Path Status code 用途 GET /v2/ 200/400/401 用于判断registry是否实现OCI Distribution Spec HEAD /v2/\u003cname\u003e/blobs/\u003cdigest\u003e 200/404 用于判断指定的blob是否存在 GET /v2/\u003cname\u003e/blobs/\u003cdigest\u003e 200/404 用于获取指定的blob HEAD /v2/\u003cname\u003e/manifests/\u003creference\u003e 200/404 用于判断指定的manifest是否存在 GET /v2/\u003cname\u003e/manifests/\u003creference\u003e 200/404 用于获取指定的blob POST /v2/\u003cname\u003e/blobs/uploads/ 202/404 获取上传blob的sessionID，为后续PUT/PATCH操作提供locator POST /v2/\u003cname\u003e/blobs/uploads/?digest=\u003cdigest\u003e 201/202/404/400 直接通过POST上传blob，optional PATCH /v2/\u003cname\u003e/blobs/uploads/\u003creference\u003e 202/404/416 分片上传blob chunks PUT /v2/\u003cname\u003e/blobs/uploads/\u003creference\u003e?digest=\u003cdigest\u003e 201/404/400 上传blob。reference为之前POST请求获取的id PUT /v2/manifests/ 201/404 上传一个manifest GET /v2/\u003cname\u003e/tags/list?n=\u003cinteger\u003e\u0026last=\u003cinteger\u003e 200/404 获取某个repository下的所有tag，可以通过list，last query进行分页 DELETE /v2/\u003cname\u003e/manifests/\u003creference\u003e 202/404/400/405 删除某个manifest DELETE /v2/\u003cname\u003e/blobs/\u003cdigest\u003e 202/404/405 删除某个blob POST /v2/\u003cname\u003e/blobs/uploads/?mount=\u003cdigest\u003e\u0026from=\u003cother_name\u003e 201/202/404 如果某个blob在其他repository上存在，此API可以将blob挂载到同一registry下的不同repository reference与digest区别 digest指的是content的唯一标识，使用digest可以标识anything，因此digest可以用作reference。但使用digest的问题是不容易记忆及索引，从而引入tag来便于记忆，因此tag是通常意义上的reference。需要注意的是一般只有manifest可以使用reference寻址，而blob仅支持digest寻址。原因是对于经典分层结构，blob对外不会单独使用，需要通过manifest定位到。即面向用户的manifest才需要用户可理解的reference(location)去寻址，底层存储blob通过manifest记录的digest(content)定位即可。 有关于content discovery的扩展 OCI Distribution Spec中关于content discovery仅定义了获取某个repository的tags api，但仍有获取到某个registry的repositories的需求，目前大部分registry都实现了此api及其分页形式：GET /v2/_catalog?n=\u003cinteger\u003e\u0026last=\u003cstring\u003e ","date":"2021-08-26","objectID":"/posts/oci-distribution/:3:0","tags":["container"],"title":"OCI Distribution Spec探索与实践","uri":"/posts/oci-distribution/"},{"categories":["探索与实战"],"content":"探索与实践 下面以ubuntu:21.04发布为例探索一下上述api的使用。 先看一下ubuntu:21.04的manifest，其中config与layers中的每个descriptor均为一个blob。 { \"schemaVersion\": 2, \"mediaType\": \"application/vnd.docker.distribution.manifest.v2+json\", \"config\": { \"mediaType\": \"application/vnd.docker.container.image.v1+json\", \"size\": 1462, \"digest\": \"sha256:bf70ebd2c444440ae068c5ccea80e2087906a825ff1019a9f6d6cbb229e33481\" }, \"layers\": [ { \"mediaType\": \"application/vnd.docker.image.rootfs.diff.tar.gzip\", \"size\": 31837572, \"digest\": \"sha256:4451f5c7eb7af74432585f5ebfbeb01bbfc87ec4a74dc93703bdd89330559cd1\" } ] } ubuntu manifest自身的digest为：ef8ee90cfa9cfc7c218586dea9daa6a8d1d191b3c73be143f4120fe140dae3d0 ","date":"2021-08-26","objectID":"/posts/oci-distribution/:4:0","tags":["container"],"title":"OCI Distribution Spec探索与实践","uri":"/posts/oci-distribution/"},{"categories":["探索与实战"],"content":"Push流程 参考oras封装了一下containerd的remotes.PushContent方法将myregistry:5000/ubuntu:21.04 push到registry。将log-level设置成debug模式，我们可以看到containerd中相关api调用的track如下（仅以layer blob为例，省略掉config blob的日志信息）。 Step1：Client端发起一个HEAD blob请求，server端返回404表明当前blob不存在。 DEBU[0000] do request digest=\"sha256:bf70ebd2c444440ae068c5ccea80e2087906a825ff1019a9f6d6cbb229e33481\" mediatype=application/vnd.docker.container.image.v1+json request.header.accept=\"application/vnd.docker.container.image.v1+json, */*\" request.header.user-agent=containerd/1.5.2+unknown request.method=HEAD size=1462 url=\"http://myregistry:5000/v2/ubuntu/blobs/sha256:bf70ebd2c444440ae068c5ccea80e2087906a825ff1019a9f6d6cbb229e33481\" DEBU[0000] fetch response received digest=\"sha256:bf70ebd2c444440ae068c5ccea80e2087906a825ff1019a9f6d6cbb229e33481\" mediatype=application/vnd.docker.container.image.v1+json response.header.content-length=157 response.header.content-type=application/json response.header.date=\"Sat, 21 Aug 2021 04:48:26 GMT\" response.header.docker-distribution-api-version=registry/2.0 response.header.x-content-type-options=nosniff response.status=\"404 Not Found\" size=1462 url=\"http://myregistry:5000/v2/ubuntu/blobs/sha256:bf70ebd2c444440ae068c5ccea80e2087906a825ff1019a9f6d6cbb229e33481\" Step2：Client端调用POST blob获取upload session id，server端返回一个locator。 DEBU[0000] do request digest=\"sha256:bf70ebd2c444440ae068c5ccea80e2087906a825ff1019a9f6d6cbb229e33481\" mediatype=application/vnd.docker.container.image.v1+json request.header.user-agent=containerd/1.5.2+unknown request.method=POST size=1462 url=\"http://myregistry:5000/v2/ubuntu/blobs/uploads/\" DEBU[0000] fetch response received digest=\"sha256:bf70ebd2c444440ae068c5ccea80e2087906a825ff1019a9f6d6cbb229e33481\" mediatype=application/vnd.docker.container.image.v1+json response.header.content-length=0 response.header.date=\"Sat, 21 Aug 2021 04:48:26 GMT\" response.header.docker-distribution-api-version=registry/2.0 response.header.docker-upload-uuid=10729918-5b28-4a0b-b793-319d048a3b66 response.header.location=\"http://myregistry:5000/v2/ubuntu/blobs/uploads/10729918-5b28-4a0b-b793-319d048a3b66?_state=vQM2ysmno9_Yvwoz6NK0qgEKVG1aCm3GqKFHYoQEX6F7Ik5hbWUiOiJ1YnVudHUiLCJVVUlEIjoiMTA3Mjk5MTgtNWIyOC00YTBiLWI3OTMtMzE5ZDA0OGEzYjY2IiwiT2Zmc2V0IjowLCJTdGFydGVkQXQiOiIyMDIxLTA4LTIxVDA0OjQ4OjI2Ljc3MTY5MloifQ%3D%3D\" response.header.range=0-0 response.header.x-content-type-options=nosniff response.status=\"202 Accepted\" size=1462 url=\"http://myregistry:5000/v2/ubuntu/blobs/uploads/\" Step3：Client端调用PUT blob上传blob，server端返回上传成功。 DEBU[0000] do request digest=\"sha256:bf70ebd2c444440ae068c5ccea80e2087906a825ff1019a9f6d6cbb229e33481\" mediatype=application/vnd.docker.container.image.v1+json request.header.content-type=application/octet-stream request.header.user-agent=containerd/1.5.2+unknown request.method=PUT size=1462 url=\"http://myregistry:5000/v2/ubuntu/blobs/uploads/10729918-5b28-4a0b-b793-319d048a3b66?_state=vQM2ysmno9_Yvwoz6NK0qgEKVG1aCm3GqKFHYoQEX6F7Ik5hbWUiOiJ1YnVudHUiLCJVVUlEIjoiMTA3Mjk5MTgtNWIyOC00YTBiLWI3OTMtMzE5ZDA0OGEzYjY2IiwiT2Zmc2V0IjowLCJTdGFydGVkQXQiOiIyMDIxLTA4LTIxVDA0OjQ4OjI2Ljc3MTY5MloifQ%3D%3D\u0026digest=sha256%3Abf70ebd2c444440ae068c5ccea80e2087906a825ff1019a9f6d6cbb229e33481\" DEBU[0000] fetch response received digest=\"sha256:bf70ebd2c444440ae068c5ccea80e2087906a825ff1019a9f6d6cbb229e33481\" mediatype=application/vnd.docker.container.image.v1+json response.header.content-length=0 response.header.date=\"Sat, 21 Aug 2021 04:48:26 GMT\" response.header.docker-content-digest=\"sha256:bf70ebd2c444440ae068c5ccea80e2087906a825ff1019a9f6d6cbb229e33481\" response.header.docker-distribution-api-version=registry/2.0 response.header.location=\"http://myregistry:5000/v2/ubuntu/blobs/sha256:bf70ebd2c444440ae068c5ccea80e2087906a825ff1019a9f6d6cbb229e33481\" response.header.x-content-type-options=nosniff response.status=\"201 Created\" size=1462 url=\"http://myregistry:5000/v2/ubuntu/blobs/uploads/10729918-5b28-4a0b-b793-319d048a3b66?_state=vQM2ysmno9_Yvwoz6NK0qgEKVG1aCm3GqKFHY","date":"2021-08-26","objectID":"/posts/oci-distribution/:4:1","tags":["container"],"title":"OCI Distribution Spec探索与实践","uri":"/posts/oci-distribution/"},{"categories":["探索与实战"],"content":"Pull流程 封装了containerd remotes.FetchHandler与images.ChildrenHandler，以将myregistry:5000/ubuntu:21.04 pull到本地为例展示一下api调用track。 Step1：Client端HEAD一下ubuntu:21.04 manifest，server端返回相关的digest。 DEBU[0000] do request host=\"myregistry:5000\" request.header.accept=\"application/vnd.docker.distribution.manifest.v2+json, application/vnd.docker.distribution.manifest.list.v2+json, application/vnd.oci.image.manifest.v1+json, application/vnd.oci.image.index.v1+json, */*\" request.header.user-agent=containerd/1.5.2+unknown request.method=HEAD url=\"http://myregistry:5000/v2/ubuntu/manifests/21.04\" DEBU[0000] fetch response received host=\"myregistry:5000\" response.header.content-length=529 response.header.content-type=application/vnd.docker.distribution.manifest.v2+json response.header.date=\"Sat, 21 Aug 2021 06:57:20 GMT\" response.header.docker-content-digest=\"sha256:ef8ee90cfa9cfc7c218586dea9daa6a8d1d191b3c73be143f4120fe140dae3d0\" response.header.docker-distribution-api-version=registry/2.0 response.header.etag=\"\\\"sha256:ef8ee90cfa9cfc7c218586dea9daa6a8d1d191b3c73be143f4120fe140dae3d0\\\"\" response.header.x-content-type-options=nosniff response.status=\"200 OK\" url=\"http://myregistry:5000/v2/ubuntu/manifests/21.04\" Step2：Client端获取到ubuntu:21.04的manifest，server端返回manifest的内容、 DEBU[0000] do request digest=\"sha256:ef8ee90cfa9cfc7c218586dea9daa6a8d1d191b3c73be143f4120fe140dae3d0\" mediatype=application/vnd.docker.distribution.manifest.v2+json request.header.accept=\"application/vnd.docker.distribution.manifest.v2+json, */*\" request.header.user-agent=containerd/1.5.2+unknown request.method=GET size=529 url=\"http://myregistry:5000/v2/ubuntu/manifests/sha256:ef8ee90cfa9cfc7c218586dea9daa6a8d1d191b3c73be143f4120fe140dae3d0\" DEBU[0000] fetch response received digest=\"sha256:ef8ee90cfa9cfc7c218586dea9daa6a8d1d191b3c73be143f4120fe140dae3d0\" mediatype=application/vnd.docker.distribution.manifest.v2+json response.header.content-length=529 response.header.content-type=application/vnd.docker.distribution.manifest.v2+json response.header.date=\"Sat, 21 Aug 2021 06:57:20 GMT\" response.header.docker-content-digest=\"sha256:ef8ee90cfa9cfc7c218586dea9daa6a8d1d191b3c73be143f4120fe140dae3d0\" response.header.docker-distribution-api-version=registry/2.0 response.header.etag=\"\\\"sha256:ef8ee90cfa9cfc7c218586dea9daa6a8d1d191b3c73be143f4120fe140dae3d0\\\"\" response.header.x-content-type-options=nosniff response.status=\"200 OK\" size=529 url=\"http://myregistry:5000/v2/ubuntu/manifests/sha256:ef8ee90cfa9cfc7c218586dea9daa6a8d1d191b3c73be143f4120fe140dae3d0\" Step3：Client端从manifest解析出blobs，并发送GET blob请求，server端将blob的内容返回。 ------Requests for 2 blobs------ DEBU[0000] do request digest=\"sha256:bf70ebd2c444440ae068c5ccea80e2087906a825ff1019a9f6d6cbb229e33481\" mediatype=application/vnd.docker.container.image.v1+json request.header.accept=\"application/vnd.docker.container.image.v1+json, */*\" request.header.user-agent=containerd/1.5.2+unknown request.method=GET size=1462 url=\"http://myregistry:5000/v2/ubuntu/blobs/sha256:bf70ebd2c444440ae068c5ccea80e2087906a825ff1019a9f6d6cbb229e33481\" DEBU[0000] do request digest=\"sha256:4451f5c7eb7af74432585f5ebfbeb01bbfc87ec4a74dc93703bdd89330559cd1\" mediatype=application/vnd.docker.image.rootfs.diff.tar.gzip request.header.accept=\"application/vnd.docker.image.rootfs.diff.tar.gzip, */*\" request.header.user-agent=containerd/1.5.2+unknown request.method=GET size=31837572 url=\"http://myregistry:5000/v2/ubuntu/blobs/sha256:4451f5c7eb7af74432585f5ebfbeb01bbfc87ec4a74dc93703bdd89330559cd1\" ------Responses for 2 blobs------ DEBU[0000] fetch response received digest=\"sha256:bf70ebd2c444440ae068c5ccea80e2087906a825ff1019a9f6d6cbb229e33481\" mediatype=application/vnd.docker.container.image.v1+json response.header.accept-ranges=bytes response.header.cache-control=\"max-age=31536000\" response.header.content-length=1462 response.header.content-type=application/octet-stream response.header.date=\"Sat, 21 Aug 2021 06:57:20 GMT\" response.header.docker-content-digest=\"sha256:bf70ebd2c","date":"2021-08-26","objectID":"/posts/oci-distribution/:4:2","tags":["container"],"title":"OCI Distribution Spec探索与实践","uri":"/posts/oci-distribution/"},{"categories":["探索与实战"],"content":"参考文献 Oras Containerd remotes Containerd images OCI Distribution Spec ","date":"2021-08-26","objectID":"/posts/oci-distribution/:5:0","tags":["container"],"title":"OCI Distribution Spec探索与实践","uri":"/posts/oci-distribution/"},{"categories":["整理与总结"],"content":" The Open Container Initiative is an open governance structure for the express purpose of creating open industry standards around container formats and runtimes. ","date":"2021-08-26","objectID":"/posts/oci/:0:0","tags":["container"],"title":"OCI 标准探究","uri":"/posts/oci/"},{"categories":["整理与总结"],"content":"内容概览 OCI定义了如下几个标准： ","date":"2021-08-26","objectID":"/posts/oci/:1:0","tags":["container"],"title":"OCI 标准探究","uri":"/posts/oci/"},{"categories":["整理与总结"],"content":"OCI Runtime-Spec 定义容器配置，运行环境及生命周期规范。 ","date":"2021-08-26","objectID":"/posts/oci/:1:1","tags":["container"],"title":"OCI 标准探究","uri":"/posts/oci/"},{"categories":["整理与总结"],"content":"OCI Image-Spec 定义image格式规范。 manifest filesystem layers image index ","date":"2021-08-26","objectID":"/posts/oci/:1:2","tags":["container"],"title":"OCI 标准探究","uri":"/posts/oci/"},{"categories":["整理与总结"],"content":"OCI Distribution-Spec 定义内容分发的一组标准API。 ","date":"2021-08-26","objectID":"/posts/oci/:1:3","tags":["container"],"title":"OCI 标准探究","uri":"/posts/oci/"},{"categories":["整理与总结"],"content":"OCI Artifacts OCI Image-Spec的通用扩展，将普通artifact按照image形式发布到distribution上。 ","date":"2021-08-26","objectID":"/posts/oci/:1:4","tags":["container"],"title":"OCI 标准探究","uri":"/posts/oci/"},{"categories":["整理与总结"],"content":"对标准的认识 标准是什么？字面上的意思是指衡量、区别事物的准则。遵循某一标准的事物可以达到某种程度上的统一。 最初对标准的认识就是两个字：抽象。似乎人们天生对于抽象的东西的初印象都是十分抗拒的，而具体的东西更有助于人们去理解新事物。随着具有相同功能的产品越来越多，人们对这些产品的选择也越来越多，但是当我们从一个产品的使用切换到另一个产品的使用上却犯了难：完成同样的事，操作或行为却大相径庭。而标准正是为了统一这类产品而生，即我们只需要了解相应的标准即可完成想要的功能。完成此功能的产品可以很多，但他们需要满足这个标准，而一旦他们满足了这个标准，我们就可以方便地在这些产品中进行切换。 上面的描述还是过于抽象，举个生活中最简单的例子：数据线接口。如果没有标准，每个设备的接口的样式可以五花八门，试想一下某款鼠标为了适配几千种笔记本的接口形状，也需要提供成千上万种的数据线，这简直就是灾难。而通过制定一组标准接口(VGA, HDMI, USB, TypeC)，所有厂商制造笔记本时受限于这些标准接口，这样外设便可以做到很通用，即便存在为数不多的几种不同标准，一个绿联就可以轻松搞定。 总之标准就是为了提升通用性，就好比多态一样，实现可以多种多样，但都实现统一的接口，而这接口便是完成某个功能的最短路径。 在工作中受益于标准化的案例就是OpenTracing，这是一套分布式追中的标准规范，定义了一组接口规范。在开发过程中，无需陷于产品的选型，直接使用这组规范接口，而只要是实现了此规范的产品（jaeger, skywalking, zipkin等）都可以在项目中轻松切换。 有了OCI Spec，我们可以使用contained来替换docker，也可以将镜像仓库从docker registry迁移到harbor。OCI让容器化变得更通用。 ","date":"2021-08-26","objectID":"/posts/oci/:2:0","tags":["container"],"title":"OCI 标准探究","uri":"/posts/oci/"},{"categories":["整理与总结"],"content":"系列文章 OCI Distribution Spec探索与实践 OCI Image Format Spec探索与实践 私有化交付下的应用打包方案 ","date":"2021-08-26","objectID":"/posts/oci/:3:0","tags":["container"],"title":"OCI 标准探究","uri":"/posts/oci/"},{"categories":["整理与总结"],"content":"加密，保障信息内容安全；认证，确保信息的来源可靠。 互联网的出现拉近了整个世界的距离，它的魔力就在于可以将芸芸众生都收罗在其控制范围内。正所谓有人的地方就一定有恶，网络面临着各种各样的威胁。而网络由于其巨大的影响力，一旦遭受破坏波及范围难以估量，因此网络安全便显得尤为重要。 ","date":"2021-07-22","objectID":"/posts/certification/:0:0","tags":["tls","网络"],"title":"网络安全基础","uri":"/posts/certification/"},{"categories":["整理与总结"],"content":"网络面临的威胁 计算机网络是不可靠的，一来网络的稳定性受制于网络提供商及对应的硬件设备；二来就是来自人为的恶意干预。前者往往是难以预测和防范的小概率事件，而后者通过精妙的网络安全技术几乎可以完全规避掉。计算机网络所面临的恶意威胁主要分为被动攻击与主动攻击两大类： ","date":"2021-07-22","objectID":"/posts/certification/:1:0","tags":["tls","网络"],"title":"网络安全基础","uri":"/posts/certification/"},{"categories":["整理与总结"],"content":"被动攻击 攻击者观察和分析数据单元而不干扰正常的网络通信。 截获：攻击者从网上窃听他人的通信内容。 ","date":"2021-07-22","objectID":"/posts/certification/:1:1","tags":["tls","网络"],"title":"网络安全基础","uri":"/posts/certification/"},{"categories":["整理与总结"],"content":"主动攻击 攻击者对某个连接中的数据协议单元进行处理，采取行动扰乱原本的网络通信。 中断：攻击者有意中断他人在网络上的通信，比如DDos。 篡改：攻击者故意篡改网络上传送的报文。 伪造：攻击者伪造信息在网络上传送。 这些攻击大多数并不像网络断线或者波动那样能让我们有所感知，而是在无形中破坏/泄露我们的通信。面临这些威胁，我们必须采取措施保证网络安全。 ","date":"2021-07-22","objectID":"/posts/certification/:1:2","tags":["tls","网络"],"title":"网络安全基础","uri":"/posts/certification/"},{"categories":["整理与总结"],"content":"加密 从上面的威胁类型来看，当务之急是如何保证我们的消息不被他人获知？百分百的不泄露信息要么是不产生任何信息，要么是与世隔绝，所以根本无法做出这个保证。但当我们换个思路：如何保证我们有用的消息不被他人获知？转机便出现了：加密技术保护我们有用的信息不被他人获取。 ","date":"2021-07-22","objectID":"/posts/certification/:2:0","tags":["tls","网络"],"title":"网络安全基础","uri":"/posts/certification/"},{"categories":["整理与总结"],"content":"无加密时代 在那个计算机网络还没有出现，人类还比较纯粹的时代，语言和文字成为了人们通信的主要手段，消息的传递也都是基于明文。这时，我们对于加密的需求不强，因为本身消息传播途径比较少，如果真的需要传递一些秘密，只要通过人来实现就可以。随着时代的进步，消息安全的重要性额外地凸显出来。最显著的场景是在战争年代的战略消息的传递，上面提到的各种类型的威胁在这个时代都有所体现。 截获：投信的使臣投宿客栈时，信报被细作偷看，但没有改变信报上的内容。 中断：投信的使臣被细作射杀了。 篡改：投信的使臣叛变了，改了信报的内容。 伪造：有人假扮投信的使臣传递信报。 通过在信报上做手脚，往往可以不折一兵一卒损敌方千军万马，因此消息的保密在人类文明伊始就意义重大。 ","date":"2021-07-22","objectID":"/posts/certification/:2:1","tags":["tls","网络"],"title":"网络安全基础","uri":"/posts/certification/"},{"categories":["整理与总结"],"content":"对称加密 最早的加密技术应当算是凯撒加密了，其核心思想就是简单的替换：将明文中所有字母在字母表上向前或向后偏移固定数目后形成了密文。对于外人而言，其看到的密文是一堆不相关的字符串，无法破解其要表达的信息。而对于消息接收者而言，他清楚加密的策略，也清楚对应解密方法。因此可以通过对应的逆偏移解码出明文，获取有用的消息。 这就是对称加密的雏形，即加密解密双方有一个公共的规则（相同的密钥），发送发方通过此规则（密钥）进行编码（加密），接收方通过此规则（密钥）进行解码（解密），信息在传输过程中是以明文经加密后产生的密文传递。 消息在网络中进行传递就要求加密算法是需要公开的，因为我们无法在通信的最开始私下里统一加密方案，也不会绞尽脑汁去创造新的加密算法。因为我们的通信对象太多了，也都远在天边，即便我们可以创造各式各样的加密算法，也无法安全地与对方分享我们的算法。所以现代的加密算法是公开的、标准化的，我们通信的时候只需要声明我们使用的算法即可，对加密的安全性保证仅在于我们为加密算法提供的特殊标识（密钥）。比如凯撒算法是公开的，但偏移量作为特殊标识是通信双方约定好的。也正是因为此标识的多样性，才能保证我们的消息不易被破解。 对称加密的好处就是简单，计算速度快，开销小。而问题也显而易见，我们的密钥需要通信双方共享，但是密钥没有办法安全地传递。一旦密钥泄露出去，密文的传递跟明文的传递别无二致。 破解难易度 对于凯撒算法而言，密钥很容易通过穷举法破解出来，毕竟字母偏移量只有25种可能，因此极易被破解。但成熟的加密算法要求密钥足够长，当然这并不意味着密钥不会被破解，只是说破解难度十分巨大，可以认为是在计算上（而不是在理论上）不可破解，或者更直白的说破解密钥的成本要比消息本身的价值高很多。这侧面说明了在对称加密中，与密钥泄露相比，密钥被破解的可能性可以完全忽略不计。 目前常用的对称加密算法是DES，3DES，AES等。 下图是一个简单的DES示例 对称加密算法示意\" 对称加密算法示意 ","date":"2021-07-22","objectID":"/posts/certification/:2:2","tags":["tls","网络"],"title":"网络安全基础","uri":"/posts/certification/"},{"categories":["整理与总结"],"content":"非对称加密 对称加密致命缺陷就是无法保证密钥安全传递，因此基于公钥密码体制的非对称加密走上了舞台。顾名思义，非对称加密指的是加密密钥与解密密钥是不同的。其中加密密钥又称公钥，是向公众公开的；而解密密钥又称私钥，是对外保密的。由于公钥本身是公开的，因此无需保证其安全传递。即便被第三方截获，其也无法破解加密后的密文，因为只有对应的私钥才能将密文解密。在公钥密码体制中，最著名的是基于大数分解问题的RSA体制。 加密与解密 经常有个误区会认为公钥是用来加密的，私钥是用来解密的，但实际上二者并无相关性。公钥与私钥是通过某种算法算出的一对密码串，使用一方进行编码，便可以通过另一方进行解码。唯一的原则是公钥是公开的，私钥是保密的，我们会为不同用途选择不同的角色进行编解码。比如信息加密我们会采用公钥编码，私钥解码；数字签名会采用私钥编码，公钥解码。 那么有了安全性如此之高的非对称加密，对称加密是不是就可以退出历史舞台了呢？并不是的，因为非对称加密有个致命的确定：开销大，性能差，而且开销是与明文的长度正相关的。在海量数据通信的时代，这显然会降低信息传递效率，因此TLS的最佳实践是通过非对称加密传递对称加密密钥，具体的信息加密仍然采用对称加密。 非对称加密的另一个应用场景是数字签名，数字签名是通过私钥加密，并通过公钥解密。其作用类似于写在纸上的签名，申明其所传递的内容无误。签名只能有发信者完成，而所有人均可通过其公钥对其进行验签。有了数字签名后，其他人无法篡改或伪造信息的内容，因为他们没有也无法破解发信者的私钥，所以无法对篡改后/伪造的内容进行签名。 原始信息的大小直接影响到签名的性能，通常我们需要对原始信息进行hash获取摘要，并对摘要进行签名。这要求hash算法是不可逆转的，即无法根据摘要推算出私钥。同时，好的hash算法能保证不同的信息输出的结果也都不相同，即在计算上同一结果只能对应一种原始信息。目前比较流行的hash算法是md5，其将原始信息散列成固定128位的结果。 数字签名示意\" 数字签名示意 有了非对称加密，信息的传递就绝对安全了吗？也不是，上述过程中最大的问题仍旧是…公钥的传递。不对呀，之前不是说了公钥是公开的吗，为什么公钥的传递还会引发安全性呢？问题的本质不在于传递公钥内容的安全性，而在于公钥的所有者是谁。换句话说，小明要和小丽通信，小明如何知道传递过来的公钥是小丽的呢？如果小丽传递过来的公钥被小三拦截，并且将小三的公钥传递给了小明，那小明原本要发给小丽的情话不就被小三拦截并破译了？小三便可以窃听或者篡改小明与小丽的通信。这就是所谓的中间人攻击。 中间人攻击示例\" 中间人攻击示例 那么如何避免中间人攻击呢？这就需要引出第三方认证了，即通过权威机构证明这个公钥是小丽的。 ","date":"2021-07-22","objectID":"/posts/certification/:2:3","tags":["tls","网络"],"title":"网络安全基础","uri":"/posts/certification/"},{"categories":["整理与总结"],"content":"认证 认证通俗来讲，就是通过一个第三方来验明某个人的身份，从而确认公钥就是这个人的，以避免中间人攻击。在流程上，一般是一方带着自己的身份信息向第三方机构去申请一个证书，第三方机构颁发一个带有自己签名的证书，该方将证书发送给对端进行验证。我们着重介绍一下数字证书和颁发机构这两个概念。 ","date":"2021-07-22","objectID":"/posts/certification/:3:0","tags":["tls","网络"],"title":"网络安全基础","uri":"/posts/certification/"},{"categories":["整理与总结"],"content":"数字证书 数字证书指在互联网通讯中标识通讯各方身份信息的一个数字认证，人们可以在网上用它来识别对方的身份。一般而言，证书需要包含如下内容： 持有者身份信息 证书颁发者信息 持有者的公钥 认证机构的数字签名 认证机构验证持有者的身份（CSR）无误后，便向其发布一个带其签名的证书，以此来标识此证书中的公钥是可信的。 在TLS中，通常使用x509证书，下例演示了minikube为kube-apiserver生成的服务端证书，我们根据这个证书看一下证书的机构。 Certificate: Data: Version: 3 (0x2) # x509证书版本号 Serial Number: 2 (0x2) # 序列号，每个证书唯一，用以与其他证书区分开 Signature Algorithm: sha256WithRSAEncryption # 签名使用的算法 Issuer: CN=minikubeCA # 颁发机构名称 Validity # 证书有效期（不早于...不晚于...） Not Before: Jul 9 02:57:51 2021 GMT Not After : Jul 10 02:57:51 2022 GMT Subject: O=system:masters, CN=minikube # 持有者的名字 Subject Public Key Info: # 持有者的公钥信息 Public Key Algorithm: rsaEncryption Public-Key: (2048 bit) Modulus: 00:b6:e3:24:20:ce:84:11:21:e5:a4:ee:fd:11:75: 51:94:1e:bb:c6:18:3c:fa:e3:1f:16:d2:18:4d:98: e2:44:30:b4:aa:c4:7a:de:8a:f4:ec:c5:e9:a6:0b: ac:12:b2:03:e9:ca:16:f4:69:f7:08:bb:1c:0d:af: 58:9a:51:39:30:cf:bc:0f:60:97:a9:a4:0a:f8:37: 65:dd:b9:21:1f:da:0b:79:19:1d:6b:96:ff:98:57: 36:3b:a3:e3:34:98:0d:70:92:5f:6f:0f:e8:a2:3b: 88:d5:4c:3d:fb:e0:75:48:af:5e:e5:16:a8:50:d6: 92:ef:be:d5:23:91:e1:c9:d5:9c:e6:ff:49:e7:ca: fb:ab:c7:72:0d:90:23:dc:0a:59:cf:8f:e4:f6:6a: fe:73:c0:8d:bb:23:8c:a8:0f:e7:90:61:e1:66:b1: ac:4d:96:23:c8:0b:43:25:a2:8a:4f:d5:ff:2d:57: 8c:fb:16:d2:69:a0:80:d1:f9:f2:e1:a3:0a:40:7a: 56:1b:3c:69:36:73:dd:b5:f6:9e:75:d4:91:5c:58: b4:e8:f7:a2:2f:1e:0c:4b:2d:d6:1e:6d:92:6f:d3: 07:85:a6:9f:7c:20:0c:7c:e8:3c:0f:6b:c8:74:a4: 8b:c6:d3:10:af:a7:dd:dc:90:ae:bc:f6:b7:b0:e1: 1b:bb Exponent: 65537 (0x10001) X509v3 extensions: # 一堆x509扩展，后面会挑一些重要的说明 X509v3 Key Usage: critical Digital Signature, Key Encipherment X509v3 Extended Key Usage: TLS Web Server Authentication, TLS Web Client Authentication X509v3 Basic Constraints: critical CA:FALSE X509v3 Subject Alternative Name: DNS:minikubeCA, DNS:control-plane.minikube.internal, DNS:kubernetes.default.svc.cluster.local, DNS:kubernetes.default.svc, DNS:kubernetes.default, DNS:kubernetes, DNS:localhost, IP Address:10.122.101.148, IP Address:172.17.0.40, IP Address:10.96.0.1, IP Address:127.0.0.1, IP Address:10.0.0.1 Signature Algorithm: sha256WithRSAEncryption # 签名信息 97:e6:66:a9:a4:fb:42:93:59:c2:2e:ea:77:9a:bf:46:99:11: 72:f6:e1:f7:ce:22:9b:35:7d:37:03:d6:ea:8d:c0:9a:9e:0b: 5c:70:93:e5:5c:e2:c8:43:df:e6:ee:ff:ba:90:8d:de:1f:e5: 4e:ee:72:a7:bc:9e:7a:a9:7f:58:2e:7e:6f:aa:91:60:02:c5: 51:71:1a:e0:80:8b:3d:08:34:a9:65:47:7a:89:7d:31:6d:1a: 1f:0f:0b:17:88:48:eb:e5:20:94:56:52:9a:e0:30:88:fb:cc: 62:12:ea:86:45:e2:a8:59:cd:d0:b1:d6:7b:a9:37:fa:24:b6: 34:d4:4d:aa:cd:28:2c:e2:57:90:6a:11:4f:c0:01:68:49:ef: bd:54:68:7f:f8:2e:99:ba:d0:b1:01:c2:eb:7e:5a:ff:f9:dd: 6c:1b:43:b4:3b:10:fc:46:ef:5b:63:05:27:12:74:6d:2c:ec: af:d6:66:2a:eb:45:ee:d9:d9:bd:73:2d:38:bd:bc:b5:38:7c: 90:9b:f0:11:ee:0a:93:1d:63:25:89:e6:c3:59:3c:7b:4a:4d: 53:d3:a1:a6:3e:82:64:f1:04:02:2c:ce:b9:68:5b:fc:1d:40: c8:8f:9a:ce:04:9d:5a:c9:6c:94:8e:43:f5:e4:78:00:82:bb: f4:5c:5b:d7 x509证书定义了一系列扩展，用于对证书进行约束及限制，常用的扩展列举如下： 扩展名 用途 是否为critical 示例 X509v3 Basic Constraints 描述该证书是否属于CA，具有签署证书的能力 Y CA=false：此证书不是CA证书，不可签署其他证书 X509v3 Key Usage 限定了证书的用途 Y Digital Signature, Key Encipherment表示可以用于数字签名及密钥加密 X509v3 Extended Key Usage 限定了证书的用途 N TLS Web Server Authentication, TLS Web Client Authentication表示可以用于服务端及客户端认证 X509v3 CRL Distribution Points 提供了CRL地址列表 F URI:http://crl.starfieldtech.com/sfs3-20.crl Authority Information Access 提供OSCP地址；CA签发者的连接(用于获取中间证书) F OCSP - URI:http://ocsp.int-x3.letsencrypt.org CA Issuers - URI:http://cert.int-x3.letsencrypt.org/ X509v3 Subject Key Identifier 持有者的唯一标识 F Authority Key Identifier 颁发者的标识 F 与颁发者的X509v3 Subject Key Identifier相等 X509v3 Subject Alternative Name（SAN） 列出证书所有的合法域名，如果其不存在就回退到Common Name寻找 F DNS:localhost, IP Address:10.122.101.148 表示证书来源的dns为localhost或者Ip为10.122.100.148的是合法的，其他均不可信 结合以上扩展可以列举出证书验证的失败的几个原因： 证书过期了 证书由不可信CA颁布 证书被吊销了 证书来源不在其SAN中 critical作用 有些扩展带有critical标识，其意义为所有的证书验证方必须理解它的含义，否则认定为认证失败。简单理解就是这些扩展要求必须能够被识别。 ","date":"2021-07-22","objectID":"/posts/certification/:3:1","tags":["tls","网络"],"title":"网络安全基础","uri":"/posts/certification/"},{"categories":["整理与总结"],"content":"颁发机构（CA） 为避免中间人攻击，证书必须由第三方权威机构认证才可信，这里的权威机构就是CA。上面描述的数字证书就是申请者发送证书签署请求（CSR）给CA，由CA认证后用其私钥进行签名形成证书。可见CA的信誉直接影响着证书的可信度。 那么CA又是怎么保证其是可信的呢？答案是通过更权威的CA进行认证，那么这个更权威的CA怎么保证是可信的呢？那就要找更更权威的CA认证……现实情况下，这种情况对应着证书链认证，即认证是一级一级向上传递的。当然为了避免证书无休止的验证下去，是需要有一个最终信任源的，这个信任源又称为根证书。 按下葫芦浮起瓢，CA的认证大致明确了，但是它又引入了两个问题： 根证书是如何终止链式验证过程的？如何成为信任源的？如果私钥泄露怎么办？如果过期怎么办？ 为什么需要证书链，直接使用根证书进行用户证书的认证会有什么问题？ 上述两个问题并非是割裂的，而是息息相关的。 根证书作为可信任的源头，其使用自己的私钥来签署自己的证书（这类证书又叫做自签名证书，其特点是Issuer与Subject信息一致），验证方只要持有该根证书的公钥便可对此根证书进行验证。而这些具有权威性的CA根证书会内置在浏览器及操作系统中，这样便可以对此类根证书进行验证。如果我们想信任某个第三方证书，那么只需要将其加入到浏览器/操作系统的证书信任列表中即可。 根证书的有效期一般会比较长，如果根证书过期了，那么只能由该机构重新签发。而在临期时，便会借着操作系统/浏览器的更新而将新证书植入进去。另一方面，现在很多证书都采用了交叉认证，即使某个根证书过期了，也能确保其他链条上的认证成功。如果根证书的私钥泄露了，那么它就可以被用于发布非法证书，作为互联网的信任根源之一，带来的影响会是灾难性的。因此为了避免根证书私钥的安全，需要做到以下保证： 私钥在计算上须是不可破解的，因为根证书有效期较长，如果私钥长度过短的话很有可能在有效期内被破解，因此需要是在计算上不可破解的。当前的x509证书可以保证这一点。 用户证书不直接通过根证书签名颁发，而是通过中间证书颁发，建立起中间证书链进行认证。 我们着重来说一下第二点，试想一下如果每个证书都需要根证书颁发的话，会不会增大私钥泄露的风险呢？从统计学角度看，如果签署的证书过多，其规律性信息量也会暴露越多，无论是泄露还是被破解的概率都会增大。因此通过追加一层中间证书来解决此问题，即中间证书颁发用户证书，根证书颁发中间证书。这样便构成了完整的证书链体系，从而减小根证书密钥泄露的风险。通常来讲，为了严格控制根证书私钥的安全性，其所在的机器通常是离线的，只有在需要签署/吊销中间证书时才会联网，将暴露的风险降到最低。 中间证书的特点 中间证书不应是自签名的，即Issuer与Subject是不同的，其携带上一级证书的DN (Distinguished Name)，可以通过DN来找到上一级证书。此外中间证书是可以签发下级证书的，即X509v3 Basic Constraints扩展字段需设置为CA=true。最后中间证书的有效期一般比根证书的短很多，如果中间证书因私钥泄露等问题需要被吊销（可以通过CRL或者OCSP来查询证书是否被吊销）时，影响范围会小很多。 证书链示意图\" 证书链示意图 总结一下链式证书发布及验证过程： 发布方 权威CA生成自签名根证书，并将根证书置于操作系统/浏览器中 权威CA使用根证书私钥签名中间证书 CA使用中间证书采用其私钥签名用户证书 用户使用其私钥签名数据摘要 验证方 采用中间证书验证用户证书 如果有多层中间证书，则使用上一级中间证书验证当前中间证书 通过内置的根证书验证中间证书 通过用户证书中的公钥对数据摘要进行验签 最后一个问题是在对用户证书进行验证时，如何获取中间证书呢？在SSL握手的过程中，是允许在将客户端/服务器证书发送后紧着着将中间证书发送出去的。但这并不是必须的，还有一些其他的方式获取中间证书，比如上述提到过的Authority Information Access扩展中可能会有颁发者的获取地址等。 ","date":"2021-07-22","objectID":"/posts/certification/:3:2","tags":["tls","网络"],"title":"网络安全基础","uri":"/posts/certification/"},{"categories":["整理与总结"],"content":"总结 本文介绍了网络安全面临哪些威胁，使用数据加密技术可以做到有效规避部分威胁。接着详细介绍了对称加密及非对称加密的特点。单方面的加密技术无法抵御中间人攻击，因此需要第三方认证以验明通信双方的身份。最后介绍了认证中的一些重要概念，如数字签名、数字证书、颁发机构等，并将这些概念在认证的流程中发挥的作用串联起来。此外，文章穿插着对TLS的认证及加密流程的介绍。 网络安全远不止于此，加密与认证仅仅是保证了最基本的通信安全，而网络安全还涵盖很多的方面，诸如人为因素，准入机制，角色权限控制等。对加密/认证的概念有了初步的认识，后续会逐步深入地研究kubernetes中的认证、鉴权、准入的安全管理机制。 ","date":"2021-07-22","objectID":"/posts/certification/:4:0","tags":["tls","网络"],"title":"网络安全基础","uri":"/posts/certification/"},{"categories":["整理与总结"],"content":"参考文献 数字证书原理 openssl x509证书 Wikipedia openssl cookbook ","date":"2021-07-22","objectID":"/posts/certification/:5:0","tags":["tls","网络"],"title":"网络安全基础","uri":"/posts/certification/"},{"categories":["探索与实战"],"content":"诸多巧合凑在一起就是完美的偏差 ","date":"2021-07-11","objectID":"/posts/minikube-tls/:0:0","tags":["k8s","tls"],"title":"Minikube中的TLS认证探秘","uri":"/posts/minikube-tls/"},{"categories":["探索与实战"],"content":"缘起 对TLS的认知最初应该在学习计算机网络中的https协议，该协议通过TLS层对传输数据进行加密解密。为了防止中间人攻击，需要第三方证书机构进行认证，认证的方式是通过数字签名。基本上这几点就涵盖了所有的考纲内容。然而当我在学习或者在工作中真的遇到TLS引起的认证问题时，我发现我所理解的十分笼统，无法给我提供任何有价值的排查思路，因此准备稍微深挖一下TLS的认证机制。 可是载体为什么是minikube？最近在跟随大佬熟悉一些operator相关的机制，在开始前搭了一套minikube环境，想着能有更好的开发体验，打算在本地去连服务器的minikube集群，后面有机会再去研究一下telepresence以便在本地调试。连接服务器的k8s集群相关的文档也有很多，核心的解决方案就是将minikube集群中的kubeconfig及对应的证书文件拷贝到本机。顺着这个思路一顿操作猛如虎，结果在使用kubectl获取资源时，出现了x509证书认证错误。 kubectl get pods Unable to connect to the server: x509: certificate signed by unknown authority (possibly because of “crypto/rsa: verification error” while trying to verify candidate authority certificate “minikubeCA”) 在google没有找到合适的诱因及解决方案，因此打算自己探秘一番。有关TLS认证，在这篇文章有所提及，本文主要记录k8s的TLS双向认证的过程。 ","date":"2021-07-11","objectID":"/posts/minikube-tls/:1:0","tags":["k8s","tls"],"title":"Minikube中的TLS认证探秘","uri":"/posts/minikube-tls/"},{"categories":["探索与实战"],"content":"初识 k8s在权限管理上做的格外细致，尤其是在k8s api的访问上，更是细分为认证、鉴权和准入等阶段。我们这里只对tls双向认证做粗略的描述。 什么是双向认证呢？简单来说就是服务器需要验明客户端的身份，同时客户端也需要验明服务器的身份。k8s的认证载体为x509证书。在minikube集群中有一个统一的CA（默认路径为.minikube/ca.crt）来对证书进行验签。 双向认证发生在任何两个进行通信的组件中，下面列举一些例子： etcd集群内peer间通信是双向的，etcd peer既充当客户端，又充当服务端。因此既需要持有客户端证书，又需要持有服务端证书进行认证。 kube-apiserver与etcd之间的通信是单向的，kube-apiserver充当客户端，etcd充当服务端。因此kube-apiserver需持有客户端证书，etcd需持有服务端证书。 kubectl与apiserver的通信是单向的，kubectl充当客户端，etcd充当服务端，kubectl需要持有客户端证书，apiserver需要持有服务端证书。 …… 每个控制面组件在启动时会指定所使用到的证书，下例列举出apiserver的启动参数 # 获取kube-apiserver 相关配置 $ kubectl get pods/kube-apiserver-minikube -o yaml --namespace kube-system spec: containers: - command: - kube-apiserver - --advertise-address=172.17.0.40 - ...... # 用于验证访问apiserver客户端证书的CA根证书 - --client-ca-file=/var/lib/minikube/certs/ca.crt - .... # 与客户端通信的服务端证书即私钥 - --tls-cert-file=/var/lib/minikube/certs/apiserver.crt - --tls-private-key-file=/var/lib/minikube/certs/apiserver.key # 用于验证服务器证书的CA根证书 - --etcd-cafile=/var/lib/minikube/certs/etcd/ca.crt # 用于访问etcd的客户端证书 - --etcd-certfile=/var/lib/minikube/certs/apiserver-etcd-client.crt # 与etcd通信使用的私钥 - --etcd-keyfile=/var/lib/minikube/certs/apiserver-etcd-client.key # kubelet相关证书及私钥 - --kubelet-client-certificate=/var/lib/minikube/certs/apiserver-kubelet-client.crt - --kubelet-client-key=/var/lib/minikube/certs/apiserver-kubelet-client.key # kube-proxy相关证书及私钥 - --proxy-client-cert-file=/var/lib/minikube/certs/front-proxy-client.crt - --proxy-client-key-file=/var/lib/minikube/certs/front-proxy-client.key - --requestheader-client-ca-file=/var/lib/minikube/certs/front-proxy-ca.crt - .... 从上面不难看出，对于一条通信链路的服务端和客户端，都需要提供一个证书，一个私钥，和一个验证对端证书的CA根证书。 再来看看我们的kubeconfig，里面有kubectl的客户端证书及秘钥，以及验证apiserver服务端证书的CA根证书。 $ kubectl config view apiVersion: v1 clusters: - cluster: # 用于验证apiserver服务端证书的根证书 certificate-authority: $HOME/.minikube/ca.crt server: https://172.17.0.40:8443 name: minikube contexts: - context: cluster: minikube user: minikube name: minikube current-context: minikube kind: Config preferences: {} users: - name: minikube user: # kubectl持有的客户端证书及私钥 client-certificate: $HOME/.minikube/profiles/minikube/client.crt client-key: $HOME/.minikube/profiles/minikube/client.key ","date":"2021-07-11","objectID":"/posts/minikube-tls/:2:0","tags":["k8s","tls"],"title":"Minikube中的TLS认证探秘","uri":"/posts/minikube-tls/"},{"categories":["探索与实战"],"content":"寻幽 下面我们来验证一下kubectl与apiserver的证书及双向认证。 从上一节可以推断出kubectl中CA $HOME/.minikube/ca.crt可以验证apiserver的服务端证书 /var/lib/minikube/certs/apiserver.crt，apiserver的CA /var/lib/minikube/certs/ca.crt 可以验证kubectl的客户端证书$HOME/.minikube/profiles/minikube/client.crt，验证结果如下： # 服务端证书验证 $ openssl verify -CAfile ~/.minikube/ca.crt /var/lib/minikube/certs/apiserver.crt /var/lib/minikube/certs/apiserver.crt: O = system:masters, CN = minikube error 7 at 0 depth lookup:certificate signature failure 139668477843096:error:0407006A:rsa routines:RSA_padding_check_PKCS1_type_1:block type is not 01:rsa_pk1.c:103: 139668477843096:error:04067072:rsa routines:RSA_EAY_PUBLIC_DECRYPT:padding check failed:rsa_eay.c:705: 139668477843096:error:0D0C5006:asn1 encoding routines:ASN1_item_verify:EVP lib:a_verify.c:218: # 客户端证书验证 $ openssl verify -CAfile /var/lib/minikube/certs/ca.cr ~/.minikube/profiles/minikube/client.crt $HOME/minikube/profiles/minikube/client.crt: O = system:masters, CN = minikube-user error 7 at 0 depth lookup:certificate signature failure 139864367138456:error:0407006A:rsa routines:RSA_padding_check_PKCS1_type_1:block type is not 01:rsa_pk1.c:103: 139864367138456:error:04067072:rsa routines:RSA_EAY_PUBLIC_DECRYPT:padding check failed:rsa_eay.c:705: 139864367138456:error:0D0C5006:asn1 encoding routines:ASN1_item_verify:EVP lib:a_verify.c:218: 双方验证均未通过，难道是根证书有问题？ # 查看apiserver客户端证书 $ openssl x509 -text -in /var/lib/minikube/certs/apiserver.crt -noout Certificate: Data: Version: 3 (0x2) Serial Number: 2 (0x2) Signature Algorithm: sha256WithRSAEncryption Issuer: CN=minikubeCA Validity Not Before: Aug 8 09:07:42 2020 GMT Not After : Aug 9 09:07:42 2021 GMT Subject: O=system:masters, CN=minikube Subject Public Key Info: ...... X509v3 extensions: X509v3 Key Usage: critical Digital Signature, Key Encipherment X509v3 Extended Key Usage: TLS Web Server Authentication, TLS Web Client Authentication X509v3 Basic Constraints: critical CA:FALSE X509v3 Subject Alternative Name: ...... ...... # 查看kubectl ca根证书 $ openssl x509 -text -in /var/lib/minikube/certs/ca.crt -noout Certificate: Data: Version: 3 (0x2) Serial Number: 1 (0x1) Signature Algorithm: sha256WithRSAEncryption Issuer: CN=minikubeCA Validity Not Before: Aug 8 09:07:41 2020 GMT Not After : Aug 7 09:07:41 2030 GMT Subject: CN=minikubeCA ...... apiserver服务端证书和kubectl的CA证书输出也符合预期，前者的Issuer与后者的Subject相同，说明前者的证书是后者颁发的；后者Issuer与Subject相同，说明其是一个合法的自签名证书。 我是谁，我在哪… 明明服务器上kubectl可以访问到apiserver，证书的颁发关系也没问题，而且TLS双向认证原理也是无懈可击，为什么openssl证书验证就是有问题的呢？ ","date":"2021-07-11","objectID":"/posts/minikube-tls/:3:0","tags":["k8s","tls"],"title":"Minikube中的TLS认证探秘","uri":"/posts/minikube-tls/"},{"categories":["探索与实战"],"content":"溯源 上述结论存在一个致命的错误 Bug 证书A的Issuer与证书B的Subject相同，说明A的证书是B颁发的 这个错误犯得自己都想笑，x509证书中Issuer代表颁发机构，而Subject代表证书所有者，A的Issuer与B的Subject相同，只能说明A的证书颁发机构与B的所有者重名，并不能说明A一定是B颁发的。这就好比小明的妈妈叫小丽，但是叫小丽的不一定是小明的妈妈。证书认证本质上是通过数字签名进行的，签名的私钥是唯一的，但机构名称并不唯一，因此验签失败并不与实际矛盾。 但是事出反常必有妖，叫小丽的可能有很多，但是一个房子里就两个人，并且他们都叫小丽就很不寻常。这就让我开始怀疑环境中是不是有另一套minikubeCA根证书，即存在不止一个minikube？ 在验证kubectl客户端证书的时候留意到~/.minikube的配置目录中也有个apiserver.crt $ tree ~/.minikube minikube ├── addons ├── ca.crt ├── ca.key ├── ca.pem ├── cert.pem ├── certs │ ├── ca-key.pem │ ├── ca.pem │ ├── cert.pem │ └── key.pem ├── config │ └── config.json ├── files ├── key.pem ├── last_update_check ├── logs ├── machines │ ├── minikube │ │ ├── config.json │ │ ├── id_rsa │ │ └── id_rsa.pub │ ├── server-key.pem │ └── server.pem ├── profiles │ └── minikube │ ├── apiserver.crt │ ├── apiserver.crt.49553cf0 │ ├── apiserver.key │ ├── apiserver.key.49553cf0 │ ├── client.crt │ ├── client.key │ ├── config.json │ ├── events.json │ ├── proxy-client.crt │ └── proxy-client.key ├── proxy-client-ca.crt └── proxy-client-ca.key 使用openssl使用Kubectl的服务端验证根证书验证一下这个证书，验证通过。 $ openssl verify -CAfile ~/.minikube/ca.crt ~/.minikube/profiles/minikube/apiserver.crt $HOME/.minikube/profiles/minikube/apiserver.crt: OK 这时候另一个疑惑就涌上来了：为什么kubectl客户端证书和apiserver服务端证书会放在完全不相关的两个目录下？又挖一挖config文件，发现有auth path相关的路径配置。 $ cat ~/.minikube/machines/minikube/config.json { .... { \"AuthOptions\": { \"CertDir\": \"$HOME/.minikube\", \"CaCertPath\": \"$HOME/.minikube/certs/ca.pem\", \"CaPrivateKeyPath\": \"$HOME/.minikube/certs/ca-key.pem\", \"CaCertRemotePath\": \"\", \"ServerCertPath\": \"$HOME/.minikube/machines/server.pem\", \"ServerKeyPath\": \"$HOME/.minikube/machines/server-key.pem\", \"ClientKeyPath\": \"$HOME/.minikube/certs/key.pem\", \"ServerCertRemotePath\": \"\", \"ServerKeyRemotePath\": \"\", \"ClientCertPath\": \"$HOME/.minikube/certs/cert.pem\", \"ServerCertSANs\": null, \"StorePath\": \"$HOME/.minikube\" } } 尽管没看过minikube的源码，也没在官方文档上找到很明确的说法，但是基本上可以确定minikube启动的所有控制面组件使用的证书是在这里配置的，也就是完全存放在~/.minikubepath中。而pod中挂载的/var/lib/minikube/certs应该并非挂是宿主机对应的path上，毕竟minikube是运行在VM中的，挂载路径的灵活性便可想而知。 minikube的定位 Minikube is a tool that makes it easy to run Kubernetes locally. Minikube runs a single-node Kubernetes cluster inside a Virtual Machine (VM) on your laptop for users looking to try out Kubernetes or develop with it day-to-day. ","date":"2021-07-11","objectID":"/posts/minikube-tls/:4:0","tags":["k8s","tls"],"title":"Minikube中的TLS认证探秘","uri":"/posts/minikube-tls/"},{"categories":["探索与实战"],"content":"破疑 接下来的就是之前使我们步入泥淖的两个问题： 在本机执行kubectl为什么会出现x509证书认证失败？ 宿主机上为什么会有/var/lib/minikube/certs一系列证书？ 这两个问题有着很强的相关性，一个大胆的猜想就是本机连的apiserver是在/var/lib/minikube/certs中认证的。 首先来看一下apiserver的配置 # 查看apiserver的配置 $ kubectl get pods/kube-apiserver-minikube -o yaml --namespace kube-system spec: containers: - command: - kube-apiserver - --advertise-address=172.17.0.40 - --secure-port=8443 - --allow-privileged=true - --authorization-mode=Node,RBAC - --client-ca-file=/var/lib/minikube/certs/ca.crt ... podIP: 172.17.0.40 podIPs: - ip: 172.17.0.40 从apiserver的配置中我们可以看到对应的podIP并不是宿主机的ip，而是个虚拟机的ip。这个再结合minikube在虚拟机中运行k8s很容易理解。那么也就是说minikube并没有暴露在宿主机的8443端口。可是我们执行kubectl并不是返回端口connection refused，而是返回的x509认证失败，这也就是宿主机的8443端口被监听。使用ps查看apiserver的进程，结果居然存在2个进程。 这样之前的灵异现象都能串起来了：宿主机还有一个额外的minikube集群，并且对外暴露了宿主机8443端口，使用/var/lib/minikube/certs进行认证。 经过一番查证与折腾，发现在/etc/kubernetes下有一些kubeconfig file以及控制面组件的部署文件。 $ tree /etc/kubernetes /etc/kubernetes ├── addons │ ├── dashboard-clusterrolebinding.yaml │ ├── dashboard-clusterrole.yaml │ ├── dashboard-configmap.yaml │ ├── dashboard-dp.yaml │ ├── dashboard-ns.yaml │ ├── dashboard-rolebinding.yaml │ ├── dashboard-role.yaml │ ├── dashboard-sa.yaml │ ├── dashboard-secret.yaml │ ├── dashboard-svc.yaml │ ├── ingress-configmap.yaml │ ├── ingress-dp.yaml │ ├── ingress-rbac.yaml │ ├── storageclass.yaml │ └── storage-provisioner.yaml ├── admin.conf ├── controller-manager.conf ├── kubelet.conf ├── manifests │ ├── etcd.yaml │ ├── kube-apiserver.yaml │ ├── kube-controller-manager.yaml │ └── kube-scheduler.yaml └── scheduler.conf 然后在服务器上指定kubeconfig为admin.conf执行kubectl，果然结果来自另外的一个集群。这个集群应该是我在最早接触k8s时使用的版本比较低的minikube搭建的，至于为啥部署形态会成这样我也不清楚至今仍然未解。 观察这个Minikube部署的apiserver，的确对外暴露的宿主机的8443端口。 $ sudo KUBECONFIG=/etc/kubernetes/admin.conf kubectl get pods/kube-apiserver-XX --namespace kube-system -o yaml ...... spec: containers: - command: - kube-apiserver - --advertise-address=10.122.101.148 - --secure-port=8443 - --client-ca-file=/var/lib/minikube/certs/ca.crt - --tls-cert-file=/var/lib/minikube/certs/apiserver.crt - --tls-private-key-file=/var/lib/minikube/certs/apiserver.key - ...... ...... podIP: 10.122.101.148 podIPs: - ip: 10.122.101.148 qosClass: Burstable 将admin.conf中的证书与/var/lib/minikube/certs下的证书进行互相验签，均可通过。真相由此浮出水面。 ","date":"2021-07-11","objectID":"/posts/minikube-tls/:5:0","tags":["k8s","tls"],"title":"Minikube中的TLS认证探秘","uri":"/posts/minikube-tls/"},{"categories":["探索与实战"],"content":"前行 知道了问题的症结，需要向最初的目的前进了。先忽视掉上面揪出来的野minikube，尝试连接新搭建的minikube，另一个后续会通过一个额外的context加入到本地多集群管理中。 由于8443端口已经被先前的端口占用了，那么我们就选择暴露一个额外的端口38443吧。 # 首先启动minikube（我在启动前删除了之前部署的minikube数据），指定apiserver的端口为38443，指定apiserver的ip为10.122.101.148 # apiserver 端口其实不必指定，后续会介绍须引入本地端口转发来将服务暴露出去 $ minikube start --apiserver-ips=10.122.101.148 --apiserver-port=38443 # 查看apiserver的配置 $ kubectl get pods/kube-apiserver-minikube -o yaml --namespace kube-system spec: containers: - command: - kube-apiserver - --advertise-address=172.17.0.40 - --allow-privileged=true - --secure-port=38443 - --authorization-mode=Node,RBAC - --client-ca-file=/var/lib/minikube/certs/ca.crt ... podIP: 172.17.0.40 podIPs: - ip: 172.17.0.40 What? 不是设置了apiserver的ip为宿主机的ip了吗？为什么podIP还是虚拟机的ip？文档里还特意的解释了flag apiserver-ips的作用，就是要 make the apiserver available from outside the machine。 $ minikube start --help Starts a local Kubernetes cluster Options: --addons=[]: Enable addons. see `minikube addons list` for a list of valid addon names. --apiserver-ips=[]: A set of apiserver IP Addresses which are used in the generated certificate for kubernetes. This can be used if you want to make the apiserver available from outside the machine --apiserver-name='minikubeCA': The authoritative apiserver hostname for apiserver certificates and connectivity. This can be used if you want to make the apiserver available from outside the machine --apiserver-names=[]: A set of apiserver names which are used in the generated certificate for kubernetes. This can be used if you want to make the apiserver available from outside the machine --apiserver-port=8443: The apiserver listening port ...... apiserver-ips option is not working 这个issue专门描述了此问题，明确指出此参数仅会将对应的ip添加到证书SAN，不会修改apiserver的podIP。当然，作者困惑是否存在这种使用方式的场景。虽然不是很明确这样使用会带来什么样的问题（maybe端口冲突？安全？可扩展性？），但是作为初入坑k8s的同学来讲，这种简单的访问方式可能会降低一些我们的学习门槛。 apiserver-ips option is not working\" apiserver-ips option is not working 既然这样，怎样才能将apiserver可以被本地访问到呢？这个也简单，可以通过ssh本地端口转发进行。 # 将服务器10.122.101.148的38443端口转发到172.17.0.40的38443端口 $ ssh -L 10.122.101.148:38443:172.17.0.40:38443 -N -f 10.122.101.148 最后，只需要将我们的kubeconfig的server字段改成10.122.101.148:38443就可以开心的访问远程的minikube了。 x509证书扩展 将对应ip添加到证书SAN，这个解释我并不是很理解，直到后面做了个实验才有些感觉。在没指定apiserver-ips去curl https://10.122.101.148，会出现诸如Hostname 10.122.101.148 doesn’t match certificate’s altnames: “Host: XXX. is not in the cert’s altnames:XXX的错误，而指定了apiserver-ips=10.122.101.148后，apiserver的服务端证书便可以通过验证。这是因为该参数将ip加入到了服务端证书的SAN扩展字段中，使得10.122.101.148成为证书可信的域。 $ openssl x509 -text -in .minikube/profiles/minikube/apiserver.crt -noout X509v3 extensions: X509v3 Subject Alternative Name: DNS:minikubeCA, DNS:control-plane.minikube.internal, DNS:kubernetes.default.svc.cluster.local, DNS:kubernetes.default.svc, DNS: kubernetes.default, DNS:kubernetes, DNS:localhost, IP Address:10.122.101.148, IP Address:172.17.0.40, IP Address:10.96.0.1, IP Address:127.0.0. 1, IP Address:10.0.0.1 ","date":"2021-07-11","objectID":"/posts/minikube-tls/:6:0","tags":["k8s","tls"],"title":"Minikube中的TLS认证探秘","uri":"/posts/minikube-tls/"},{"categories":["探索与实战"],"content":"插曲 在验证双向认证时，为了避免两端都要使用openssl验证，便想通过curl去验证。使用curl验证的结果让我再次怀疑人生… # 执行双向验证，客户端验证服务端证书失败 $ curl https://10.122.101.148:38443 --cert ~/.minikube/profiles/minikube/client.crt --key ~/.minikube/profiles/minikube/client.key --cacert ~/.minikube/ca.crt curl: (60) server certificate verification failed. CAfile: ~/.minikube/ca.crt CRLfile: none More details here: http://curl.haxx.se/docs/sslcerts.html curl performs SSL certificate verification by default, using a \"bundle\" of Certificate Authority (CA) public keys (CA certs). If the default bundle file isn't adequate, you can specify an alternate file using the --cacert option. If this HTTPS server uses a certificate signed by a CA represented in the bundle, the certificate verification probably failed due to a problem with the certificate (it might be expired, or the name might not match the domain name in the URL). If you'd like to turn off curl's verification of the certificate, use the -k (or --insecure) option. # 关闭客户端的服务端证书验证，正常返回 $ curl https://10.122.101.148:38443 --cert ~/.minikube/profiles/minikube/client.crt --key ~/.minikube/profiles/minikube/client.key -k { \"paths\": [ \"/api\", \"/api/v1\", \"/apis\", \"/apis/\", ... ] } # 确认客户端CA对服务端的证书验证结果，认证通过 openssl verify -CAfile ~/.minikube/ca.crt ~/.minikube/profiles/minikube/apiserver.crt ~/.minikube/profiles/minikube/apiserver.crt: OK 上面的测试结果看上去互相矛盾，折腾了很久，大概查了下curl的文档，感觉自己做的并没有问题，大胆的怀疑一下是curl的版本问题，于是准备在一个curl版本更高的镜像里去执行这个curl命令。 # 在golang:1.16.2镜像中通过curl验证双向认证，成功 $ docker run --rm -v $HOME/.minikube:/minikube golang:1.16.2 curl https://10.122.101.148:38443 --cert /minikube/profiles/minikube/client.crt --key /minikube/profiles/minikube/client.key --cacert /minikube/ca.crt { \"paths\": [ \"/api\", \"/api/v1\", \"/apis\", \"/apis/\", ... ] } 果然是旧版本curl的问题。由于目前为止在这上面浪费了比较久的时间，并且感觉越往后排查越偏离初始方向，因此便未继续往下追溯。二者版本列举如下，希望自己未来有时间、有兴趣去往底层排查一下。 # 服务器10.122.101.148上curl版本 $ curl --version curl 7.47.0 (x86_64-pc-linux-gnu) libcurl/7.47.0 GnuTLS/3.4.10 zlib/1.2.8 libidn/1.32 librtmp/2.3 Protocols: dict file ftp ftps gopher http https imap imaps ldap ldaps pop3 pop3s rtmp rtsp smb smbs smtp smtps telnet tftp Features: AsynchDNS IDN IPv6 Largefile GSS-API Kerberos SPNEGO NTLM NTLM_WB SSL libz TLS-SRP UnixSockets # go:1.16.2 image中curl版本 $ docker run --rm -v $HOME/.minikube:/minikube golang:1.16.2 curl --version curl 7.64.0 (x86_64-pc-linux-gnu) libcurl/7.64.0 OpenSSL/1.1.1d zlib/1.2.11 libidn2/2.0.5 libpsl/0.20.2 (+libidn2/2.0.5) libssh2/1.8.0 nghttp2/1.36.0 librtmp/2.3 Release-Date: 2019-02-06 Protocols: dict file ftp ftps gopher http https imap imaps ldap ldaps pop3 pop3s rtmp rtsp scp sftp smb smbs smtp smtps telnet tftp Features: AsynchDNS IDN IPv6 Largefile GSS-API Kerberos SPNEGO NTLM NTLM_WB SSL libz TLS-SRP HTTP2 UnixSockets HTTPS-proxy PSL ","date":"2021-07-11","objectID":"/posts/minikube-tls/:7:0","tags":["k8s","tls"],"title":"Minikube中的TLS认证探秘","uri":"/posts/minikube-tls/"},{"categories":["探索与实战"],"content":"悟道 你永远不知道你不知道的事，只有学习才会让我们发现原本我们不知道的事，哪怕过程使我们谦(zi)卑。 最初只是想体验一下telepresence，仅仅是一个准备工作就牵出如此多的知识点，遇到问题是痛苦的，但寻找解决问题的方法是快乐的。 与安全相关的问题搞得多复杂都不为过，仅仅是k8s认证阶段中的证书认证这一步就如此的丰富，后面的鉴权、准入等过程会更加刺激。 工具的使用很皮毛，比如curl，openssl，不过比较复杂的工具往往在实际问题排查时仅需要最基本的使用方法。 仍然存在诸多基础知识盲区，比如 ssh端口转发， 数字签名，x509证书相关概念等，后面会有专门的文章来记录这些基础。 好记性不如烂笔头，文章落笔于解决问题的第二天，但是能记住的甚微，写文章时基本又根据history重放了一遍才将脉络重新梳理清楚。 ","date":"2021-07-11","objectID":"/posts/minikube-tls/:8:0","tags":["k8s","tls"],"title":"Minikube中的TLS认证探秘","uri":"/posts/minikube-tls/"},{"categories":["探索与实战"],"content":"启明 远程访问minikube 一文带你彻底厘清 Kubernetes 中的证书工作机制 Installing Kubernetes with Minikube Certificate Signing Requests apiserver-ips option is not working ","date":"2021-07-11","objectID":"/posts/minikube-tls/:9:0","tags":["k8s","tls"],"title":"Minikube中的TLS认证探秘","uri":"/posts/minikube-tls/"},{"categories":["整理与总结"],"content":"参考谢希仁 《计算机网络（第5版）》 ","date":"2021-06-27","objectID":"/posts/network/:0:0","tags":["网络"],"title":"《计算机网络》纲要整理","uri":"/posts/network/"},{"categories":["整理与总结"],"content":"概述 ","date":"2021-06-27","objectID":"/posts/network/:1:0","tags":["网络"],"title":"《计算机网络》纲要整理","uri":"/posts/network/"},{"categories":["整理与总结"],"content":"电路交换与分组交换 电路交换 需要建立物理连接，需要通过电线两两相连。 通话过程中，两个用户始终占用端到端的通信资源，线路传输效率比较低。 分组交换 存储转发技术，将报文划分成若干数据包（分组），并将地址等信息加入消息头封包。 使用特定协议，通过路由器转发分组。 对于高速网络，提高的仅仅是数据发送速率，而不是比特在链路上的传播速率，后者仅与传输介质有关。 ","date":"2021-06-27","objectID":"/posts/network/:1:1","tags":["网络"],"title":"《计算机网络》纲要整理","uri":"/posts/network/"},{"categories":["整理与总结"],"content":"OSI七层模型 应用层：直接为用户的应用进程提供服务。 传输层：为两个主机中进程间通信提供服务，由于每个主机可以同时运行多个进程，因此传输层有复用和分用的功能，一台主机上的多进程一般通过不同端口来区分。 网络层：为网络上不同主机提供通信服务，以IP数据报方式进行封装并传输。 数据链路层：IP数据报封装成帧，加入控制信息，并在相邻节点的链路上透明传输。 物理层：传输比特流。 ","date":"2021-06-27","objectID":"/posts/network/:1:2","tags":["网络"],"title":"《计算机网络》纲要整理","uri":"/posts/network/"},{"categories":["整理与总结"],"content":"网络分层特点 协议是控制对等层通信的规则集合，即协议是水平的。 服务由下层向上层通过层间接口提供，即服务是垂直的。本层服务无法看见下面的协议，即下面的协议对上面的实体是透明的。 底层的实体在封装上一层的数据包时，通常会加一个包头用以描述本层的信息。在解包时，对应层将对应的包头剥离并解析。 网络分层\" 网络分层 ","date":"2021-06-27","objectID":"/posts/network/:1:3","tags":["网络"],"title":"《计算机网络》纲要整理","uri":"/posts/network/"},{"categories":["整理与总结"],"content":"数据链路层 ","date":"2021-06-27","objectID":"/posts/network/:2:0","tags":["网络"],"title":"《计算机网络》纲要整理","uri":"/posts/network/"},{"categories":["整理与总结"],"content":"基本问题 封装成帧 将IP数据报前后添加首部和尾部，构成一个帧。 首部和尾部的一个作用是起到帧定界，此外还包含很多控制信息。 MTU表示最大传输单元，即帧的数据部分的长度上限。 透明传输 传输的文本可能与定界控制字符冲突，这样需要通过添加转义字符来将数据文本与控制字符区分出来，以便输入的任何字符都可以放在这样的帧中传输过去，这样的传输称为透明传输。 差错检验 现实通信链路不会是理想的，bit在传输过程中可能产生零一倒置，引发比特差错。 数据链路层常常通过采用CRC（循环冗余检验）来检错，并不能纠错。 数据链路层的差错检验只能检出比特差错，而无法检测出帧丢失，帧重复，帧失序等问题，因此数据链路层无法提供可靠传输。 注意 为什么当前网络协议中数据链路层不通过帧编号，确认和重传机制做到可靠传输呢？由于当前通信线路的质量大大提高，数据链路层的出错概率大大降低。因此广泛使用的网络协议中都不要求数据链路层提供可靠传输。一旦传输时出现了差错，那么改正差错由上层的TCP协议完成，从而提升通信效率。 ","date":"2021-06-27","objectID":"/posts/network/:2:1","tags":["网络"],"title":"《计算机网络》纲要整理","uri":"/posts/network/"},{"categories":["整理与总结"],"content":"局域网 拓扑 星型（使用最广泛） 令牌环形 总线型 树形 共享信道可以使多个用户共享通信媒体资源，主要有以下两种方法： 静态划分信道，即时分/频分/波分/码分等复用方式使得各用户分配到的信道资源正交，不会彼此发生冲突。但其利用率较低，代价较高，不适用于局域网。 动态媒体接入控制，又称多点接入，分为随机接入和受控接入两种。前者用户可以随机发送信息，如果发生碰撞就需要通过解决冲突的网络协议来处理冲突；后者需要服从某种控制来接入，常用于令牌环拓扑中的轮询控制，使用的较少。 ","date":"2021-06-27","objectID":"/posts/network/:2:2","tags":["网络"],"title":"《计算机网络》纲要整理","uri":"/posts/network/"},{"categories":["整理与总结"],"content":"以太网 采用随机接入的方式。 将数据链路层演进为MAC层（媒体接入层）。 采用曼彻斯特编码，解决连0/连1问题导致的无法从比特流中提取位同步问题。 由于多站共享一个信道，单个站无法做到同时发和收，因此以太网是半双工通信。 冲突解决协议采用CSMA/CD协议（载波监听多点接入/碰撞检测）。 多点接入表明其为总线型网络，多个站点共享信道。 载波监听表明发送前先监听，，尽量避免冲突的产生。 碰撞检测表示边发送边监听，在发送过程中通过传输信号的异动判断出其他人也在发送，从而检测出碰撞。此时应立即停止发送，避免持续浪费网络资源，并采用指数退避的方式重试。 集线器 集线器使得以太网从总线型拓扑演进到星型拓扑，采用的传输介质是双绞线。 使用集线器后的以太网仍是一个总线网，同一时刻只有一个站发送数据，扩展以太网是网桥的事。 集线器工作在物理层，仅做简单的比特转发，本质就是一个多接口转发器，不进行碰撞检测。 MAC层 MAC地址即物理地址，48位，固化在适配器中，具有唯一性。 MAC帧组成 目的地址 源地址 类型（描述上一层的协议类型） 数据（长度在46-1500字节之间，不足46字节加入填充字段） 帧检测序列（FCS） 扩展以太网 物理层通过使用光纤和光纤调制解调器进行电/光信号转换，可以将多个集线器连接起来，避免减少信号的衰减导致的CSMA/CA协议无法工作，本质上扩大了碰撞域。 扩大碰撞域\" 扩大碰撞域 网桥：将多个网段连接起来，扩展以太网范围，其依赖转发表来在各个网段中转发帧。 优势 各网段碰撞域相互隔离，不同网段的通信互不干扰，增大吞吐量。 扩大了物理范围，增加了接入的站数。 提升可靠性，网段之间互不干扰。 缺点 查找转发表增加了时延。 没有流量控制，当网络负载很重时，会出现丢帧情况。 接入站点数过多时会导致广播风暴 多个相互隔离的碰撞域\" 多个相互隔离的碰撞域 透明网桥 以太网上的站点不知道帧会经过哪几个网桥，这类网桥一旦接入局域网，无需经过人工配置转发表就可以工作。 透明网桥的自学习 初始时转发表为空。 网桥每收到一个帧时，就会记录其源地址和来源端口，构建转发表**（盲转发）**。 收到一个帧时，会先查转发表，如果目的地址存在，则向对应的端口转发，否则向除来源外的所有端口转发。 转发表项中会记录更新时间，在站地址发生变更时能够使得相关表项过期掉。 透明网桥使用生成树算法，避免帧在网络中兜圈子。 自学习示意图\" 自学习示意图 网桥与集线器的区别 网桥位于数据链路层，是基于存储转发，将完整的帧接收下来并校验无误后转发出去，网桥将两个局域网连接成一个大的网络，不同局域网碰撞域相互隔离；而集线器工作在物理层，是逐比特转发，只是扩大了碰撞域。 以太网交换机（L2交换机） 本质是多接口网桥，通过隔离碰撞域连接多个网络，提升吞吐率。 VLAN可以通过交换机实现，在MAC帧首部增加4个字节，通过其中的VID来标识此帧所属的VLAN。 ","date":"2021-06-27","objectID":"/posts/network/:2:3","tags":["网络"],"title":"《计算机网络》纲要整理","uri":"/posts/network/"},{"categories":["整理与总结"],"content":"网络层 ","date":"2021-06-27","objectID":"/posts/network/:3:0","tags":["网络"],"title":"《计算机网络》纲要整理","uri":"/posts/network/"},{"categories":["整理与总结"],"content":"特点 向上提供best-effect数据报服务，不提供质量保证。 实际链路传输由下层提供，且对网络层透明。 网络层使用IP地址标识每个站点，其中包括网络号用以标识网络，主机号用以在网络中唯一标识主机。 使用路由器作为中间设备，将不同的网络（可以是异构的）连通起来，构成一张逻辑网络。而网桥连接的多张网络在网络层而言只是一个网络，具有同一个网络号。 ","date":"2021-06-27","objectID":"/posts/network/:3:1","tags":["网络"],"title":"《计算机网络》纲要整理","uri":"/posts/network/"},{"categories":["整理与总结"],"content":"IP地址与硬件地址 IP地址是网络层上使用的地址，存放在IP数据报的首部；硬件地址是物理层和链路层使用的地址，存放在MAC帧的首部，MAC帧会将IP数据报作为自己的数据负载。 硬件地址对网络层不可见，换句话说，数据链路层及以下的通信对于网络层是透明的。 IP地址与MAC地址在数据流动中起到的作用\" IP地址与MAC地址在数据流动中起到的作用 ARP协议（地址解析协议）：根据IP地址解析物理地址。 主机的ARP高速缓存中存放IP地址到物理地址的映射表，并动态更新。 具体流程 如果ARP高速缓存中有，则直接获取。 否则在本网络广播一个ARP请求。 站点发现IP是本站的IP则将物理地址加入到一个ARP响应中并回复，其他站点忽略此请求。 将该响应的物理地址与请求的IP地址构建的映射关系加入ARP高速缓存。 同网桥的自学习类似，ARP缓存也存在生存时间（ttl）避免站点地址发生变化。 RARP协议（逆地址解析协议）：根据物理地址解析IP地址，逐渐被DHCP所取代。 为何要在物理地址的基础上构建IP地址，而不是直接使用物理地址来通信呢？ 异构网络的物理地址十分复杂，彼此之间的通信所带来的复杂转换过程基本上无法在用户主机上完成。使用统一的IP地址屏蔽掉了底层网络的复杂性。 ","date":"2021-06-27","objectID":"/posts/network/:3:2","tags":["网络"],"title":"《计算机网络》纲要整理","uri":"/posts/network/"},{"categories":["整理与总结"],"content":"IP数据报 格式：首部（可变部分+不可变部分）+ 数据部分。 首部固定部分（20字节） 版本：表示IP协议（v4, v6）。 首部长度：表示首部总长度，为4*x字节。 区分服务，一般不用此字段。 总长度：首部和数据的长度之和。 标识：用于串联分片。 标志：DF=1表示不允许分片，MF=1表示后续还有分片。 片偏移：用于描述分片的顺序，从而在收端组装分片。 生存时间：IP报文在路由器间转发的最大跳数，避免在网络中兜圈子。 首部校验和：CRC校验首部。 源地址 目的地址 可变部分 一般不使用，在ipv6中无可变部分。 需填充至4字节的整数倍。 ","date":"2021-06-27","objectID":"/posts/network/:3:3","tags":["网络"],"title":"《计算机网络》纲要整理","uri":"/posts/network/"},{"categories":["整理与总结"],"content":"路由 路由表 每条路由记录着 （目的网络地址，下一跳地址）。 路由表中记录着网络地址而非主机地址的原因是避免路由表过大，导致查表时引入较大的开销。 会有一些特例，在路由表中的地址是特定主机的地址，称为特定主机路由，一般用于排查问题。 在路由表中没有找到网络地址时，会走默认路由。 路由转发时，不会改变数据报的源地址与目的地址，而是通过ARP协议将路由表中的网络地址转为MAC地址进行转发，IP地址屏蔽了底层帧传输细节。 分组转发算法 从数据报首部获取目的IP地址D，得到网络地址N。 若网络N与该路由器直接相连，则直接交付到特点的主机。 若路由表中有地址D的特定路由，则直接把数据报转发给下一跳所对应的路由器。 若路由表中有到达网络D的路由，则把数据报转发给下一跳所对应的路由器。 若路由表中有默认路由，则将数据报转发给默认路由器。 以上均不满足则报错。 ","date":"2021-06-27","objectID":"/posts/network/:3:4","tags":["网络"],"title":"《计算机网络》纲要整理","uri":"/posts/network/"},{"categories":["整理与总结"],"content":"子网与超网 子网出现的原因 IP地址空间利用率低。 每个物理网络一个网络号会使路由表太大导致性能变坏。 两级IP地址不够灵活 子网特点 原物理网络基础上，划分出若干个子网，由两级变三级。 对外仍变现为一个网络，减少外网路由表的条目数，通过多分一级变线性为乘法。 划分子网后，路由表多了一列子网掩码，在路由查找时会多一步将IP地址与子网掩码进行与运算获取网络地址，再进行匹配查找。 超网（CIDR，无分类编址）特点 消除了A,B,C类地址及划分子网的概念，通过引入网络前缀的概念使得网络的划分更灵活。 从三级编址**\u003c网络号，子网掩码，主机号\u003e回到了两级编址\u003c网络前缀，主机号\u003e**。 采用最长前缀匹配从而进行能匹配得更具体。 通过二叉查找树的数据结构提升路由查找效率。 超网出现的原因 为解决传统IP分类及子网划分引起的IP地址分配不灵活，从而降低IP地址利用率低的问题。 ","date":"2021-06-27","objectID":"/posts/network/:3:5","tags":["网络"],"title":"《计算机网络》纲要整理","uri":"/posts/network/"},{"categories":["整理与总结"],"content":"路由协议 自治系统AS 单一技术管理下的一组路由器。 典型的一个ISP就是一个AS。 本质上是一个网络单元，内部表现同质，对外部表现为一个整体。 内部网关协议（IGP）：一个AS内部使用的路由选择协议。 RIP OSPF 原理描述 基于距离（跳数）向量的路由选择协议 基于代价的最短路径优先算法，使用链路状态协议 使用算法 距离向量算法（基于ford算法） 洪泛法+Dijkstra最短路径算法 交换对象 相邻下一跳路由器 相邻的所有路由器 交换内容 本路由器所知道的全部信息（到所有网络的距离） 本路由器与相邻所有路由器的链路状态（为构建网络拓扑图） 交换间隔 固定时间间隔 发生变化时 限制 跳数不超过16 - 传输方式 UDP IP数据报 适用场景 网络规模小的场景（少于最大跳数限制） 网络和规模大的场景 优势 实现简单，开销较小 更新过程收敛的快；代价相同的路径可以通过负载均衡策略选择 劣势 网络故障时，将消息传递给所有的路由器时间很慢；只会选择一条跳数最小的路径 协议负载，需维护链路状态数据库，开销较大 外部网管协议（BGP） 需考虑的问题 网络规模太大，使得AS之间的路由选择很困难。 AS之间是异质的，路由选择时需考虑相关策略。 核心：力求找到一条比较好的路由，而非选择最佳路由。 ","date":"2021-06-27","objectID":"/posts/network/:3:6","tags":["网络"],"title":"《计算机网络》纲要整理","uri":"/posts/network/"},{"categories":["整理与总结"],"content":"虚拟专用网VPN 机构内部使用专用地址，节省公网地址资源。 因特网中所有路由器对目的地址是专用地址的数据报一律不行进转发。 专用IP地址集合： 10.*.*.* 172.[16-31].*.* 192.168.*.* VPN：用于外网/专网/远程接入专用互联网。 实现方式：IP隧道技术 隧道技术示意图\" 隧道技术示意图 ","date":"2021-06-27","objectID":"/posts/network/:3:7","tags":["网络"],"title":"《计算机网络》纲要整理","uri":"/posts/network/"},{"categories":["整理与总结"],"content":"网络地址转换NAT 用于专用网内的一台主机与外网进行通信。 NAT路由器（一般是网关）需要有公网IP，专网内的主机通过公网IP与外界通信。 NAT本质上是通过端口映射的方式实现多机同时与外界通信的，即一个主机的请求映射到公网IP：特定端口上，与外部的通信地址就是该形式，在NAT路由器侧进行转换。 根据通信方向将NAT分为sNAT与dNAT。 sNAT：专网内主机访问外网。 dNAT：外网访问专网内主机。 ","date":"2021-06-27","objectID":"/posts/network/:3:8","tags":["网络"],"title":"《计算机网络》纲要整理","uri":"/posts/network/"},{"categories":["整理与总结"],"content":"其他 PING使用了ICMP（网际控制协议）协议进行报文信息交换。 IGMP（网际组管理协议）用于通知多播路由器本局域网中是否有主机加入或退出了某多播组。 ICMP，IGMP，OSPF报文均在IP层传输。 ","date":"2021-06-27","objectID":"/posts/network/:3:9","tags":["网络"],"title":"《计算机网络》纲要整理","uri":"/posts/network/"},{"categories":["整理与总结"],"content":"传输层 传输层与网络层的区别 网络层为主机之间提供逻辑通信（主机之间），传输层为应用进程之间提供端到端的逻辑通信（进程之间）。 两个主机上的多进程通信是在IP协议上加上一层端口的概念区分开来的。 IP数据报只检验首部，而TCP/UDP的检验是首部+数据。 ","date":"2021-06-27","objectID":"/posts/network/:4:0","tags":["网络"],"title":"《计算机网络》纲要整理","uri":"/posts/network/"},{"categories":["整理与总结"],"content":"UDP协议 仅在IP数据报服务上加了复用/分用及差错检测的功能。 特点 无连接。 尽最大努力交付，不可靠（校验有误后就丢弃掉）。 面向报文，一次交付一个完整报文。 无拥塞控制。 支持单播，多播，广播通信。 首部开销小（8字节，源端口、目的端口、长度、校验和），传输速度快。 ","date":"2021-06-27","objectID":"/posts/network/:4:1","tags":["网络"],"title":"《计算机网络》纲要整理","uri":"/posts/network/"},{"categories":["整理与总结"],"content":"TCP协议 特点 面向连接，虚连接。 只能点对点，无法实现一对多，TCP的端点是Socket，形如IP:PORT。 提供可靠交付，保证数据无差错、不丢失、不重复、不失序。 全双工通信。 面向字节流，即不像UDP一次交付一个完整报文，而是根据窗口值和网络拥塞决定报文段的大小。只是最终接收方应用程序需要和发送方应用程序发出的字节流完全一样。 TCP报文的首部 源端口和目的端口。 报文段序号，按字节顺序编号，起始序号需要在TCP建立连接时确认。 确认号，期望收到对方下一个报文段的第一个数据字节的序号。 数据偏移，指出TCP首部长度，因为TCP首部是变长的。 保留位 控制位（6位） 紧急URG：表明报文为紧急数据，不受接收窗口值限制。 确认ACK：表明此信息为确认信息。 推送PSH：表明报文需要尽快将报文交付给应用程序。 复位RST：表明因为某种原因需要释放连接。 同步SYN：表明该报文用于请求建立TCP连接。 终止FIN：表明该报文用于请求释放TCP连接。 窗口，接收窗口值。 检验和 紧急指针，URG=1时生效，表明紧急数据字节数。 选项，长度可变。 可靠传输 停止等待协议 又称为自动重传请求（ARQ） 每发送完一个分组就停止发送，等待对方确认，收到确认后再发送下一个分组。 一段时间（略大于RTT）后没有收到收端的分组确认，便会重传。因此要求发送完分组必须暂时保留已发送的副本，此外分组和确认分组需要进行编号来确认是否发送成功。 ARQ协议比较简单，但信道利用率很低，可以通过利用流水线技术予以改造（连续ARQ协议）。 连续ARQ协议 在发送窗口内的多个分组可以连续发送出去，不需要等待对方的确认。 接收方采用累积确认，即对按序到达的最后一个分组发送确认。 滑动窗口协议 本质是连续ARQ协议，滑动窗口以字节为单位，而非以报文为单位。 TCP流量控制的实现，流量控制的作用是让发送方的发送速率不要太快，要让接收方来得及接收。 窗口内可能包含两类数据，可以使用三个指针来标识，其中P1、P3为窗口前后沿，P2为两类数据的分界。 已发送但未收到确认（P2-P1），此类数据需要被缓存住，以备重传。 允许发送但尚未发送（P3-P2）。 发端和收端均有一个窗口值，发送窗口会受接收窗口的调节（发送窗口\u003c=接收窗口），因此接收窗口是根据接收端处理能力动态变化的。不过发送窗口和接收窗口并不总是一样大，因为通过网络进行窗口的同步存在延时。 为何发送窗口可能小于接收窗口? 发送窗口除了受流量控制的调节外，还受拥塞控制的调节。 在拥塞控制中，引入了拥塞窗口的概念，因此为避免网络拥塞，发送窗口需要小于拥塞窗口。即 发送窗口=min(接收窗口，拥塞窗口) 接收方需要有累积确认的能力，对于未按序到达的数据，建议接收方可以将其缓存起来（而非直接丢弃）以提升传信率。 由于累积确认只会传递按序到达的最后一个分组的确认消息，在网络有较多的丢包情况下，发端会重传很多数据，加速网络的恶化。因此引入选择确认(SACK)进行优化，其可以在ACK报文首部中描述已到达消息的边界。 如果每次传输的报文数据相对于TCP首部很小，那么传输效率会很低，滑动窗口存在以下问题。 当用户数据逐字发送时，会引起单个TCP报文数据内容过短。可以通过发送方攒batch方式将数据缓存起来发送。 糊涂窗口问题，即收端逐字节腾出接收窗口空间，导致发送窗口一直很小。此问题可以通过让接收方攒batch方式批量增大接收窗口。 接收窗口为0时是否可能引发死锁？ 如果接收窗口从0发生变化时，其会向发送方同步接收窗口。但如果此同步信息丢失了，那么发送窗口是否会一直为0，发端无法发送数据，收端接收不到数据，且没有变更窗口值的打算，是不是会陷入死锁的状态？ 不会，首先需要明确窗口的同步报文不存在确认机制，同样也不存在超时重传机制。为了避免上述死锁的问题，TCP连接维护一个计时器，当接收窗口为0时，计时器开始计时，若计时到期则发送一个零窗口探测报文，对方会在确认这个报文时给出当前的窗口值。 拥塞控制 网络拥塞主要是由于对资源的需求大于可用资源产生，引起网络拥塞的可能原因列举如下。 结点缓存的容量太小，导致到达该结点的分组被丢弃。 处理机处理时间太慢，导致队列逐渐被灌满，后到达的请求会被丢弃。此外处理速度慢，可能导致驻留在队列时间过长，超过了超时重传间隔，引起重传。 拥塞控制的核心思想在于通过控制发送方发送速率，防止过多数据注入到网络，避免网络中的路由器或链路出现过载。 拥塞控制的方法 慢开始：发送方维护一个拥塞窗口，发送起始窗口值为1，之后每轮窗口值翻倍，直到超过了慢开始门限 ssthresh。当发生拥塞时，ssthresh减半（乘法减小），从头进行慢开始。 拥塞避免：当拥塞窗口达到了ssthresh，窗口值开始逐1递增（加法增大），以降低发送增速。 快重传：当收端收到一个失序的报文就立即发送一个重复确认，当收端连续收到3个重复确认就立即重传报文，而无需等待此报文的重传计时器到期。快重传用于尽早重传未被确认的报文段，快速发现拥塞。 快恢复：当发生乘法减小时，并不从头执行慢开始，而是将拥塞窗口设为ssthresh的一半，之后开始进行加法增大。 全局同步 当网络拥塞发生时，缓存队列已满，新来的分组全部被丢弃（尾部丢弃策略），此时所有TCP连接都会触发重传，从而触发乘法减小，这就导致了TCP中的全局同步问题。 全局同步导致全网通信量可能瞬时减小很多，而一段时间后又会增大很多。 可以通过随机早期检测RED策略来改善全局同步问题，此策略核心是设置软硬门限；在软门限内，不丢弃任何报文，而在软门限和硬门限间，以一个自适应概率丢弃报文；当超过了硬门限，则采用尾部丢弃策略。RED可以将批量的乘法减小预打散，以缓解全局同步问题。 TCP的连接管理 连接建立 三次握手用以同步双方序号。 建立连接为何需要3次握手，而不是2次或者4次？ 由于建立连接需要双方同步一些信息（主要是序号），而在不可靠信道中完成可靠的同步，至少需要3次通信。 如果是两次的话，当一个历史握手请求由于滞留在网络中而在连接关闭后到达收端，收端给出的ACK会被发端忽略掉，此时收端已经进入ESTABLISHED状态，而发端又不会向收端发信，导致资源会出现浪费。 理论上双方互相确认是需要4次通信的，即像挥手一样的两个来回。只是建立连接时并不像释放连接那样在两个来回间还会继续发送未发完的数据。因此第一次握手的ACK和同步请求可以放在一个报文里（从图示可以看到），所以可以减少一次握手。 连接释放 四次挥手 前两次挥手由主动方发起，被动方确认，关闭主动方的连接。 被动方等待数据发送完。 后两次回收由被动方发起，主动方确认，关闭被动方的连接。 TIME-WAIT的作用 主动端发送最后一个ACK时进入TIME-WAIT状态，需要等待2MSL才变更到CLOSED状态，有以下两个原因。 最主要的原因是确保被动端收到了确认消息并正常关闭。如果此ACK丢失了，被动端可以重传FIN报文，主动端可以重新发送ACK。如果主动端跳过TIME-WAIT状态直接进入CLOSED，其无法重传ACK，被动端也无法正常的进入CLOSED。 为了确保在网络中兜圈子的报文进入到下一次连接中，可以在此次TIME-WAIT阶段消化掉。 ","date":"2021-06-27","objectID":"/posts/network/:4:2","tags":["网络"],"title":"《计算机网络》纲要整理","uri":"/posts/network/"},{"categories":["整理与总结"],"content":"应用层 ","date":"2021-06-27","objectID":"/posts/network/:5:0","tags":["网络"],"title":"《计算机网络》纲要整理","uri":"/posts/network/"},{"categories":["整理与总结"],"content":"域名系统DNS 域名系统 将人们使用的机器的名字转换为IP地址。 因特网上的域名系统是由分布式域名服务器实现的。 使用UDP传输。 域名服务器 分类 根域名服务器，知道所有顶级域名服务器的域名和IP地址，是最高层次的域名服务器。 顶级域名服务器，负载管理在该顶级域名服务器注册的所有二级域名。 权限域名服务器，负责一个区的域名服务器，一个域下可能会有多个区。 本地域名服务器，也称为默认域名服务器，离用户较近，可以解析同一个ISP下的所有域名，是向外查询的入口。 解析方式 递归查询 如果DNS服务器不知道被查询域名的IP地址，那么其就以DNS client身份向其他根域名服务器发出查询请求报文，而不是告知主机下一个查询DNS服务器的地址让主机自己查询。 一般用于主机向本地域名服务器的查询。 迭代查询 当域名服务器收到迭代查询请求报文时，要么给出所要查询的IP地址，要么告诉本地域名服务器下一步应向那个域名服务器进行查询，并不充当DNS client帮其查询。 一般用于本地域名服务器向根域名服务器的查询。 高速缓存 为提高DNS查询效率，减少解析所传的报文数量。 存放最近查询过的域名以及从何处获得域名映射信息的记录。 可以是域名对应的IP。 也可以是域名对应顶级域名服务器的IP地址。 为防止无法感知到域名发生变动，DNS缓存一般会有一个过期时间。一般而言，DNS发生变动的频率较低，缓存与数据库的一致性影响不大。（在云原生的某些场景下DNS变化较为频繁，DNS缓存会成为瓶颈。） ","date":"2021-06-27","objectID":"/posts/network/:5:1","tags":["网络"],"title":"《计算机网络》纲要整理","uri":"/posts/network/"},{"categories":["整理与总结"],"content":"文件传输协议FTP/TFTP FTP基于TCP，TFTP基于UDP FTP通过复制整个文件以实现文件共享，如果需要修改文件，需要先获取文件的一个本地副本，在副本上进行修改，然后再将修改后的文件传回。 FTP基本原理 一个主进程负责接收新的请求。 若干从属进程，负责处理单个请求。 FTP的客户端与服务器间要建立两个并行的TCP连接，控制连接和数据连接，控制连接在会话期间一直打开，客户端传输请求通过控制连接发送给服务端的控制进程，控制连接不用于传输文件；数据连接用于传输文件，服务端控制进程收到客户端的请求后便会创建数据传输进程和数据连接，用来传输文件。FTP的数据面与控制面相互分离。 熟知端口是21（监听）和20（传输）。 FTP缺陷：复制整个文件实现共享不够灵活，当需要在原有的文件作出一点修改时，传输整个文件。而NFS可以允许应用进程打开一个原地文件，并在该文件的某个特定位置开始读写数据，因此在网络上传输的只是少量的修改数据。 TFTP工作原理 类似停止等待协议，发送数据需要确认。 熟知端口是69。 ","date":"2021-06-27","objectID":"/posts/network/:5:2","tags":["网络"],"title":"《计算机网络》纲要整理","uri":"/posts/network/"},{"categories":["整理与总结"],"content":"万维网WWW 统一资源定位符URL 用于标志分布在整个因特网上的万维网文档。 组成：\u003c协议\u003e://\u003c主机\u003e:\u003c端口\u003e/\u003c路径\u003e。 最常使用的协议是http，其次是ftp。 超文本传输协议 HTTP 无状态，使用TCP传输。 从浏览器点击一个连接发生的事件： 浏览器分析URL并通过DNS解析出IP。 浏览器向此IP服务器建立TCP链接。 浏览器发送读取文件的命令。 服务器将对应的文件以HTTP response的方式返回给浏览器。 释放TCP连接。 浏览器将收到的数据进行渲染，将结果返回给用户。 HTTP 1.1 vs HTTP 1.0 在HTTP 1.0中每个http请求都会创建一个TCP连接，因此一个GET命令需要2RTT；此外，短连接的频繁创建与销毁会影响数据传输效率，因为每次创建后数据的发送都会历经一个慢开始的过程。 HTTP 1.1支持了长连接，减少了频繁建立TCP连接的开销。此外还支持pipeline技术，以缩短TCP连接空闲时间，提升服务器资源利用率。 HTTP 2.0在HTTP 1.1 pipeline基础上又提升了复用程度，此外消息的传输从明文变为二进制字节流，提升传输效率。 代理服务器可用作万维网高速缓存，用户的请求到达proxy后，如果发现有缓存则直接传递。否则proxy充当http client向服务器发起请求，并将响应缓存起来。 Cookie：由服务器返回给浏览器，记录一些用户信息，在下次发http请求时连同此信息发送给服务器。存在的核心原因是http是无状态的。 检索系统 搜索引擎分类 全文搜索引擎：通过蜘蛛在网络链接间爬行，建立一个大型的在线数据库，用户输入关键词在此数据库中搜索结果。 分类目录搜索引擎：数据库是按目录分类组织的，用户需要按设计好的目录逐级查询。 垂直所有引擎：相比全文所有引擎，更加针对某一特定领域、特定人群或特定需求提供搜索服务，即在某个行业知识上下文中进行关键词搜索。 元搜索引擎：将用户请求发到多个独立的搜索引擎上搜索，将结果统一处理，称为搜索引擎之上的搜索引擎。 ","date":"2021-06-27","objectID":"/posts/network/:5:3","tags":["网络"],"title":"《计算机网络》纲要整理","uri":"/posts/network/"},{"categories":["整理与总结"],"content":"电子邮件 主要构成组件 用户代理（UA） 邮件服务器 邮件发送协议（如SMTP）及邮件读取协议(如POP3) SMTP协议和POP3协议 二者均是基于TCP传输。 从UA发送到发送方邮件服务器的过程使用了SMTP协议。 从发送方邮件服务器向接收方邮件服务器传输使用了SMTP协议。 UA从接收方邮件服务器读取邮件的过程使用了POP3协议。 为什么不将邮件服务器程序植入到UA中？ 并非所有计算机都具有运行邮件服务器的条件。 邮件服务器程序需要24小时运行，而个人PC通常不具有long running的特性。 ","date":"2021-06-27","objectID":"/posts/network/:5:4","tags":["网络"],"title":"《计算机网络》纲要整理","uri":"/posts/network/"},{"categories":["整理与总结"],"content":"动态主机配置协议 DHCP 作用：自动进行网络配置。 在计算机第一次连入到因特网时，需要相应的网络配置。 IP地址 子网掩码 默认路由器的IP地址 域名服务器的IP地址 计算机在网络中的位置发生变化时，需要更新网络配置，因此需要采用自动协议配置方式。 DHCP是基于UDP的（需要广播），知名端口是68（client）与67（server）。 工作原理 待配置的主机广播一个发现报文，用以寻找DHCP server。 DHCP中继路由器发现此报文，会以单播形式转发给DHCP server。 DHCP server将网络配置信息及租用期返回给DHCP中继路由器。 DHCP中继路由器将其返回给主机。 主机获取到对应的网络配置并应用，同时计算租期。 租期临近时向DHCP server发起续约请求。若同意则更新租期，否则发送发现报文重新获取网络配置。 ","date":"2021-06-27","objectID":"/posts/network/:5:5","tags":["网络"],"title":"《计算机网络》纲要整理","uri":"/posts/network/"},{"categories":["读书笔记"],"content":"参考王爽《汇编语言》 CPU读写外部设备需要如下交互信息（分别对应三大逻辑总线） 地址信息：存储单元的地址。 控制信息：器件的选择，读或写的命令。 数据信息：读或写的数据。 寄存器的作用 CPU可直接读写的部件，可以通过改变寄存器的内容实现对CPU的控制。 寄存器cheat sheet 名称 类型 作用 AX 通用寄存器 用于一般的数据传递 BX 通用寄存器 用于表示偏移地址，如mov ax [bx]将ds:[bx]中的内容送入ax CX 通用寄存器 用于存储循环变量，cx中的值会影响loop指定的执行结果，cx为零时会跳出循环 SI/DI 配合BX指明内存单元的偏址，如[bx+si+idata] SP 存放栈顶的偏移地址 IP 指令指针寄存器，存放代码段的偏址 BP 栈内偏址，主要用于指向/寻找栈内的某个地址的元素 DS 段寄存器 存放数据段的寄存器，配合[addr]做段内寻址 SS 段寄存器 存放栈的段地址，配合SP/BP做段内寻址 CS 段寄存器 存放代码段的寄存器，配合IP做段内寻址 Flag 标志寄存器 用来存储相关指令的某些执行结果，从而为CPU相关指令提供行为依据 标志寄存器标志位 作用 ZF 零标志位，记录指令执行结果是否为0 PF 奇偶标志位，记录相关指令执行后，所有bit位中1的个数是否为偶数 SF 符号标志位，记录相关指令执行后，结果是否为负 CF 进位标志位，在无符号数运算时，记录了运算结果的最高有效位的进位值 OF 溢出标志位，用于标识指令执行结果是否溢出 DF 方向标识位，在串处理指令中，控制每次操作后si, di的增减 TF 调试标志位，TF=1时，表示进入单步执行 IF 中断允许标志位，表示能否接收外部中断请求，为1时能响应外部中断，反之屏蔽 8086CPU是16位机，但却有20位地址总线（1MB的寻址能力），无法做到简单的一一映射，其合成物理地址的方式如下 通过两个地址16位地址合成一个20位地址：物理地址=基址+偏址。 在8086CPU中物理地址合成公式为：物理地址=段地址*16+偏移地址。 内存并没有分段，段的划分来自CPU。 将若干的地址连续的内存单元看做一个段，用段地址*16定位段的基址，用偏移地址定位段中的内存单元。 CPU如何区分出内存中存放的是数据还是指令呢？ 数据和指定在内存中的存储形式是一致的，都是二进制信息 CPU将CS:IP指向的内存单元中的内容看做指令，将DS:[addr]指向的内存单元中的内容看做数据 SS:SP用于指向栈顶元素，需要注意栈顶越界的问题。 内存单元的描述 完整的描述一个内存单元需要两种信息：内存单元的地址和内存单元的长度。 mov ax, [0]：将ds:[0]的内容送入ax中，内存单元的长度为2字节（即一个字单元，因为是送入到ax）中。 move al, [0]：将ds:[0]的内容送入al中，内存单元的长度为1字节（即一个字节单元）。 转移指令：修改CS或IP的指令成为转移指令。只修改IP时称为段内转移（近转移），同时修改CS和IP的指令称为段间转移（远转移）。 无条件转移指令，如jmp。 jmp不需要转移的目的地址，而是通过相对位移来跳转。 条件转移指令。 循环指令，如loop。 过程 call \u0026 ret 中断 CPU在执行完当前正在执行的指令后，检测到从外部或者内部产生的特殊信息（中断信息），便转去处理这个特殊信息 内中断 除法溢出 单步执行（debug） 执行into 执行int指令 外中断 可屏蔽中断 不可屏蔽中断 中断处理程序入口通过中断向量表（中断类型码）来索引到（存储中断程序地址），对于8086而言，中断向量表存储在内存地址0处。中断向量表中，一个表项占两个字节，高字节存放段地址，低字节存放偏移地址 中断过程 从中断信息中获取中断类型码 标志寄存器入栈 设置标志位TF和IF为0 CS内容入栈 IP内容入栈 根据中断类型码定位到中断程序的入口 ","date":"2021-06-27","objectID":"/posts/asm/:0:0","tags":["汇编"],"title":"汇编入门速记","uri":"/posts/asm/"},{"categories":["Anecdotes"],"content":"晦涩的社会心理现象，别具一格的黏性表达。 ","date":"2021-06-20","objectID":"/posts/anecdote/:0:0","tags":["思辨"],"title":"有趣的经济学/心理学效应","uri":"/posts/anecdote/"},{"categories":["Anecdotes"],"content":"格雷欣法则（劣币驱逐良币） 含义：泛指价值不高的东西会把价值较高的东西挤出流通领域。 起源：古时候，因为铸造货币工艺的差别很大，人们就倾向于将那些足值的“良币”收藏起来，并试图将那些成色差的“劣币”转让给他人，这样市场上就同时流通着劣币和良币，且劣币得不到有效地制止和惩罚，如此循环，良币就会被驱逐出市场，质量差的货币反而在市场上流通了。 示例：当你的钱包里既有新钱又有旧钱时，你总是倾向于把那张破旧的先花出去。久而久之，流通中的货币越来越破旧，新钱却没有花出去，仍然呆在钱包里。 ","date":"2021-06-20","objectID":"/posts/anecdote/:1:0","tags":["思辨"],"title":"有趣的经济学/心理学效应","uri":"/posts/anecdote/"},{"categories":["Anecdotes"],"content":"马太效应 马太效应\" 马太效应 凡有的，还要加给他，叫他有余；凡没有的，连他所有的也要夺去 —— 太：13·12 含义：只要获得了每一点的成功，就会产生累积优势，使之拥有更大的机会获得更卓越的成就。 起源：有一个贵胄往远方去，要得国回来。便叫了他的十个仆人来，交给他们十锭银子（锭原文作弥拿，一弥拿约银十两），说，你们去作生意，直等我回来。他本国的人却恨他，打发使者随后去说，我们不愿意这个人作我们的王。他既得国回来，就吩咐叫那领银子的仆人来，要知道他们作生意赚了多少。头一个上来说，主阿，你的一锭银子，已经赚了十锭。主人说，好良善的仆人。你既在最小的事上有忠心，可以有权柄管十座城。第二个来说，主阿，你的一锭银子，已经赚了五锭。主人说，你也可以管五座城。又有一个来说，主阿，看哪，你的一锭银子在这里，我把他包在手巾里存着。我原是怕你，因为你是严厉的人。没有放下的还要去拿，没有种下的还要去收。主人对他说，你这恶仆，我要凭你的口，定你的罪。你既知道我是严厉的人，没有放下的还要去拿，没有种下的还要去收。为什么不把我的银子交给银行，等我来的时候，连本带利都可以要回来呢？就对旁边站着的人说，夺过他这一锭来，给那有十锭的。他们说，主阿，他已经有十锭了。主人说，我告诉你们，凡有的，还要加给他。没有的，连他所有的，也要夺过来。——路：19·12-26 示例：强者愈强弱者越弱，贫富差距大，赢家通吃。 ","date":"2021-06-20","objectID":"/posts/anecdote/:2:0","tags":["思辨"],"title":"有趣的经济学/心理学效应","uri":"/posts/anecdote/"},{"categories":["Anecdotes"],"content":"幸存者偏差 幸存者偏差\" 幸存者偏差 含义：当取得资讯的渠道，仅来自于幸存者时，此资讯可能会与实际情况存在偏差。 起源：1941年,第二次世界大战中，美国哥伦比亚大学统计学沃德教授应军方要求，利用其在统计方面的专业知识来提供关于《飞机应该如何加强防护，才能降低被炮火击落的几率》的相关建议。沃德教授针对联军的轰炸机遭受攻击后返回营地的轰炸机数据，进行研究后发现：机翼是最容易被击中的位置,机尾则是最少被击中的位置。沃德教授的结论是“我们应该强化机尾的防护”，而军方指挥官认为“应该加强机翼的防护，因为这是最容易被击中的位置”。教授认为： 统计的样本，只涵盖平安返回的轰炸机； 被多次击中机翼的轰炸机，似乎还是能够安全返航； 并非是机尾不易被击中，而是因为机尾被击中的飞机早已无法返航，寥寥几架返航的飞机都依赖引擎尚好。 示例：邻家小孩啥都比你强；炒股的大部分人赚得盆满钵满；SLA计算工具的可靠性（当系统由于断电等缘故大范围崩溃时，SLA计算工具也不work了，此时的不可用时间未被统计到）。 ","date":"2021-06-20","objectID":"/posts/anecdote/:3:0","tags":["思辨"],"title":"有趣的经济学/心理学效应","uri":"/posts/anecdote/"},{"categories":["Anecdotes"],"content":"路径依赖 马屁股决定火箭推进器\" 马屁股决定火箭推进器 含义：人类社会中的技术演进或制度变迁均有类似于物理学中的惯性，即一旦进入某一路径（无论是“好”还是“坏”）就可能对这种路径产生依赖，并在此基础上进行自我强化，初始时的细微差异会被放大，从而不成比例地引发了后来的境况，即过去的决定对未来产生较强的影响。 示例1——键盘的构造：肖尔斯发明的打字机，首先是按字母顺序排列，后来发现，经过专业训练的打字员正常击键时老是出故障，因为打字员打得太快，使得支撑键盘的机械杆相互碰撞产生故障，反而严重影响了打字速度。有一位工程师提议，打字机绞键的原因，一方面是字键的弹回速度慢，另一方面也是打字员的击键速度太快了，由于当时的机械工艺水平，无法再提高字键弹回的速度。他想，为什么不想法降低打字员的击键速度呢？而降低打字员的击键速度，最简单的方法给打字制造难度，打乱26个字母的排列顺序，把较常用的字母摆在较笨拙的手指下。比如，字母“O”是英语中第三个使用频率最高的字母，但却把它放在右手的无名指下；字母“S”和“A”，也是使用频率很高的字母，却被交给了最笨拙的左手无名指和小指来击打。同样理由，使用频率较低的“V”“J”“U”等字母却由最灵活的食指来负责。这样，这种毫无规律可寻专门为增加打字难度的打字机键盘设计出来了，并且逐渐定型下来。后来，即使制造工艺的发展，字键的弹回的速度远大于打字员的击键速度，但是键盘字母顺序却无法改动，这种“QWERTY”式组合的键盘就一直沿用至今。后来也有许多人发明了更方便科学的键盘，但是一直没有推广开来。 示例2——火箭推进器与马屁股：如果火箭需要运输更大的重量，就要直径更大、箭体更长，但火箭的推进器直径，美国国家的标准是四英尺八点五英寸，这个尺寸的选定的依赖链如下： 当时火箭推进器，是通过火车来的运输的，火箭推进器的大小由火车的两轨之间的距离决定； 火车轨道的距离参照英国老路上的辙迹； 辙迹间距是罗马战车的两个轮子之间的距离； 战车轮子间据依赖于拉动战车两匹马的屁股宽度。 ","date":"2021-06-20","objectID":"/posts/anecdote/:4:0","tags":["思辨"],"title":"有趣的经济学/心理学效应","uri":"/posts/anecdote/"},{"categories":["Anecdotes"],"content":"肥皂水效应 含义：是将批评夹在赞美中，将对他人的批评夹裹在前后肯定的话语之中，减少批评的负面效应，使被批评者愉快地接受对自己的批评。 起源：1923年，约翰·卡尔文·柯立芝成为美国总统，他有一位漂亮的女秘书，人虽长得很好，但工作中却常因粗心而出错。一天早晨，柯立芝看见秘书走进办公室，便对她说：“今天你穿的这身衣服真漂亮，正适合你这样漂亮的小姐。”这句话出自柯立芝口中，简直让女秘书受宠若惊。柯立芝接着说：“但也不要骄傲，我相信你同样能把公文处理得像你一样漂亮的。”果然从那天起，女秘书在处理公文时很少出错了。 解释：你见过理发师给人刮胡子吗？他要先给人涂些肥皂水，为什么呀，就是为了刮起来使人不觉痛。 ","date":"2021-06-20","objectID":"/posts/anecdote/:5:0","tags":["思辨"],"title":"有趣的经济学/心理学效应","uri":"/posts/anecdote/"},{"categories":["Anecdotes"],"content":"旁观者效应 旁观者效应\" 旁观者效应 含义：在紧急情况下，一个人在有其他人在场时，出手帮助之机会降低，援助的几率与旁观者人数负相关。换句话说，旁观者数量越多，他们当中任何一人进行援助之机会越低。 起源：1964年，纽约昆斯区，28岁的Kitty Genovese在经受了长达35分钟的性侵犯后最终被谋杀致死，共有38个本地区人性正常的居民经过，但没有一人提供帮助。 示例：项目中如果将责任明确到个人时，其可以完成的很好，但是如果没有明确的责任划分，项目往往会停滞不前，所谓三个和尚没水吃。比如明知陈旧代码存在问题，我们总是在假设别人会来修补这些问题。如果这些问题出现在我们的代码库中，我们很可能对之无动于衷，因为“这事儿跟我无关”。程序员对这样的问题通常的反应：这是别的程序员造成的问题，我才不管呢。这种“这事儿跟我无关”的态度很流行。 ","date":"2021-06-20","objectID":"/posts/anecdote/:6:0","tags":["思辨"],"title":"有趣的经济学/心理学效应","uri":"/posts/anecdote/"},{"categories":["Anecdotes"],"content":"拆屋效应 含义：你想让某人达成你的一个对你有利要求，如果你直接说出与自己的要求，那么你的要求也许会被对方压制下去，最后形成了一个“折衷”的结果。这个提议实际上没有达到你预期的效果。但是，如果你提一个相对自己想要的结果更大的要求，那么对方也会调和，但是你可以步步退让，最后退到自己的要求上，就能达到效果。其最大的好处在于让人无法拒绝你 起源：鲁迅（周树人）在1927年所写的《无声的中国》中写道：“中国人的性情总是喜欢调和、折中的，譬如你说，这屋子太暗，说在这里开一个天窗，大家一定是不允许的。但如果你主张拆掉屋顶，他们就会来调和，愿意开天窗了。 示例：《左耳听风》中提到 当你面对做不到的需求时，给出另一个你可以做到的方案，而不是把对方的方案直接回绝掉 。 当你面对过于复杂的需求时，我不说我不能完全满足你，但我说我可以部分满足你 。 我不能说不，但是我要有条件地说是。 ","date":"2021-06-20","objectID":"/posts/anecdote/:7:0","tags":["思辨"],"title":"有趣的经济学/心理学效应","uri":"/posts/anecdote/"},{"categories":["Anecdotes"],"content":"棘轮效应 棘轮(ratchet)\" 棘轮(ratchet) 由俭入奢易 由奢入俭难 ——司马光《训俭示康》 含义：人的消费习惯形成之后有不可逆性，即易于向上调整，而难于向下调整。尤其是在短期内消费是不可逆的，其习惯效应较大。这种习惯效应，使消费取决于相对收入，即相对于自己过去的高峰收入。消费者易于随收入的提高增加消费，但不易于收入降低而减少消费，以致产生有正截距的短期消费函数。 示例：一般来讲，领导在年初为下属设置业绩目标，在年底通过一些关键指标（KPI）来度量下属的表现。下属的表现主要取决于其能力和努力程度。这两个都不易被领导所见。领导往往根据对下属能力和努力程度的预估为其设置业绩目标。为提供激励，往往许诺超额重奖。下属为了争取奖金，加倍努力。年底业绩超额，奖金兑现，领导下属皆大欢喜。来年开工，领导心想，去年业绩这么好，可见这下属能力不一般，今年他的业绩目标就调高一点。面对更高的业绩要求，下属发现同样的努力程度今年刚好达标，想拿奖金，只能比去年更努力。下属今年的优异表现推高了领导来年对其的业绩期望，导致下属为拿奖金所付出的努力越来越高，这就是职场中的棘轮效应。给定这个现象，聪明的下属努力时，不仅考虑它对今年奖金的影响，还考虑它对明年领导期望的影响。有了动态的眼光，才能用最少的努力换来最大的收获。 ","date":"2021-06-20","objectID":"/posts/anecdote/:8:0","tags":["思辨"],"title":"有趣的经济学/心理学效应","uri":"/posts/anecdote/"},{"categories":["Anecdotes"],"content":"眼镜蛇效应 含义：指针对某问题的解决方案，反而使得该问题恶化。 起源：英国政府计划要减少眼镜蛇的数量，因而颁布法令说每打死一条眼镜蛇都可以领取赏金。然而印度人为了赏金反而开始养殖眼镜蛇。当英国政府意识到这种情况而取消赏金后，养殖蛇的人把蛇都放了；放出去的蛇继而大量繁殖，结果眼镜蛇族群数量不减反增。 ","date":"2021-06-20","objectID":"/posts/anecdote/:9:0","tags":["思辨"],"title":"有趣的经济学/心理学效应","uri":"/posts/anecdote/"},{"categories":["Anecdotes"],"content":"墨菲定律 面包落地的时候，永远是抹黃油的一面着地 含义：指的是任何一个事件，只要具有大于零的几率，就可确定它终有一天会发生。墨菲定律的原句是：如果有两种或两种以上的方式去做某件事情，而其中一种选择方式将导致灾难，则必定有人会做出这种选择，常解释为担心的事情总会发生，凡是会出错的事一定会出错。 示例：一粒米掉入轮盘上任意一点的概率是0，但落在轮盘上某点是个必然事件。 ","date":"2021-06-20","objectID":"/posts/anecdote/:10:0","tags":["思辨"],"title":"有趣的经济学/心理学效应","uri":"/posts/anecdote/"},{"categories":["Anecdotes"],"content":"羊群效应 含义：指盲目从众跟风。 起源：在一个竞争非常激烈的行业上，而且这个行业上有一个领先者（领头羊）占据了主要的注意力，那么整个羊群就会不断摹仿这个领头羊的一举一动，领头羊到哪里去吃草，其它的羊也去哪里吃草。 他用：zookeeper作为分布式锁，大量客户端注册监听事件抢锁，当锁被释放以后，会向所有的监听器发送消息，引起羊群效应。此处的羊群效应含义有所不同，指代信息风暴。 ","date":"2021-06-20","objectID":"/posts/anecdote/:11:0","tags":["思辨"],"title":"有趣的经济学/心理学效应","uri":"/posts/anecdote/"},{"categories":["Anecdotes"],"content":"皮格马利翁效应 含义：指人在被赋予更高期望以后，他们会表现的更好的一种现象。 起源：希腊神话故事里面的一位名为皮格马利翁的雕刻家，他爱上了自己用象牙雕刻出来的女神雕像，由于他每天对着雕像说话，最后那座女神雕像变成一位真正的女神。 示例：内心常常带着负面期望的人们将会失败；而内心常常带着正面期望的人们将会成功。 ","date":"2021-06-20","objectID":"/posts/anecdote/:12:0","tags":["思辨"],"title":"有趣的经济学/心理学效应","uri":"/posts/anecdote/"},{"categories":["Anecdotes"],"content":"海格力斯效应 以彼之道，还施彼身 含义：人与人之间或群体之间存在的冤冤相报、致使仇恨越来越深的社会心理效应。 起源：希腊神话故事中有位英雄大力士，叫海格力斯，一天，他走在坎坷不平的路上，看见脚边有个像鼓起的袋子样的东西，很难看，海格力斯便踩了那东西一脚。谁知那东西不但没被海格力斯一脚踩破，反而膨胀起来，并成倍成倍地加大，这激怒了英雄海格力斯。他顺手操起—根碗口粗的木棒砸那个怪东西，好家伙，那东西竟膨胀到把路也堵死了。海格力斯奈何不了他，正在纳闷，一位圣者走到海格力斯跟前对他说：“朋友．快别动它了，忘了它，离它远去吧。它叫仇恨袋，你不惹它，它便会小如当初；你若侵犯它，它就会膨胀起来与你敌对到底。”仇恨正如海格力斯所遇到的这个袋子，开始很小，如果你忽略它，矛盾化解，它会自然消失；如果你与它过不去，加恨于它，它会加倍地报复。 ","date":"2021-06-20","objectID":"/posts/anecdote/:13:0","tags":["思辨"],"title":"有趣的经济学/心理学效应","uri":"/posts/anecdote/"},{"categories":["Anecdotes"],"content":"破窗效应 破窗效应\" 破窗效应 含义：环境中的不良现象如果被放任存在，会诱使人们仿效，甚至变本加厉。 起源：以一幢有少许破窗的建筑为例，如果那些窗不被修理好，可能将会有破坏者破坏更多的窗户。面对“第一扇破窗”，我们常常自我暗示：窗是可以被打破的，没有惩罚。这样想着，不知不觉，我们就成了第二双手、第三双手……“环境早就脏了，我扔的这点儿垃圾根本起不到关键性作用”、“反正也不是我先这么做的”，不少人会这样为自己辩解。 示例： 一面墙，如果出现一些涂鸦没有被清洗掉，很快的，墙上就布满了乱七八糟、不堪入目的东西； 一条人行道有些许纸屑，不久后就会有更多垃圾，最终人们会视若理所当然地将垃圾顺手丢弃在地上； 出轨只有零次和无数次。 ","date":"2021-06-20","objectID":"/posts/anecdote/:14:0","tags":["思辨"],"title":"有趣的经济学/心理学效应","uri":"/posts/anecdote/"},{"categories":["Anecdotes"],"content":"刻板印象 你以为你以为的就是你以为的吗？ 含义：人类对于某些特定类型人、事或物的一种概括的看法，看法可能是来自于同一类型的人事物之中的某一个个体给旁人的观感。 类比：晕轮效应是指人们对他人的认知首先根据初步印象，然后再从这个印象推论出认知对象的其他特质，以点概面（由局部到整体）。 ","date":"2021-06-20","objectID":"/posts/anecdote/:15:0","tags":["思辨"],"title":"有趣的经济学/心理学效应","uri":"/posts/anecdote/"},{"categories":["Anecdotes"],"content":"边际效用递减 边际效用递减\" 边际效用递减 含义：在其他商品的消费数量保持不变的条件下，当一个人连续消费某种物品时，随着所消费的该物品的数量增加，其总效用（total utility）虽然相应增加，但物品的边际效用（marginalutility），即每消费一个单位的该物品，其所带来的效用的增加量）有递减的趋势。 起源：一个人右手举着300克的砝码，这时在其左手上放305克的砝码，他并不会觉得有多少差别，直到左手砝码的重量加至306克时才会觉得有些重;如果右手举着600克，这时左手上的重量要达到612克才能感觉到重了。也就是说，原来的砝码越重，后来就必须加更大的量才能感觉到差别（贝勃定律）。 示例： 当人经历强烈的刺激后，再施予的刺激对他（她）来说也就变得微不足道。就心理感受来说，第一次大刺激能冲淡第二次的小刺激。比如，原本一元钱的报纸变成了十元一份，你定会感到无法接受；而原本10000元的电脑涨了100元，你一定不会有什么大的反应。 你很喜欢巧克力，在吃第一块巧克力的时候会获得一种味蕾和精神上的满足感，这就是经济学家所说的“效用”。但是随着你越吃越多，你所获得的满足感会变得不那么强烈渐渐趋于平淡。第五块巧克力带给你的满足感远不及第一块，吃到第十块的时候，你甚至感到厌倦，更别说第十五块第二十块了。新增加的每一块糖所带来的满足感就是边际效用，“边际”的意思是事物的边缘，巧克力效用的边际是最后一块巧克力的效用。 ","date":"2021-06-20","objectID":"/posts/anecdote/:16:0","tags":["思辨"],"title":"有趣的经济学/心理学效应","uri":"/posts/anecdote/"},{"categories":["Anecdotes"],"content":"帕累托优化 婚前状态\" 婚前状态 婚后状态(预想)\" 婚后状态(预想) 含义：在一个系统中，存在一种分配状态，在不损失所有人的利益下，至少提升一人利益，此分配方向称为帕累托优化。在不损失所有人的利益下，无法找到一种策略使得至少一人利益提升时，系统达到帕累托最优。 本质：多目标优化的资源分配问题 ","date":"2021-06-20","objectID":"/posts/anecdote/:17:0","tags":["思辨"],"title":"有趣的经济学/心理学效应","uri":"/posts/anecdote/"},{"categories":["Anecdotes"],"content":"损失厌恶 损失厌恶\" 损失厌恶 含义：人们面对同样数量的收益和损失时，认为损失更加令他们难以忍受。损失带来的负效用为收益正效用的2至2.5倍。 实验 实验团体先行持有1000单位的现金。在此基础上做出选择。 A.50%的概率将持有的现金增加为2000。 B.100%的概率将持有的现金增加为1500。 此实验中，被实验团体的16%选择了A，84%选择了B。 同实验团体先行持有2000单位的现金。在此基础上做出选择。 C.50%的概率损失1000单位现金。 D.100%的概率损失500单位现金。 此实验中，同实验团体的69%选择了C，31%选择了D。 ","date":"2021-06-20","objectID":"/posts/anecdote/:18:0","tags":["思辨"],"title":"有趣的经济学/心理学效应","uri":"/posts/anecdote/"},{"categories":["Anecdotes"],"content":"沉没成本 含义：指发生在过去，但对当前决策无关的成本，来自于对过去投入的执着，以此来说服自己。也是作用在人的心理因素层面，心理成本意识大过本身付出的经济成本。 示例：即便本行干不下去也不愿意转行；即便没有爱了也不愿意分手；来都来了… ","date":"2021-06-20","objectID":"/posts/anecdote/:19:0","tags":["思辨"],"title":"有趣的经济学/心理学效应","uri":"/posts/anecdote/"},{"categories":["读书笔记"],"content":"一本让创意有粘性的好书","date":"2021-06-19","objectID":"/posts/stickiness/","tags":["思辨"],"title":"《粘住》有感","uri":"/posts/stickiness/"},{"categories":["读书笔记"],"content":"让创意具有黏性，打破知识的诅咒。 ","date":"2021-06-19","objectID":"/posts/stickiness/:0:0","tags":["思辨"],"title":"《粘住》有感","uri":"/posts/stickiness/"},{"categories":["读书笔记"],"content":"知识的诅咒 一旦我们知道某样东西，我们就会发现很难想象不知道它是什么样子。我们的知识诅咒了我们，对于我们来说，同别人分享我们的知识变得很困难，因为我们不易重造我们听众的心境。 ","date":"2021-06-19","objectID":"/posts/stickiness/:1:0","tags":["思辨"],"title":"《粘住》有感","uri":"/posts/stickiness/"},{"categories":["读书笔记"],"content":"黏性创意的六大原则 ","date":"2021-06-19","objectID":"/posts/stickiness/:2:0","tags":["思辨"],"title":"《粘住》有感","uri":"/posts/stickiness/"},{"categories":["读书笔记"],"content":"简约 寻找核心，从中提炼，切忌淹没导语。 谚语：从丰富的经验中提炼出的短句。 通过类比化繁为简。 ","date":"2021-06-19","objectID":"/posts/stickiness/:2:1","tags":["思辨"],"title":"《粘住》有感","uri":"/posts/stickiness/"},{"categories":["读书笔记"],"content":"意外 吸引注意力，并使注意力持久。 缺口理论：知识的缺口产生好奇心。 ","date":"2021-06-19","objectID":"/posts/stickiness/:2:2","tags":["思辨"],"title":"《粘住》有感","uri":"/posts/stickiness/"},{"categories":["读书笔记"],"content":"具体 “具体“的辨别：能够凭感觉审视某样东西。 例子，寓言，故事是具体的，便于理解，易于流传。 语言经常是抽象的，但生活不是。 ","date":"2021-06-19","objectID":"/posts/stickiness/:2:3","tags":["思辨"],"title":"《粘住》有感","uri":"/posts/stickiness/"},{"categories":["读书笔记"],"content":"可信 细节与数据会增强事物的可信度。 可获得性偏差：直觉往往会由于一些共同的偏差造成缺陷。 ","date":"2021-06-19","objectID":"/posts/stickiness/:2:4","tags":["思辨"],"title":"《粘住》有感","uri":"/posts/stickiness/"},{"categories":["读书笔记"],"content":"情感 当我面对人群的时候，我束手无策；但如果面对的只是一个人，我便有了办法。 ——特蕾莎修女 理性会抑制情感的自然流露，感性促使人们产生共情。 ","date":"2021-06-19","objectID":"/posts/stickiness/:2:5","tags":["思辨"],"title":"《粘住》有感","uri":"/posts/stickiness/"},{"categories":["读书笔记"],"content":"故事 宏观定义：能在脑海中产生画面的事物。 故事以更少的直觉，更多戏剧化的方式让我们参与其中。 故事的魔力就在于如果自己的某些经历与故事中的主人公相似，那么就会在大脑中产生深深的共鸣，依靠着这种共鸣，故事就可以产生巨大的传播力。 ","date":"2021-06-19","objectID":"/posts/stickiness/:2:6","tags":["思辨"],"title":"《粘住》有感","uri":"/posts/stickiness/"},{"categories":["读书笔记"],"content":"书评扩展 ","date":"2021-06-19","objectID":"/posts/stickiness/:3:0","tags":["思辨"],"title":"《粘住》有感","uri":"/posts/stickiness/"}]